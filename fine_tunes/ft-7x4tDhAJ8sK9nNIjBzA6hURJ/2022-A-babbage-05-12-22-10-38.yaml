0adb677b374a6fe1f51ca0084710d05e:
  4:
    pred: 4
    text: '*;D,;2;3;5;6;s;3;8;S;9;s;10;Š;C XII;+;D D, 3;IX;Or: 3x2 = 3 Q: X32X1;�
      at x3 xX1, tak počeme - podľahkého propaganito;upraviť D3 a D1'
    truth: 4
  6:
    pred: 4
    text: generativy model => model sa snaží modliť rozložení jednotlivých trénovacích
      dát ale nemá 4 nů aj vygenerovať dáta (nově) z jednotlivých klasifikací je třad
      výzvou na z nich učiť L) Gaussový klasifikátor � lepšie výsledky z menším počtom
      trénovacích dát � předešnosť dáta do buěd je potřebné vypočítať;niž nové nepři;distriminativy
      model => model sa snaží odhodnoť „rozhodovanie hranicu medzi jednotlivými třeskani
      Logistická regresia � priamomodeluje príslušnosť dáta x do tvrzeny c 2) lepší
      výsledky pri dostatočce velkou počtu trénovacích dát;p (x);GEN;DISk.
    truth: 2
  8:
    pred: 0
    text: P(NAKAZENY) = 0,2 P(ZDRAVÍ) = 1 - P(NAKAZENÍ = 0,8 P(POZ|I NAKAZENÍ) = 0,9
      P(ZDRAVÍ / POZ) = 0,1;P(X|= PEP|x|y) P(x|4) = P(X|Y). P(4) = P|4|X) � P(X) P(F|X)
      - APLX) P(X|Y) =;P(4);P(POZITIVNA) = ???;P(NEGINALIZENT) = 0,1 PINAKAZENÍ POZD
      = 0, 9;P(POZITIVNÍ) =;P(POZI NAKAR). P(NAKAZY;P(X|Y) = PLYIH).;P(4);PL+;L (PE);P(X|M.
      P(4) = p(4|X). P(X) / IPEXIM) P(C|X) = P(YX). PLX);P(NAKAZIPOZ);P(X|4);P(POZITIVNÍ)
      =;0,9. 0,2;0,9
    truth: 4
  11:
    pred: 2
    text: to;jednotlivých;XI;X.;konvolučných jadrec;učitelně parametre;x2 x3;moh ac
      .x;=počet parametrů;žila vyšla počet ; zugsfürste erst nicht am Ende dahin an
      Heraus genommen werden wird u. erst noch nicht anders das Eine verspachen verschien
      verseit deien versen Berseichen ven versen den veren zu zu zu zu zich zich zu
      zu zu zu zu der zu ver zu der zu der der Ba jádra jádra lampion;počet konvoluční
    truth: 4
  14:
    pred: 4
    text: ak odmenujeme len za splnenie úkoly, může sa stať, že sa agent nebude zlepšovať
      prelože sa nebude schopný „přibližovat“ k správnem riešeniu � nedostane sa do
      „cúle“ preto je v některých typoch úloh potřebně odměňovat agente průběžné,
      protože by na mohol „prestať zlepšovať“ a zachovíť teda tvoje zlepšovanie
    truth: 3
1101bdc0b19ca8bc615b343a37e69620:
  2:
    pred: 0
    text: MAX;10;MIN;88;vonna
    truth: 4
1470d08ba3cc205b74780668fd31047f:
  1:
    pred: 0
    text: DB;ABX
    truth: 4
  3:
    pred: 4
    text: greety seanch;(problém, o, h) DFS a* (problem, 1, 0),
    truth: 2
  7:
    pred: 0
    text: jsou trenovací data. parabola je výsledek polynomiální regrese druhého řádu.
      Model generalizuje protože se jedná o data s podaným rozložením pokud by jsme
      zvednuli rád napríliž velkou hodnotu může se stát, že bude regrese přetrénovaná
      a na nová data nebude odpovídat správně
    truth: 3
  10:
    pred: 0
    text: '- každé ráno je spojen se vším provozovat další vrstvě;VII - CO + VE'
    truth: 3
  12:
    pred: 0
    text: 01 - 71 03 - 412 73
    truth: 3
  13:
    pred: 0
    text: '- vstup;Výstup je semenován pomocí určení pravděpodobností (slova) na základě
      předešlích slov a první vstupní vektor je Start, noták podle vstupu vypočítá
      pravděpodobnost slov a zvolí jedno z pravděpodobných. - na druhé vstupu je vektor
      prvního slova, pravděpodobnost 2. slova vyspočítáme na základě prvního'
    truth: 4
16c6668cb781a439cd65dd36354b9847:
  5:
    pred: 0
    text: Pareretre u-stredná hodnota ať kovarianční ratica, kde je vektor a zovarianční
      ratica je ratica. Strední hodnota sú 2 reálne čísla a kovarianční ratica je
      veľkosti 2x2, teda 4 reálné čísla pre každú triedu, teda dokopy pre 3 vriedy
      ide o 18 reálných čísel. Odhadneme netvorou maximum likely hood P(x|c) - Rc
      odhad třeasy pre novo přichádzajúci vzor, vyvazuje s danou P(c|x) = PRX) pravdepodobnostou
      patří do danej triedy
    truth: 2
  7:
    pred: 4
    text: D1;p = flx/= wo + writt + w2;-> model generalizuje, lebo ná dostatek dát
      a daná funkcia je neprehlídka presne trenovacíni dátani � aby negeneralizoval,
      tak by sa muselo zmenšit počet dát, alebo zvýšit stupeň polynózu, teda model
      by dokonale fungoval na trenovacích dátach, no na nových by refungoval správu
    truth: 1
2999da745d9319388937680319e94ef8:
  1:
    pred: 4
    text: 'A;Nejprve provedeme 3krát po sobě akti A, tím se vždy dostaneme do stavu
      2: 132 32 1325 2 42 541 + z 32 ze stavu 2 potom může- me přejít do stavu O pomocí
      sekvence. Celková posloupnost je tedy (Aj Aj A; A; B; X), bez ohledu na počáteční
      stav.'
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;55;víme, že protihráč bude propagovat pro nás nejhorší možný výsledek,
      tím pádem ve 2. a 3. větvi to vždycky bude 212 nebo horší, což je míň než 8
      v první větvi.
    truth: 2
  3:
    pred: 4
    text: 'DFS: Zl problem, o, o;guedy: � a* (problem, g, o) greedy: a* (problem)
      o ih)'
    truth: 2
  4:
    pred: 3
    text: '3x2 x3: D2 = {1, 2, 3}; 83 = 64, 5, 6, 7, 8; 9i 10} X3K XI: DA = §53; D3
      = E43 3x2 x 3: D2 = {13; D3 = E43 X3. XI: D1 = §53: = 53.;D1 = {53; D2 = {1
      1}; D3 } 4}.'
    truth: 4
  7:
    pred: 1
    text: K=8;KART.;přesně;Rozložení Řešení se snaží nálezt spojitou funkci, kterou
      aproximuje diskretních bodů v rovině Generalizuje díky tomu, že je omezený na
      druhý řád (K=2) aby, takže musí aproximo Při extremě vysokém řádu by prostě
      udělal nějakou šílenou vhodku, která sice přesně protne všechny body, ale bude
      nám naprosto k ničemu
    truth: 4
2a75e5d12870ce9323a75192fef31a49:
  2:
    pred: 4
    text: '- Maximálna úspor;MAX;MIN;bude 2 aksanet musieť prehladávat;50;Alpha-Beta
      je optimalizátora algoritmu minimax, ktorá vmožňuje mne chať / orezať prehľadávanie
      niektorých vztahů v prípade, že užmáme rovnaké ale to lepšie riešenie;55 1/8'
    truth: 4
  3:
    pred: 4
    text: '- preedy search = A* problem, 0, 4) - DFS = AX (problem, 8, 0)'
    truth: 2
  6:
    pred: 1
    text: '- peneratívny modeluje rozdelenie hustoty pravdepodobnosti pre jednotlivé
      triedy a je schopný povedať s akou pravdepodobnosťou dáta patria do danej triedy
      - diskriminativní van ich "naturdo" rozděluje a je schopný povedať rovno že
      do anej triedy dá to patrí sorerativny je napríklad Gausovská klasifikátor -
      rozpoznávání s nutné rozumové - dokáže určiť pravděpodobnosti jednotlivých tried
      liškriminativny môže buť napríklad ineárna regresi citlivý na pretrénovanie
      nearest-nějšho do besedy'
    truth: 1
  9:
    pred: 0
    text: Strousal NATIVOU AI deep learning shallow learning ja že podobný;- vodotiha
      - počítačové vidence - strojové učenie - Neurónové siete v posilované učenie
    truth: 4
  10:
    pred: 0
    text: Musí se jednat;O ORIENTOVANÝ a ACYkLICKÝ svat;u Dobré se sešlo x3= max(w|x10)
      x2 = max(w|x, 0);zlý príklad ba bol;EDIOSOSEJ-TOALE
    truth: 4
  13:
    pred: 4
    text: výstupné sekvencie sa generují na základe pravdepodobnosti že jednotlivé
      slová/znaky (tokeny) za sebou nasledujú na vstup dostane dehoder encoded vstupný
      text, kterému určí wo, nasledujúce slová sa budú odvíjať od predchádzajúceho
      výstupu a pravdepodobnost; že slová za sebou nasledujú. P(wo) P(w|lus) P(w2|w|w|wo)...
      P(w|lús nahé slova v rozlišních jazykoch ba mali mať od sebevrovnanú euklidovskú
      vzdialenosť šňoro
    truth: 3
  14:
    pred: 2
    text: Není to vhodné pretože ak by bola úloha náročná tak ja extrémne dlhú dobu
      nic nedostal -> nevedel tu sa věst nevedel by, či to čo vodí je dobré alebo
      zlé;prípade, že tu dostával odmeny aj počas vykonávania danej úlohy, ideálne,
      čím bližšie k cieľu, tým väčšiu odměny, tak to sa rýchlo vedel naučiť správný
      i smer čo má ako vobíť aby doslahol cieľ. - tento prístup ale môže spůsobiť
      že agent nepresným úplne všethy stavy ktoré sa môžu javiť ako zbytečné ale za
      nimi sa shrána efektivnej šie viešenie
    truth: 4
2fcfde5bdeca3406910a9f82585f5a99:
  4:
    pred: 4
    text: 'KART. 345 Dne 11. 10. 103;3;D3 : 21, 4;Der 51. ... 103;312 27;D2 = {1,
      2, 3, 10} D3 = {2, 3, 4. 10};34;108;t3 LX1 D1 = 12,34,53 3: [2, 3, 43, 43]'
    truth: 2
  10:
    pred: 0
    text: jednoduché derivovatelné operácie konečný - první obsahovať reálne nie celé
      číslo;.;od
    truth: 2
  14:
    pred: 4
    text: nie závisí od problému (úlohy). Keby sme dávali;Priebežme et sa blíží tak
      nakonice ty sa zo stavu, kde sa blíží mohol naraziť na stav nelysa fi komu co
      nedostane a to by nehol byť problém.
    truth: 2
339df3958e8b2954a8f4aa1cf116a8cf:
  1:
    pred: 0
    text: DA AABX;OB
    truth: 4
  6:
    pred: 1
    text: 'generativny model - odhadneme rozloženie hustoty pravdepodobnosti dát výhody
      - veľme potom z rozloženia generovať dalšie dáta - napr.: lineárna regresia
      diskriminativny - zo vstupu sa rovno určí příslušná tréda (alebo pravdepodobnosť
      třídy) mě je potřebné zisťovať rozložené hustoty pravdepodobnosti, stačí určiť
      rozhodovacie hranice - výhody - potřebných menej parametr a - napr. logistická
      regresia'
    truth: 0
  7:
    pred: 2
    text: model regeneralizuje keď je pretrénovaný - či že funguje presne pretrénovacie
      data ale nie ne nové dáta polynomiálna regresia bude pretrénovaná, teď použijeme
      moc vysoký řád polynómu trénovacie dáta x příklad něšenia;- hodel generalizuje
      leto bude dobré určovat výsledky aj ne nově dáta
    truth: 4
356429a76a6d6231da81cd661d45a184:
  7:
    pred: 1
    text: '- tečky zobrazují učící data - čára zobrazuje naučenou křovku Model generalizuje
      protože se pohybuje okolo bodu s určitou chybou. Pokud by body procházel přímo
      generalizace by nefungovala. Tak by se mohlo stát, když bychom použili velmi
      vysoký stupeň k, např. počet trénovacích dat'
    truth: 2
3a3284a0871ed9e4bef8d9913724f16b:
  2:
    pred: 4
    text: MAX;1 MNV;O 20 10 8
    truth: 4
  3:
    pred: 4
    text: 'aby simulovala;Pre greedy search:;g-0 h= h;Pre DFS:;h=0;g =;Vytvoril by
      sam nová funkciu, která by počítala počet všech prejdených potomkov uzlu (deti,
      vnuky, ...). Tým dosiahnem, že napr. z korenča bude g stále stápať, protože
      DFS bude více zanárať. Pri vynárazní tento počet taktež bude stúpať. Takže hodnota:
      Venk. rozp. root. num Of AI Passed Children'
    truth: 2
  7:
    pred: 3
    text: nex + w1 + w6;Aby negeneralizoval, může byť model zle natrénovaný - problém
      overfittingu;Snažíme sa vytvoriť (napasovať) polynomiálnu funkciu 2. rádu tak,
      aby vzdialenosť sumy štvorcov od každého dáta dohromady bola čo najmenších Aby
      funkcia zodpovedala trendu dát v kterých je gausovský šum.;přetrénovan
    truth: 2
  11:
    pred: 0
    text: počet kanálov vstupu počet kanálov výstupu
    truth: 2
3a3d21d3d346f65e160c3859d0a79dc3:
  1:
    pred: 4
    text: 'X;190: X 2�0: Bx 3s0: AX 400: x;AXXEX;dosiahne ciel z ľubovoľné počiatočního
      stavu'
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;5;II;O;ušetříme nemusia prehladať;sa
    truth: 4
  3:
    pred: 4
    text: 'greedy search: a* (problem, 0, 1X) : a* (problém, 0, 0);DFS'
    truth: 2
  4:
    pred: 4
    text: 1;z;3;„;s;6;7;8;9;10;X1;X;x;x;x;x;xD1 = {1, 2, 3, 4, 5};x2;Š;x;x;x;x;>;3X2
      s X3 x3 LX1;D1 = {2, 3, 4, 5} D2 = {1, 2, ..., 9, 10} D3 = {1, 2, 3, 4}
    truth: 4
  5:
    pred: 4
    text: 'N;nálne rozloženie;P.;N(x|M, 6;2 71.;STRED. HODN.: M = 1/4 % X x n;VARIABILITA:
      0? = 1/5 En (xXm);Klasifikátor je popísaný střednou hodn.;a variabilitou.;11
      IR číslom.;Každý parameter je reprezentovaný Parametre na dátach odhadneme pomocou
      optimalizácie odhadu maximálnej Pravdepodobnosti. Novo prídený vzor bude patriť
      pravdepodobnostnému modelu niektorej z tried (k niektorému bude nejblížšíe).;fun.'
    truth: 1
  6:
    pred: 0
    text: 'funkcie:;p(y|x);DISKRIMINATIVNÍ;GENERATIVNÍ;68;- mapuje vstupy x na výstupu
      (labels) priamo rychlejší je - potrebuje viac dát, pri menšom počte dát su pretrénuje
      a zle generalizuje;generuje pravdepodobnostný model;- počíta pravdepodobnosť
      Bayes. vzorcom:;p(4|x|= p(x|y). p(x);ply;príklad: gaussovský;klasif.;íklad:
      lin. regresia;- stačí mu menej dát na natrénovanie - keď už má model vie navzorkovať
      ďalšie dáta'
    truth: 1
  12:
    pred: 0
    text: O.;02 = 1/2
    truth: 3
3c47f8987e710f7b4cb3fddd88b90692:
  4:
    pred: 0
    text: X, I D;„;3 4;- 2 - 1 2 3 4;5;- § 9 /10 56;Podtržení zimní vyřazení
    truth: 1
  7:
    pred: 1
    text: Nakreslil jsem docínky jež obsahují dostatečně velký počet trénovacích dat
      tudíž dochází ke generalizaci. Pokud by jich bylo málo mohlo by dojít nepříklad
      k přetrénování,
    truth: 2
  10:
    pred: 0
    text: '- nesmí se v grafu vyskytnout;Strana 26. Sept. 1870 več. vaillandi Karlovi
      Haar Schulič Hajazdjanského Koromu Bartovského Bartovského Bartovce Kostel Ba
      Bartovici Ba Ba Ba Ba Hojelszelar. Bela Bela Ba Her. Ba Ber. Ba Ha Ba Ba Ha
      Ba Ba Ha Ba Ba Baeraer. Baer. Haer. Haer. Baer. Ba Ba Ba Ba Ba Ba -'
    truth: 3
  13:
    pred: 0
    text: P(MúX) mai Následující slovo je generováno na základě pravděpodobnosti jak
      i jak předchůdců;p(wa) p(w2 Iwa) PIW2 IW2 W.
    truth: 3
  14:
    pred: 2
    text: Ano, já vhodně aby dostával odmíny i kalgz.;(průběžně). Pokud by dostal
      odměnu až za splnění, nemuselo by dojít ke splnění úlohy - obdržení odmny;se
      blíží k řešení
    truth: 3
40e971aa0d0f94173372792184d7c18b:
  1:
    pred: 2
    text: ADA;1;JB-X
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;10 Po;x u nepodstatné
    truth: 4
  4:
    pred: 4
    text: D1 D2 P3;X;*;x;+;Y x;t X XI;X 7;X. x;x;+ x;x;* x;x;x;x;x;+;r;X;X;X;x3 x
      1 433 X1);42;D1= 65;�;41
    truth: 4
  6:
    pred: 3
    text: 'Např. Paussovský klasizikátor, kde nejprve namodelujeme óst. funkci trénovací
      dat a potom vypočítáme p(C|X) Diskriminativní modelují posterior pravděpodobnost
      ravnou p(c|x) - bez hledání dist. punkce (p(x|c). Tedy hledají funkci, která
      trénovací data odděluje a na základě ní se potom pomocí sismuid punkce nebo
      jiné Např. Logistická regrese, SVM i tak spadá 1 vypočítá p(c|x) přímo. Výhoda
      solektivních, že teoreticky můžeme sonovovat falci, protože máme rozložení ale
      ty nám nepomůžou v modelu. o výhoda fiokriminativních: Jsou častěji používané
      a můžou mít lepší výkon'
    truth: 4
  10:
    pred: 0
    text: měl by být orientovaný acyklický sraz.
    truth: 2
43986b8b6ebee0468cbde54d39668894:
  1:
    pred: 0
    text: Bstate = 1. akcia Bstate => k 2. akcia Bstate;Ty;cia a ake;postupnost akci
      A
    truth: 4
  3:
    pred: 1
    text: 'RAD;světové české války proběhat idea: vzly v principu frontě chceme vkladat
      "opačnou" poradí, pomocou znenachystan řešeně: prodáme, póvodní h= h funkciu„
      -> greedy search neberie v petaz vražení cestu. eturno'
    truth: 1
  9:
    pred: 0
    text: učenie s učitelem učenie bez učitele posilované učenie semi-supervised learning
    truth: 1
  11:
    pred: 0
    text: 'in;tlol;M. K;Hol;vojtelné povahě neponevalnější vrstvy: konvolučné jádro.;počet
      šířeb matice konvoluční fitrové (jedieř) debít;ýška matice dát'
    truth: 3
43d4fa03bc9f11129af3e68ceb8890dd:
  1:
    pred: 2
    text: 'Posloupnost akcí: A BX ABX'
    truth: 4
  4:
    pred: 4
    text: 1;2;3;";6;6;7;8;a;10;XI;J;v;X;X;X;X;X;X3;X;D1 = § 53 D2 = {13 P3 = 54
    truth: 4
  6:
    pred: 1
    text: 'P(c|x) generativní model: — učíme se P(x|C) a P(c) a pomocí;-;"Baesova"
      vzorce počítáme gaušovský klasifikátor;diskriminativní model: se učí;- Lineární
      / Polynomiální regrese;P(c|x) přímo;generativní: * Potřebuje méně dat než diskriminativní
      - Pomalejší než diskriminativní + modulární diskriminativní : + rychlejší než
      generativní — Snadno se přetrénuje - potřebuje více dat'
    truth: 0
  9:
    pred: 0
    text: '- učení s učitelem;- učení bez učitele — Posilované učení;- Semi-supervised
      - learning'
    truth: 1
  10:
    pred: 0
    text: '- acyklický;- orientovaný;- strana poměru'
    truth: 4
  11:
    pred: 0
    text: hodnoty Filtrů;Počet parametrů = (velikost filtrů) * počet filtrů
    truth: 3
  14:
    pred: 3
    text: '- kdyby agent dostal odměnu jen za splnění úlohy, tak by tyto odměny byli
      příliš řídké.;Proto je lepší dávat odměny podle toho jak se blíží ke splnění.'
    truth: 2
45c6ae61bc1ecb52540c701d0158b3c4:
  3:
    pred: 0
    text: 'aby simulovala greedy search a depth-first search (DFS)?;Greedy search:
      q : return 0; k = h = (ako funkciu g prodán fun. které musí O);DFS: k: return
      0; g: return - len (parth); Kde len procia dlžku už uraženej asty (kolika uzlou
      sam už predtým navštívil) path � cesta pro daný uzel (pravdepod. by šla opěť
      o funkci která vracía akci (prodlouž daného uzlu) 6 akce s kterými sme sa do
      daného uzlu dostali;Ak je dovolená záporná cena'
    truth: 4
  5:
    pred: 4
    text: Vyjmenujte všechny parametry, kterými je takový klasifikátor popsán a které
      je potřeba na datech odhadnout. Jakou mají tyto parametry podobu? Kolika reálnými
      čísly jsou všechny tyto parametry reprezentovány? Jak tyto parametry na datech
      odhadneme? Jak tyto parametry využijeme k výpočtu pravděpodobnosti, že nově
      příchozi vzor patří do jedné, druhé či třetí třídy?;funkce hudby pravdepodobnosť
      pro všechny 3 třídy, teda my, w2, pro, 16, 16/21 % teda potrebujeme u a dr pre
      všelky 3 trady, čo je 6 parametru pobahujeme apriorní pravdepodobnosti všelikých
      3 tried, čo sú ďaložie. 3 parametry (1 by sa dal dopočítať). Spolu teda potřebujeme
      9 parametru Všetky parametry sú váhu čísla, leto pre hustoty pravd. nám stačia
      paranety Gausovky. Je třeba 9 rúzkých čísel. p�, ciz, ciz, 0ž, 8 2, 6 2/3 odhadneme
      metódou maximálnej viewhodnosti samozřejme pre každú dvojscu zvlášť, na odhad
      týchto parametru potřebujeme dáta. Apriárně první buď dostaneme alebo si ich
      odvodíme na základe dát (počet dát daný triedy)! (počet všetkých dát),;Tieto
      parametry dosadíme do Bayesovky vzorca pro výpočet;steriórnej pran. x
    truth: 1
  7:
    pred: 3
    text: Nakreslil svou dátu, které odpovídají zašumenej časti kvadratickej funkcie,
      a regresní prianka, která správne odhaduje nezašramenné díla To, že generalizuje
      je spokojené tým, že máme vhodne nastavený stupeň pobyvan a learning rute a
      aj počet iterácií učení Aby negeneralizoval, tak stačí dat nevhodný learning
      zato, alebo napríklad nastavit příliš vysoký stupeň polynomu alebo trénovať
      model příliš dlho (pretrénovanie)
    truth: 3
  11:
    pred: 4
    text: konvolučné jádrá � jejich hodnoty;tel;teda;a, b, c, ...;- (počet vstupných
      kanálov) x (výšku konvolučného jadra) * (šírka konvolučného jadra) * počet konvolučných
      jadier) alebo počet výstupných kanálov
    truth: 4
  13:
    pred: 0
    text: V ideálním případě vysvětle algoritmus generování jen neformálním pseudokódem.;Na
      vstupe majú celý vstupný dotaz/vetu a čast velký, ktorú už vygeverovali, teda
      na to aké ďabžie slovo sa vygeveruje má zásadný vplyn to aké slová sme vygenerovali,
      pro jarní slovo za dáva na vstup špeciálny taken START � Generujú funkciu pravdepodobnosti
      nasledujúceho slova, teda ak sme vygenerovali slová Maria ide", tak zastaví
      funkciu, která nám pozic akcí je pravdepodobnosť, že slovo u je dalším slovom
      tejto vety a to pro Fvo z nášho slovníka. � Teda "poznem za na to, načo mám
      odpoveduť (čo je moja úloha. vygeverujem prvé slovo a to potom použijem pri
      generování druhého vela dávala zmysel, to prvé a druhé zase použijem pri generování
      treticko, 14. Je při posilovaném učení vhodné, aby agent dostal odměnu jen při
      splnění úlohy, nebo i průběžně podle toho, jak se blíží splnění úlohy? Proč?
      Nůže to naopak způsobit nějaké problémy?
    truth: 3
49370e21cf26e14fd95bad47c4c64feb:
  1:
    pred: 0
    text: 3;AABX
    truth: 4
  2:
    pred: 0
    text: MAX;MIN;D;8;úspora 2 uzly
    truth: 4
  4:
    pred: 4
    text: X3SX2 D1 = {1, 2, 3, 4, 5} D2 = {2, 4, 5... 10} D3 = {1, 2, 3, 4};D1 = {1,
      2, 3, 4, 5} D2 = {1, 3} D3 = {4};3x2 W3;D2 = {13 D3 = {4};D1 = {5};W22 < 41;úzly
      z
    truth: 4
  9:
    pred: 0
    text: '- supervized semi-supervised - unsupervised - reinforcment (posilované)'
    truth: 1
  10:
    pred: 0
    text: p(nula);u -;- musí být orientované acyklické
    truth: 4
  11:
    pred: 0
    text: číslo);pan, počet - parametrů =;bias, váhy kernelu;Počet kanálů vstupu šířka
      - ker 1. netu výška - Kernel počet - AI trůlkemezů);Pokračování stav (neosov
      to mínusy,
    truth: 4
495ef79db86e9a0196ac1c8f89e61f67:
  3:
    pred: 4
    text: greedy:;a*;a, o r;problém;DFS
    truth: 2
  13:
    pred: 0
    text: udokódem.;Model vyberá slovo na základe pravdepodobnosti naj lepšej následující;zhody.
      Táto pravdepodobnosť získava pomocou váh přirodených k předchádzajúčinu slovám
      vo vete.
    truth: 2
4c12e29eaddc50e059d6ea3575524431:
  1:
    pred: 2
    text: 'A p. KANTAOX;STAV 2: AMAN STAVY: XAABA StAV 3: xAADABA;xAHABX;Po'
    truth: 4
  4:
    pred: 4
    text: 2;3;4;5;6;7;8;a;10;XI X2 X3 Výsledek � x1= 93,453 x2 21, 3, 4, 5, 4, 7,
      8, 103 x3 = 91,23;X.;x;X.;X.;*;*;*;* X
    truth: 1
  8:
    pred: 0
    text: 'P(NAKC) = 0,2 P(POZINAK) = 0,9 P(NEMAK| poz) =0,1;ALERALIZACE P(NOKY|PAAZ)
      = 0,9;P(poz)?;sum nule: P(A) = ? P(w|A) PRODUCT PCADIS = PCHIDELS = PCHIADPLA;P(P(POL)
      = p(POL) = p(POZICIAK) P(AN|C) NAK P(POZ| P(poz) =;P(POZNIAKIPOZ);vy 6/XI 9
      * 0,3;0,18;02;0;0,4;12;2'
    truth: 4
  10:
    pred: 0
    text: '- spravedlivost [-> sismii a diverzita;o 10 % (as o 10 %);2) vrstva neuronů'
    truth: 4
  12:
    pred: 0
    text: (x, T)
    truth: 4
5053112ed2eb6e04292b5773a3faaebe:
  1:
    pred: 0
    text: XAXSXBX
    truth: 4
  5:
    pred: 3
    text: 'Pro každou třídu potřebujeme ZD Gauss- klasifikátor. Každý ZD Gauss. se
      2/22 23 u = (* ný) z bodu a kovariační matice z střed musí být Tedy celkem 5
      reálných čísel pro jednu ZD Gaussovku. syndrická Pro 3 třídy tedy 15. Poramaty
      lze odhadnout pomocí Mod Likelihood: Ďraz = argumex NW/cie) = argent 2 human
      (ta NALEINE);skládá;Klasifikovat můžeme například pomocí MAP klasifikátoru.
      Pravděpodobnost, že dato x patří do (třída odpovídá Gaussově lince c) třídy
      a vypočítáme následně oprozní pravděpodobnost (jestliže je u všech tříd stejná,
      tak můžeme N(x|m, že) p(c) vynechat) p(x) Klasifikátor podnikuje soft rozhodnutí.;IN
      (x) (verzika) - p(x);sama přes všechny třídy /Gausse'
    truth: 4
  6:
    pred: 0
    text: Generativní model se snaží nemodelovat rozložení dat. Tedy snažíme se zjistit
      libelibost a opromí pravděpodobnost a z nich pomocí Bayesova vzorce vypočítat
      posteriorní pravděpodobnost Výhoda je, že se méně přetrénováva, můžeme z rozložení
      generovat nová neviděná data, nepotřebuje tolik dat. Nevýhodou je, že je zložitější
      a rozložená v některých případech nemusí být přívítaná jako např. Gauss Např.
      Gaussův CAN, Diskriminativní model napije vstup rovnou na výstupy, tedy snaží
      se odhadnout přímo posteriorní pravděpodobnost. Výhoda je, že je jednodušší,
      rychlejší Nevýhody jsou, že se snáze přetrénuje, potřebujeme více dat, Např.
      Logisticka his regrese (klasifikátor), pohynoucího regrese, lin. regre
    truth: 3
  9:
    pred: 0
    text: Učení s učitelem Učení bez učitele Posilové učení
    truth: 1
  10:
    pred: 0
    text: acyklický, vrstvený, žádné vazby v rámci vrstvy,;vztah;( 8;nebo
    truth: 2
  11:
    pred: 0
    text: karnel;počet kanálů na vstupu x velikost kernelu *velikost herala *počet
      výstupních kanálů (jedné strany);(+ ještě bias po celý hemal)
    truth: 4
  13:
    pred: 0
    text: Rekmentně se předává vnitřní stav a výstup záleží jak na něm, tak na vstupu.
      Začne se předáním tohonu START na první vstup a za ním následuje věta. Po vypracování
      věty se předá toku EVD . Výstupu se nám pak objasnuje věta.;odpověď.;věda
    truth: 1
527d06b610e162f0535cc5616c255c12:
  9:
    pred: 0
    text: učení bez učitele učení s učitelem. semi-supervised learning posilované
      učení
    truth: 1
  12:
    pred: 0
    text: výstupní vektory;váhy;OB Ty on LIT2 � 02;Vstupní vektor
    truth: 3
  14:
    pred: 4
    text: Je lepší, když dostává odměnu průběžně. Dostane-li odměnu až při splnění
      úlohy, nic se nenaučí, protože neví, které z akcí byly užitečné a které kontraproduktivní.
      Ví jen, že se dostal do cíle, ale neví, kterou cestou by se tam dostal lépe.
    truth: 2
5461d6183a165604c103a4923fcab04c:
  6:
    pred: 2
    text: 'Generativny model: - snažíme sa modelovať rozloženie hustoty pravdepodobnosti
      príklady klasifikátorov: lineárna, regresia, gaussovský klasifikátor - výhody
      na natrénovanie stačí málo dát, nemusí sa tak ľahko pretrénovat - nevýhody:
      pri nejakej odľahlej hodnotě nemusí fungovať správne Diskriminativny model:
      - mapujeme vstupy x na výstupy y na základe = f(x) - príklady klasifikátorov:
      logistická regresia, SVM (Sypport Vector Machine) - výhody: vie pracovať aj
      s odľahlými hodnotami - nevýhody: pri malom počte dát sa môže pretrénovať'
    truth: 1
  7:
    pred: 3
    text: Příklad trén. dát pre regresný problém:;Príklad riešenia:;Naprostená krivka
      je polynóm 2. rádu v tvare y = wo + w1x + 14, X. Polynomiálna regresia je špeciálny
      typ lineárnej regres kotvy x čím vytvárajú protože sa pridávajú bázy do tejto
      rovnice polynóm z tejto rovnice. Nemám Model generalizuje, tebe nepřechádza
      každým vzorkom a tým by správne klasifikoval aj na nových nevidených dátach
      Aby model negeneralizoval, musela by to byť polynomiálna regresia vyšších např.
      lyžno + 4, x + W. X + IV , 27 kg *;bídy;ro (napr. k
    truth: 1
  10:
    pred: 0
    text: 'výstupem musí byť vektor pravdepodobností;o;výstup: vektor'
    truth: 1
  11:
    pred: 0
    text: 'kernel vrstvy;2 počet parametrov: tento výška - kemel vrsty x širka - tenel
      vrstvy x počet vstupných kanálov x počet výstupných kanálov'
    truth: 4
  14:
    pred: 3
    text: Je lepšie, ak dostával odmeny aj při blížením k splněním úlohy Protože potom
      vie na základe týchto odmien si vytvořiť cestu k cieľu.
    truth: 3
55153f3976b813a5a04f49ae4dce8ac9:
  1:
    pred: 2
    text: XAXBI;PLÁN AKCÍ;JE pOSLOVNOST EX, A, X, X, XI.
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;úspora z UZLY 68 POKU ZMĚNILI POŘADÍ PROCHÁZENÍ (STŘED PRVNÍ, BYCHO
      NA MAXIMÁLNÍ úROVNÍ POUZE - sTAČILO BI PÉRUSPOŘÁDAT VĚTVA;c;x;ÚSPORA BUZLY
    truth: 4
  4:
    pred: 0
    text: D;53 12,33 51.
    truth: 2
  7:
    pred: 4
    text: '- TEČNÍ JSOU PATA Křivka je naučená regresní křivka PRŮZKY JSOU TESTOVACÍ
      DATA;x ABY NEGARIZOVAL staČilo by zvíšit K naTolik aby trpěla over-fitingem
      a Díky tomu nefungovala na testovacích datech NAKRESLIL JEM TAKOVÁ DATA OBY
      KOPIROVACÍ ŠUMEM COŽ ODPOVÍDÁ NAŠÍ REGRESNÍ TŘÍDCE s Y= Bot BIx + BAY? GENERALIZUJE
      PROTOŽE JE DOSTATEČNÉ složitá aby pochopila tréno v datech, ale není příliš
      složitá aby nefungovala dobře na jiných DATECH MIMO TRÉNOVACÍ SADU (PUNGUSK
      NA NICH DOBŘE)'
    truth: 4
  8:
    pred: 0
    text: (A) P(A);P(A|B);(6;Požár;ZPRAV;P(P|;1040 -;Nemocný;Nemocný pozitivní) -
      P(pozitivní informací) p(nemocný);P(POZITIVNÍ) =;(pozitivní nemocný) p(nemocný);P(POZiTIVNÍ);p(Nemocný/pozitivní;0,9
      .0,2;0,9;20
    truth: 4
  14:
    pred: 4
    text: Není to vhodné, protože to způsoby Možná že agent ani tuto odměnu nenajde.
      a není možné se pak zlepšovat, protože ani nevíme jaké z Agrentů byl Lepší (VARIAKY
      iNSTRUKCÍ) TÉMĚŘ TO ODPOVÍDAT náhodnému prohledávání protože nelze úplně zaručit
      že se to agent kdy NAUČÍ
    truth: 3
554f1cfee56cf20c2f51a5331933eb85:
  1:
    pred: 0
    text: AXAX;dostaneme sa vždy do cielového stavu - nezávisle od počintočnej polohy
      agenta
    truth: 4
  3:
    pred: 1
    text: 'greedy search: aX (problem, 0, h) DFS: ax (problem, 0,0'
    truth: 2
  7:
    pred: 4
    text: Trénovacie dáta:;Príklad naučeného riešenia:;z „Diskrétných hodnot získavame
      odhad funkcie popisujúcej vstup nédá) Bern
    truth: 1
  9:
    pred: 0
    text: '1 pokladník KART. Souvislost Oeep learning: Neurónové siete, KNS polynomiálná
      Shallow learning: Prehľadávanie stavového priestoru, regresia (logistická i'
    truth: 2
55c36c77f5b1db93efa809d68b0c3ff3:
  2:
    pred: 4
    text: MAX;MIN;1;nejvíce lze uvařit 2 uzly;1
    truth: 4
  4:
    pred: 4
    text: 11 B by;12 34 1 o AZA;67 C S;19 10;D3 = {4}
    truth: 4
  5:
    pred: 1
    text: 'ovat gaussovský klasifikátor. Vyjmenujte všechny parametry, kterými je
      takový klasifikátor popsán a které je potřeba na datech odhadnout. Jakou mají
      tyto parametry podobu? Kolika reálnými čísly jsou všechny tyto parametry: reprezentovány?
      Jak tyto parametry na datech odhadneme? Jak tyto parametry využijeme k výpočtu
      pravděpodobnosti, že nově příchozi vzor patří do jedné, druhé či třetí třídy?;klasifikáte
      je po každou třídu popsán Normálním rozdělením � personely: 4 (střední hodnota)
      a 5 (veriora) (A00 An 8. = 4 = (Ano Stro.) všechny paraety: 3x (2 x4) = 18 hledíme
      také proto, N = argentina A|x|MS) data náleží do třídy pro kterou p(c|x) = 10x10
      litrů K rozde tvrdě podobnost nejvyšší'
    truth: 1
  9:
    pred: 0
    text: číslo) konvoluční filtry;šich filtr x vojsk filtr * počet kanálů natop x
      před filtrů (topoly 323 Kuř) + před filtrů (bas)
    truth: 2
  10:
    pred: 0
    text: W,;14. Stoletínský 2-0 - VI
    truth: 1
56ffb625c1d50b61aa838947499f8ea9:
  3:
    pred: 3
    text: 'Greedy: glubso; hulaht;DFS: h(n) so; g(n) = kdo k sa bude znizovat s každým
      nevštíveným vrcholem � teda počítatelný vrchol bude model g(o) = 0; pri prohľadzení
      potromkov budeme jednotlivým potomkem přirodovat -1, -2, -3, ..., tým potom
      AI rozbalí posledního potomka, jeho potomkom přivádíme hodnoty J: - e--l-1,
      -l-2; ..., čím dovielme, že AX začne prohlídávat posledního potomka. Teda potrebujeme
      udržiarť globálne sedm číslo k a postupne ho zmenšovať.;es;� průzbah # vhodnoty
      vztah své hodnoty'
    truth: 4
  5:
    pred: 1
    text: '(Varlua) couldate) - 3 třídy � 3 gausovky. 2D data � XN N (Pi2); N = (x1|22);
      2= (coulearlie) varlat);- V gasmorka obsah. 6 parametrov, avšak cov (X1, X2)
      = cov (12, XX), proto stačí len 5 parametrov. params: 3.6 = 18 irsp 3. 5 = 15
      (ak berieme v úvahu symetru COU). p= ZDŠ: E = 1/4 CŘI-PI (KART = VIII) (predpokladáme
      stlucové Odhadneme žeh pomocou MLE vektory) N(x|M) [e) P(c) P(x|c) . p(c) p(c|x)
      =;P(x);Ta Z PCON N XINCI E2);� Výpočet pravdy. třídy nového vzoru.;Jednotlivé
      parametre odhodujeme z dát pu každá trieda zvlášť'
    truth: 4
  6:
    pred: 2
    text: -> gen. model využíva p(x|c) k výpočtu p(cla) � diskrim. model priamo modeluje
      p(c|x);(Gaussovský klasifikátor) (hogistická regresia);resp. pri tréningu gen.
      modelu odhadujeme perametre p(x|cin), kdyžto Pri diskriminativních modelech
      odhadujeme parametre p(c|x, r).;Výhody/nevýhody � Ak máme málo dát (2 pozitivne,
      2 negativnosti, Gausss klasifikátor môže dávať horšie Výsledky protože jednotlivé
      gaussovky budí mať veľký rozptyl. V tomto případu log. regresia fungovat budu.
      Taktiež ak máme jediný bod v jednej triede, tak nemôžeme použít genss klasifikátor,
      protože by 0 h = 0.
    truth: 4
  7:
    pred: 4
    text: 3;tečky si data, že je polynomý model 2. rádu. Log. reg. 2. rádu se bo +
      B1x + B2x? akcí že dáta vieme celkem presně modelovať parabolog, model bude
      vhodné generalizovat .;Negeneralizoval by, ale by naše dáta boli generované
      processor vyššího rádu (nepr x ), případne ak by dáta boli periedické (sin)
      Protože pol. regressa 2. rádu nic je periodická fu.
    truth: 4
  9:
    pred: 0
    text: � Supervised learning � Universita learning � Semi-supervised learning �
      Reinforcement learning � Selt-supervisus learning
    truth: 1
  10:
    pred: 0
    text: � orientovaný � acyklický � Huzol je buď tensor, alebo funkcion -;6 III;octnit;1
    truth: 4
  11:
    pred: 0
    text: � Váhy Kernelov Nah Ki, kz si dimenzie kerek, I ... počet informálov, D...
      počet filtrov vo vrstve � parametrov vrstvy = K1-22. I. D (+D ak uvažujeme bias).
    truth: 4
  14:
    pred: 2
    text: odmenu málo krát,;� Ak agent dostane odneseno ku pri splnení úlohy, bude
      dostávat čo vedic k pomalému uzeniu (prodpohledáme, že zo začátku agent nebude
      plniť úlohu, budu sa chovať cca náhodne). V tom případe v prvých fórech učenia
      by nedostával rewards � neučil by sa. Jedine kedy by sa zlepšoval by bolo v
      případu, že by sa mu podařilo splniť úlohu, že je malá pravdupodobností. Avšak
      ale máme jednoduché úlohy (il, malý počet možných akcí a stavov), tento přístup
      môže fungovať. Naopak, de agent dostáva revovés v priebehu plnensa úlohy, má
      vice spätnej všichni z teda má více informacie z kterej sa vie učiť.
    truth: 3
590c21c83ef826040fbb869666b99554:
  2:
    pred: 4
    text: MAX;MIN;66;nebudou se prohledávat (může v nich být cokoliv
    truth: 4
  10:
    pred: 0
    text: Musí to být Noriendovaný graf zloobsahovat;vykly.;nějaká vrstva neuronů,
      která je na konci povolnému nelineární
    truth: 4
5b664b32ef0f72ca651874d45d93b7db:
  7:
    pred: 1
    text: Generalizuje;Nakreslil jsem funkci vy (x), což je zjevně nějaká kvadratická
      funkce. Touto funkcí se snažím proložit body (trénovací data, abych pak dokázal
      pro nějaká nová dosud nepoznaná data odhadnout co nejpřesněji vy.;Model negmeralizuje,
      je zjevně přetrénovaný;Negeneralizuje
    truth: 3
  11:
    pred: 0
    text: konvoluční jádra;vstupní obrázek;konvoluční jádro např. 3x3 x 180 počet
      kanálů jistou šířku;jádro postupně přikládám ke každému pixelu obrázku a provádím
      konvoluci;64x64 x 180;výšku;šířku;počet kanálů;konvoluční jádro je nějaká matice:;5;2;1;8;5;z;"
    truth: 2
5eab670eb5ce6ebf722e191d7114c8c9:
  4:
    pred: 4
    text: D1 D2;D;1;X;2;3;„;5;6;X;X;7 X;x;X;8;X;9;X X;10;X;x;D1 = {2, 3, 4, 5} D2
      = {1, 2, 3, 4, 5, 6, 7, 8, 9, 103 D3 = {1, 2, 3, 4}
    truth: 4
  6:
    pred: 1
    text: generativní - modeluje rozložení (hustoty p.) pro data pro všechny třídy
      zvlášt a podle Bayesova vzorce dopočítává p (c|x) - př. gaussovský klasifikátor;diskriminativní
      - počítá p(c|x) přímo - př. logistická regrese;generativní potřebuje více výpočetní
      síly regresivní jde přímo x p (c|x))). vřínovacích nadruhou stranu nepotřebuje
      tolik vstupních dat
    truth: 3
  7:
    pred: 0
    text: 'generalizuje: �odpovídá rozložení dat negeneralizoval by, pokud by byl
      řád menší (1)'
    truth: 1
  9:
    pred: 0
    text: klasifikace (rozpoznávání pastevníků) generování obsahu (obrázky, videa,
      Deepfake etc.) řízení chování (autonomní roboti p auta, chatboti...)
    truth: 3
  13:
    pred: 0
    text: 'pozor;součin;modelují P(w|w: _ p... w6) pro X u v sekvenci'
    truth: 1
  14:
    pred: 2
    text: lepší je, když dostává odměny i při přiblížení k řešení (pokud je to možné),
      protože tak rychleji najde řešení X problém by nastal, pokud by to ohodnocení
      nebylo správné (přišel by o výhodnější řešení)
    truth: 4
6f5ac7c2b9cfe572c3654ff47bd016cb:
  1:
    pred: 0
    text: A;xAXAX;A;Po
    truth: 4
  4:
    pred: 4
    text: 3;56;D1;X;XXXX XXXxx 1 2 344 D1x x x X 0 D2 0 x x xx x X. XXX D3x x X 0X
      x x x x D3 D1 = 553 D2 = {15;X X;X;8;02 D;x
    truth: 4
  7:
    pred: 1
    text: Overfit;Výsledný model regrese (v =x) generalizuje jelikož se nenechal ovlit
      šumem a bude schopný najít správně i pro nové data Nakreslil jsem body a rovnice
      y=x s mírným Šumen. kdybychom modelu dovolili využít více řádu polynomu mohl
      by se přeučit a snažit se všechny body protnout. Čímž by způsobil že neví data
      by nenacházel správná y (regeneralizoval by)
    truth: 2
  12:
    pred: 0
    text: O;LIST;To;->;04
    truth: 4
  13:
    pred: 0
    text: V každém kroku generují na základě toho co doposud vygenerovali.;P(X|P(X|X))
      P(XS|P|P|P(X|P(X|))
    truth: 2
  14:
    pred: 4
    text: Ne - agent by se učil provádět průběžné kroky a mohl by ignorovat splnění
      úlohy
    truth: 2
772bee97261975d8ac3d623892156933:
  1:
    pred: 0
    text: 2 1. check � state ib O, neturn goal 2. proced with actions in order (A-B-�x)
      and go to point 1,;Do
    truth: 1
  6:
    pred: 0
    text: Generativny model počíta pravdepodobnosť P(X|Y) a apriornú pravd. P(Y) a
      n nich, na náklade Bayesovej vety, odvodňuje P(Y|X) Napr. K-nearest neighbors;Diskriminativny
      model počíta pravdepodobnosť P(Y|X) Napr. logistická regresia al, clustering
    truth: 1
  8:
    pred: 4
    text: (nak) = 0,2;p(wdzaw);p(pozitivat) = 0,9 p(zdrav) por) = 0,1;p (negl nak)
      p (nakl por) = 0,9 nak p(pon|p).;nak p(roz) -;p(poz) (norm/nobl). p(nabo) 0,9
      . 0,2;p(non) =;,2;p(nak|par);0,9;p(por) = 20%
    truth: 4
  9:
    pred: 0
    text: '- strojové učenie: supervised - unsupervised - semi-supervised - reiforement'
    truth: 1
  10:
    pred: 0
    text: '- acyklický - orientovaný;O'
    truth: 4
  11:
    pred: 2
    text: Počet = m x n x d x j m,n - rozmerz konv. jadra d - počet kanálov na vstupe
      = počet kanálov jadra j - počet konv. jadier v jednej vrstve
    truth: 4
  14:
    pred: 4
    text: Ak bude agent odmeňovaný na prieběžné krok, nikam sa nemusí reálne dostať,
      a teda je vhodné ho admeňovať až na sylnenie úlohy Poprípade rozdeliť úlohu
      na podúlohy odmeňovať tie. Nie však každú akciu.
    truth: 2
7f5b23849aa9f99628ec8fd57bd68a15:
  6:
    pred: 1
    text: Generativní model se snaží odhadnout parametry rozložení dat, příkladem
      je gaussovský klasifikátor. Model trénovaný diskriminativně má cíl co nejpřesněji
      modelovat hranici, která by sloužila k klasifikaci. Například, logistická regrese.
      Výhodou generativních modelů je to že nemají tendenci k overfittingu (přeučení),
      ale diskriminativní modely je snadněji naučit, protože nesnaží se odhadnout
      zbytečné parametry.
    truth: 2
  10:
    pred: 1
    text: graf musí být acyklický a orientováný.;- č-9-8- (letu) - člověk - (sobotu)
      - s
    truth: 4
  13:
    pred: 2
    text: 'Input evidence Fonn weat.;Výstupné sekvence generují postupně, slovo po
      slovu. Tyto sítě modelují pravděpodobnost následujících slov na základě předchozích:
      P(wa, ..., wa) = p(wi). p (w|lwi) . P(w2, wi)...;Honza šel;o 0 - ...;Staré Honza'
    truth: 3
825b1ce7fb0e1b7007e1df994a9c2f05:
  1:
    pred: 0
    text: 1471 77 KART. 1917 STŘEDA. VE FRAUE KCE DE NE SE SE SE SEŠE STINICH STICH
      POH;von;AXAX BXBX;B;AXLAX)
    truth: 4
  3:
    pred: 3
    text: 'xxx DFS: a (problem, lambdax: 0, lambdax: 0) GS: a (problem, lamldu x:0,
      h);Opce všetky x'
    truth: 2
  4:
    pred: 4
    text: D1 = {1, 2, 3, 4, 5} ka = D3 = {1, 2, 3, 4} D2 = {213;x3 LXI;3X2 LX;13;D2
      = {13 D3 = {4} D1 = {53;3X2 LX3 X3 LXI;-;D1 = {5} D2 = {13 D3 = {43;x3 LX, �
      3x2x3;J
    truth: 4
  10:
    pred: 0
    text: acyklický, directed (musí nať udaný smer);ŠOFTIAX
    truth: 3
  11:
    pred: 0
    text: filtry konvolúcie;počet = k . k. , s počet koní do velkostatku filtra;velkosť
      vrstvy
    truth: 4
837032a3c2d8c387024651eb631ff039:
  6:
    pred: 3
    text: Generativní model se učí jak data byla „vygenerovaná“, učí se rozložení
      dat. V podstatě učí se joint probability P (x, y), x jsou data a y jsou lubels.
      Tento přístup potřebuje víc paramet na modelování rozložení dat, ale dá se jej
      aplikovat v případě když nemáme moc dat. Příkladem je gaussovský klasifikátor
      Aktualně mají horší vysledky než disk. přístupy když máme dostatek. Diskriminativní
      modely modelují pravděpodobnost P(y|x), takž je nezajíma jak data byla vygenerována,
      hledají jenom rozhodovací hranici. Potřebují víc labeled tat pro trénování ale
      darají SOTA vystedky. Příkladem je logistická regrese nebo neural networks.
      Tyto modely využívají své parametry efekti;(ale všechno se může změnit ).
    truth: 4
  7:
    pred: 4
    text: 1X2;každý bod je sample z trénovac;a sady;K=2);Nakreslený model generalizuje
      protože jsem schvalně nakreslil rozležení dat, které se dá regresí 2. řadu namodelovat.
      Kdybych nakreslil tečky (samply) ve tvaru f-cí cos nebo sin nebo nějakou nelinearní
      fci tak by regrese (K=2) nestačila, nastal by underfitting. PÍPÍM PÍSMI = PODLEJDY;0.
      9. 0. 2 =
    truth: 4
  9:
    pred: 0
    text: Artificial General Intelegence - něco o čem nevíme nic a chceme toho dosahnou
      (napodoba lidskému intelektu). Má knowledge, může se učit během celého životního
      cyklus;AI, který se používá pro konkrétní tasky. Když umí obličije tak sotva
      může dělat něco jiného než ten tak na který byl natrenovan. Může dosáhnout a
      obejít lidskou performance ale jen v konkrétním tasku.;třarization NLP (Natural
      Language Processing) enchancement ASR (Automatic speech Recognition) recognition
      recognition - detection cv (computer vision) traching nějaký data modelling
      se taky dá považovat za AI
    truth: 4
  10:
    pred: 0
    text: Musí být derivovatelný aby se dalo aplikovat back propagation;studium [L|stmat|xw)
      = z;E
    truth: 1
  13:
    pred: 0
    text: h = Encoder (x) bos = "LISTARTS" (bude to nějaké číslo, ne string) output
      = tm = bos. bos for t in outpat out = Decoder (tmp, k) tmp=out output + = rout
      (string concat, v našem příp.;odpo;je spis trenován toto jelikož máme y, při
      generování všechno bude jednoduš V GOSTE STARÝ; tmp=bos k = Encoder (x) while
      true out = Decoder (tmp, h) tmp-out output. append (out) it (out = = CENDY)
      break Podstatná čast decodování v seg2 sey je to že decoder potřebuje output
      z minulého kroka a celou vstupní sekvenci P(gi/yi-a, gi-z... gosx);it (tmy =
      = LENDY) bréak;* v kódu závislost na všech předešlých last step outputech je
      implicitní, použilá se jen
    truth: 3
  14:
    pred: 0
    text: auto regressivní;modely;se špatně paralezují př. trénování protože vždycky
      potřebují chtput z minulého kroku;Reward by se musel dávat průběžně aby agent
      se naučil celkový postup (strategii) jak se cílí dosahnout. Kdyby to bylo naopak
    truth: 1
8ce0af8bc8320da3cdad209461ad5f7c:
  3:
    pred: 4
    text: 'DFS:;DES;cena cesty uročenej je v každem uzle rovnakú hibšie uzly majú
      nižšiu cenu do cieťa (rozbalí sa vzol a nasledujúce vzly mojí prednosť � ide
      sa do hľbky) 66;Greety Scarch: - S - vroucí cenu cesty -h - odhad ceny je vo
      H uzloch rovnozuj'
    truth: 0
  4:
    pred: 4
    text: D1;3;9;10;D;3;výsledek:;D1 = §53 D2 = {13 Os = k 4
    truth: 4
8f89c29a449586071735da9d9be70bb9:
  1:
    pred: 4
    text: '1. proveď akci X (pokud jsem v cílovém stavu nebo stavu 1, 4 dostanu se
      do cíle) 2. pokud nejsem v cílovém stavu, proveď A, 5 3. proveď x 4. pokud nejsem
      v cíli, 2.;sekvence: X, A, X, A, X, von;by měla stačit pro tento graf pro jakýkoliv
      stav;sum 2-3,3 -> 2'
    truth: 4
  2:
    pred: 0
    text: xino5 B.:5 č. 5 23 600 BPZ;MAX;B. 5;MIN;D Z úzky / pomším podmínku, cokoliv
      zvolím do posledních 2 uzlů v 350 BEM * hráč 1 se nikdy nerozhodne pro tento
      uzel � zbytečné počítání;protože nikdy nebude s
    truth: 4
  13:
    pred: 1
    text: '- na vstup dostanu větu k překladu - větu zakóduji - začnu dekódovat -
      věta začíná příznakem „START“ - následně vyberu nejpravděpodobnější první slovo
      zase začnu dekódovat, ale využijí START + slovo a hledám, které slovo má nejvyšší
      pravděpodobnost navazovat - takto opakuji, dokud nenarazím na příznak STOP -
      vracím přeloženou větu;- modelují max. likelihood (hledám nejvhodnější kombinaci
      parametrů)'
    truth: 3
  14:
    pred: 4
    text: Bylo by lepší, aby dostal odměnu až při splnění úlohy Agent ztrácí motivaci
      k učení, když dostává odměnu za průběžné kroky � možné zhoršení výsledku
    truth: 1
9107b38aa824dfbf43dc6389416d5d1e:
  6:
    pred: 2
    text: '- generativní model - odhadne parametry rozložení, modeluje funkci hustoty
      rozložení pravděpodobnosti + pomocí spočítaných priorů spočítá Bagesovým pravidlem
      pravděpodobnos třídy (tedy chceme P(y|x), které spočítáme z P(x) a P(x|y) -
      příklad k nemocnici k nejbližších sousedů diskriminativní - odhadují přímo pravděpodobnost
      P(y|x) - snaží se majovat y na x - příklad: logistická regrese - výhodné když
      máme málo dat, ale nevýhodné protože nemůžeme generovat nové vzorky nové vzor
      - výhody x nevýhody generativních - pokud známe parametry rozložení, můžeme
      generovat a klasifikovat je, nevýhodou je potřeba hodně dat'
    truth: 1
  7:
    pred: 2
    text: TK= 2;nahradil jsem část paraboly (tedy k =2) která generalizuje - pokud
      navzorkují nová data ze stejného rozložení, bude toto řešení stále vhodné -
      generalizující aby negeneralizovalo, mohl bych zvýšit k tak moc, že polynom
      přesně projejí body tedy bude přetrénovaný a nebude generalizovat
    truth: 4
  9:
    pred: 0
    text: přípravy;Nadutila;- supervised learning - učení s učitelem - unsupervised
      learning - učení bez učitele - semi-supervised learning - reinforcement learning
      - seff-viset learning)
    truth: 1
  10:
    pred: 0
    text: '- musí být acyklický;� nesmí záviset na později spočítaných hodnotách -
      důležité, aby šlo následně použít chain- rale ke spočítání bach - propagation'
    truth: 3
  14:
    pred: 3
    text: Je vhodné, aby agent dostával odměnu průběžně a tím hledal cestu k cíli,
      by bez této průběžné odměny nemusel nikdy najít, (např. špatná rozhodnutí, krátká
      sekvence zážitků aj. který - může teoreticky způsobit něco jako uváznutí agenta
      v lokálním suboptinu tedy ANO, může způsobit problémy
    truth: 4
916f1b2e1dead796dd18343b179494dc:
  1:
    pred: 0
    text: 'Bax;Ak agent bude vykonávat striedavo akcie vždy (z noci jakého stavu)
      sa dostane po určitom čase do;teplo step = o while not in 90 aif step %2: action
      � B elše action <-x do - action (action) stept+'
    truth: 1
  4:
    pred: 4
    text: 2;3;4;5;6;7;8;9;10;X;X;XX;X;X;X2;1;83;X;X;x;x;X;X;X351 � 3x x312 = 3X53/32
      X3=3=3x2=3=3=3=3) x3 = 4 = 3x24 = 5 x2 4/2
    truth: 4
  9:
    pred: 1
    text: '- - machine learning - speech recognition - neural networks (deep shallow
      learning) - computer vision - language models - agentní systémy - rozhodovacie
      systémy'
    truth: 4
  10:
    pred: 0
    text: Musí to byť orientovaný a acyklický graf;S - pri učení je treba počítať
      gradienty jedným prechodom od konce na začintok (používa sa chain rule, čiastkové
      gradienty sa medzi sebou násobia) -> je treba, aby graf nemal cykly (acyklický,
      a, aby sa dalo isť od koberca na začatek (orientovaný);W2 - minc-
    truth: 4
  11:
    pred: 1
    text: 'parametre = konvolučné;jadrá danej vrstvy;konv.;Počet parametrov = počet
      jadier vo vrstve;šírba : výška jadra jádra;počet Kanálov jadra;napr.;Konv. jadro
      2x2 s počtem kanálov 3 je 12 parametrov. Konvolučných jader môže byť aj viac
      (treba prenásobiť počtom)'
    truth: 4
  14:
    pred: 0
    text: Niekedy je velmi těžké doslabnuť cieľ. Agent AU by sa odmena dávala len,
      agent by sa k nej vóbec nemusel za dobiahnutie dostať (alebo by to trvalo velmi
      dílo). Aleto je častokrát lepšie dávať odmeny aj za stavy, ktoré sa blížia cielu
      (nie len za cieľ) Odmenu však môže byť tažké stanoviť pre dané stavy, ale by
      bola stanovená zle; môže to agenta "oklamat“ a ten sa potom bude učiť nesprávne
      veci.
    truth: 4
93f74ef23a742aa725be9a7edf20c3d0:
  1:
    pred: 0
    text: 'DA;BxBX;Ake: B-X-B-X;DB'
    truth: 4
  2:
    pred: 0
    text: MAX;MIN;59;O;D
    truth: 4
  3:
    pred: 4
    text: '65 to. 9=0, h-h DFS: g = len (death), h = o (neboru o)'
    truth: 2
  5:
    pred: 0
    text: '- řešíme pravděpodobnost P(c|x), tedy pravděp., že dato x patří do třídy
      c P(X|c) P(c) P(c|x) - řešíme podle Bayesova vzorce: P(x) - P(c) můžeme přímo
      dopočítat, je to priorní pravděpodobnost, dopočítáme pro všechny 3 tři P(x|c)
      budeme muset odhadnout rozložení hustoty pravděpodobnosti gaussovského rozložení
      P(x) dopočítáme ze sčítacího a násobního pravidla P(x) = 2 P(x|c) => P(x, c)
      = P(x|c) P(c) P|c) P| P| P|C) =P(c|x) P(c|X) P(c|X) = P(c|X) = ) K);po - musíme
      odhadnout nejdříve parametry Gouss. rozložení P(x|= N|x; MO ?) = tedy střední
      hodnotu pr a odchylku o - pro odhadování parametrů je vhodné využít odhad s
      maximální věrohodností (ML;20'
    truth: 2
  9:
    pred: 0
    text: '- rozpoznávání řeči, osob, podezdřelých transakcí asp. v hraní počítačových
      bez - překlad - vyhledávání informací - generování hudby, dle zadání dobráčků,
      textů - posilované učení'
    truth: 3
  10:
    pred: 0
    text: '- musí být orientovaný a nesní obsahovat cykly;- např.;KART.-IV-SOUŘAD
      - LISTINACE'
    truth: 4
  13:
    pred: 2
    text: P(w2 (w2 - 1, wo?) = II P(w2-1, w2-2. ..., nos);pseudokád:;poreg. dele.
      segr to-segra na základě předchozích vygenerovaných slov se snaží vygeverovat
      slova další;vygeneruj první slovo na zaklada vstupu; for (generuj in delkavoty)
      podívej se na predchozí slova a vygeneruj pravděpodobnosti, vyber nejpravdepodobnější
      slovo,?
    truth: 4
  14:
    pred: 2
    text: '- je vhodné agentovi dávat odměny průběžně, aby věděl jakým směrem postupovat
      respektive, jak se mu daří, protože v RL ohodnocujeme až řešení, ale nevíme,
      jak se k němu dostat'
    truth: 2
94474f32d4666fa6a215c2f3c304d86e:
  3:
    pred: 4
    text: 'g, (cesta) : return o;a* (problem, g1, hx);DFS:;h2 (cesta): return 0;JZ
      (osta): return encoresta) (-1);a x (problem, g2 (h2)'
    truth: 4
  8:
    pred: 0
    text: P(nakažený) = 0,2 P(pozitivní) nakažený -0,9 P(zdravý / pozitivní) = 0,
      1 => p(nakažený/pozitivní) = 0, 9 P(pozitivní) = ?;P(pozitivní) P(pozitivní)
      = P(pozitivní|nakažený) - p(nakažený);P(nakažený/pozitivní):;si nakažený (pozitivní);P(pozitivní)
      nakažený . P(nakažený;P(positivní) =;012
    truth: 4
  14:
    pred: 2
    text: V určitých situacích to může být vhodné, aby dostal odměnu i průběžně, pokud
      je dosažení splnění velmi obtížné a agent by se neměl jak učit dostatečně rychle.
      Obecně je ale lepší, pokud agent dostane odměnu až na splnění. Jinak totiž agentovi
      vnucujeme určitý způsob řešení, který chceme aby vykonal. Je tedy otázka, jestli
      je toto tlačení do určitého způsobu řešení náš záměr neboť přicházíme o možnost,
      že agent objeví nějaké nečekané a originální (notemoiálně nejneprší) řešení
    truth: 4
946210e51441cdd5d807f3a7d958f9f9:
  5:
    pred: 0
    text: apriorní Parametry - likelihood funkce p(X|C) pravděpodobnost třídy p(c)
      - pro každou třídu dat p(c) = poměr trénovacích dat ze tříd, pro každou třídu
      1 hodnotu likelihood - potřebujeme parametry normálního rozdělení - ve + J tedy
      20 vektor pu = ø] a kovarianční matice < pro každou třídu 6 reálných čísel or
      Celkem celkem x likelihood param = 3 + 3 b = 27 N = 2 = 2. 2. 2. 2014 - aN /
      A - vysádření z max. likelihvod MALXICI;PICIFIE;(x|c) . p(c);S POLICIDLY
    truth: 4
  6:
    pred: 2
    text: generativní - trénujeme rozdělení pravděpodobnosti jednotlivých tříd, P(c|X)
      vyjádříme s využitím bayesova vzorce - např. gaussovský klasifikátor diskriminativně
      - trénujeme přímo P(C|X) - např. logistická regrese;generativní funguje lépe
      s méně daty, ale plýtváme parametry diskriminativní - lepší s hodně daty, ale
      má tendence se přetrénovat na málo datech
    truth: 4
  12:
    pred: 0
    text: OSTATE;01- 51 O4-T1, T2, I3, L4
    truth: 3
  13:
    pred: 4
    text: Generují výstup na základě předchozího výstupu;P(w2, w2, ..., W2) = TT P(wn)
      P(wn as, W2 , ..., W1) BOTŮ;JAN;14;bytový lůžec JAN;ŠEL
    truth: 3
  14:
    pred: 4
    text: černo Vhodnější je až po splnění úlohy, při odměňování moc často se tak
      dobře neučí (např. bude pořád opakovat stejnou cestu, kde už odměnu dostal)
      může být lepší Učení může na začátku déle trvat (než se např. dostane do cíle)
    truth: 2
94c11b6d613717c655f2df563c47e9dc:
  2:
    pred: 1
    text: MAX;3;Š;- úspora = 2 udy;MÍN;je to jedno, nebudou prohledány (min už je
      menší než max z vyšší úrovně)
    truth: 4
  5:
    pred: 2
    text: 4 (co - nahoře možná ne) odhadném metodou maximální věrohodnosti Pro vzor
      spočteme hustoty všech rozdělení (ve vzorovém datu) a řekneme, že vzor patří
      do třídy s nejvyšší hustotou.;=2
    truth: 1
  7:
    pred: 4
    text: tečky - trénovací data Z křivka = naučený model Generalizuje proto, že prochází
      daty rozumně. Negeneralizoval by tehdy, kdyby bodů (dat) x bylo málo a naučený
      polynom by protínal data přesně, ale velmi divoce (tzn. měl vysoké kaeficienty
      vah). To se stává, když uvažujeme polynom vysokého řádu (a máme málo dat).;,
      negeneralizuje
    truth: 4
  10:
    pred: 0
    text: w w2 LISTOPADU vstup;D vzduch
    truth: 3
  11:
    pred: 2
    text: váhy v jádřech parametrů = (velikost jádra x) - (velikost jádra - y) - (počet
      výstupních hanáků
    truth: 3
9959b39950406bc66827b12959f783aa:
  1:
    pred: 2
    text: 'ABX;Pokud budu spravovat samá A, pak se dostanu určitě do stavu 2, ve které
      x budu chtít, nejdelší cesta do 2 je ze 3 odkud stačí 3A. Odtud pak 3 a X stačí
      na to se dostat Do koncového stavu O.;Poslední akce musí být x;Postoupnost:
      ANOX'
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;Prohledání vždy;Není co natřít;Tyto větším - 2 velké;Na tento se
      podívám a končím
    truth: 4
  4:
    pred: 4
    text: 12 3456 7 8 9 10;senom komentář;23/XXIX 1x x x x x;D2 xxxxx XXXx;DA XXXIX
      x x x x XXX;Výstupem je D, = § 55 2513 D3 = {4} (Jediným řešením CPP je tato;xxx
      x1 x1 je menší než 6. -> X3 musí být menší než 5 Ahoj 3x2 x 2 x ? největší x
      je 4 a tudíž největší x je 1 (z 2 bytu byl 64 4, což neplatí). Současně x 3.
      Současně x x3 � x 14;kombinace domín
    truth: 4
  7:
    pred: 3
    text: Ředpokládám, že K=2=) y= w + wx + w - Nakreslil jsem nějaká lehce zašuměná
      data naznačující průběh paraboly a mezi nimi namodelovanou parabolu - dobře
      generalizuje, jelikož původní závěr byl parabola a po dosazení nemusel dostávám
      tvar, který bych očekával (generalizace = umím dobře odhadovat i výstup pro
      taková data, která jsem dosud neviděl) Negeneralizovat by mohl např. v situaci,
      kdy - přidám výrazněji zašum. data (outliers), odeberu data, výrazně zvýším
      stupeň polynomu bez přidání dalších tat (křivka by pak šla 'cih cak
    truth: 4
  8:
    pred: 3
    text: P(náh (poz);P(poz)ňati P(mak;P(nak) = 0,2 P(pokl. |nah) = 0,9 P(náh (poz)
      = 0, 7 P(poz) - ? P(náh) = 0,8) (pozitivní) P(nak) / poz) =0, 9;p(poz);P(pozice
      = P(pozitivník) Pinak 944-9);P(nak) poz);P(pozinah) = P(nah / poz) - P(poz)
      P(nak) P(pan Inak) - Plnok) 0,9. 0,2 P(poz) P(nak (poz) P(poz) = 20 %;0,9;0,2
    truth: 4
  9:
    pred: 3
    text: '- Strojové učení retody bakálního prohledávání Stavové prohledávání a hraní
      her Genetické algoritmy Zpracování přirozeného jazyka Počítačové vidění inteligentní
      systémy / zařízení probotika'
    truth: 4
  13:
    pred: 0
    text: slovo 2 + Swoboda w soudu Předspisování vzoru dekan - hodin Tyto modely
      obecně pracují na principu hledání nejpravděpodobnější posloupnosti slov p (slovo),
      slovo 2, ... slovo m) a počítají ji tak, že nejprve spočítají pravděpodobnost
      prvního slova, pak druhého pst prvního atd. - vzorec p(x|x) = x) = FI = 664
      �2
    truth: 3
9b33f3eaa48336d891ace3b901cdf7b7:
  1:
    pred: 0
    text: 'v alam;čo wydím;Triesene: BX 3X;DB;x;B8X'
    truth: 4
  5:
    pred: 4
    text: 8;lido dva parametre charakterizujú jedna třída. Keď máme tri triedy tak
      máme trojicu týden dvacet parametrov.;d;kovariační matica;pr- priemer/stred/uniestnenie
      dvojrozmezného gaussovského rozloženia v 2 d přestore, 2 neděle čísla E- kommandí
      metica, a- udáva ako velmi je reloženie "rozťalové" v ose x d - -;v ose;XIC
      2 Dic 8 = EXTINGENT;10;c - izdex brindy No - počet dát danej tviedy;p(x|c) =
      16 m = 12) = ve F. 2;Ak-ristérye);b = C - korelácia vedzi atributmi x a y čím
      bližšía k +1 čím bližším k -1;ak sú rosí o;Pomoc týchto parametrov vieme modelovať
      rozloženie resp. rozdelenie pravdepodobnosti. teď chceme avezť do ktorej briedy
      dané dato patří, tak vypočítame pravdepodobosť jeho výskytu podle funkcie rozdelena
      pravdepodobosti pre každá z bied, a priudíme ho třeba, pre ktorú je táto prodepodobot
      největšía.
    truth: 3
  9:
    pred: 0
    text: '- spracovanie obrazu - spracovanie přirodreného jazyka - generovanie textu
      / obrazu (deep fakes) - preklad - odporučacie systémy - swarm intelligence -
      ray tracing (NIDIA)'
    truth: 3
  10:
    pred: 0
    text: '- argetický;diferencovatelné aktivační funkcie (hodi GD) - nevhodné aby
      za sebou boli dne 2x vody ber aktivizej faktně nechci zimi - vedie k zbytečnému
      výpočtu, telo upravenlivý stav, který je možné obsíahat pomocou jedinej vrstvy;WART
      �;4 hod/poledne / soubor our;BAD'
    truth: 4
  11:
    pred: 2
    text: paranetre filtrov konvolučnej vrsty;všecky porozebrané vzty;počet parametrov
      jedné vzty NAXXIC avšak pozor, porazila v konábrah filtra sa rovných, proto
      je tento počet;NAXY;C - počet kazílov vstupu N - před filtrov vrsty X, Y - roznesy
      filtra;PUT;v každej;vstve môže byť až N filtrov. každý filter musí mať romaklý
      počet kanálov ako vstup. Mali by měl všetky filtre roncké roznosy.;učitelné
      paraztu;vyty
    truth: 4
  14:
    pred: 0
    text: me to rání od tazku. Ak nu však dávame odmeru priebežne (hned po vykonaní
      správnej akce) tak vie lepšie asociovať danú odmenu s danou akciou. Ak na dána
      odmena len na konci, tak nevie která konkrétna akcia bola v konkrétnom stave
      tá nejvhodnějšia. To že na déme odmezu hned môže vieď ku problému podobnému
      "instant gratification", kedy bude stále vykonávať daná akcia za účelem odmey
      a nebude objavovať nové postuposti stavov/akčí, případne v danou stave určitezne
      napríklad AI která pozerala televizi v bludisku.
    truth: 3
9f14e4b60aa060a04813f144a2533dea:
  2:
    pred: 2
    text: MAX;MIN;600;úspora - 2 uzly
    truth: 4
  6:
    pred: 1
    text: generativní - modelujeme rozložení podle vstupních dat (Gauss diskniminativní
      - nemodelujeme rozložení, pouze odhadujeme předél mezi třídami (logistická regrese)
      lehce se přetrénují vyžadují méně trénovacích dat
    truth: 1
  8:
    pred: 0
    text: x ... je nakažený ... je pozitivní p(x) = 0,2 p(y) =0, 9 p(x|y) =0,1 � n
      (x;(x) negle p(x|y) = (y) p(xry) = p(x|y) p(o);(y) =?;1) (x);,;0,9 0,9;0,2
    truth: 4
  10:
    pred: 0
    text: acyklický.;složen z nelimánních matematických operací;o;- ouk
    truth: 2
  12:
    pred: 0
    text: 01 = f(11) O4 = f(11, 12, 13, 14);S
    truth: 3
  13:
    pred: 3
    text: Generují výstupní sekvence iterativně. V každé iteraci je výstup vektor
      pravděpodobnost tokemů (slov). Pravděpodobnost každého 1 rokem je závislá na
      již vygenerovaném prefixu a celkovému vstupu (překládaná věta).
    truth: 3
9fae5964355733843daa9b7668b03bed:
  1:
    pred: 3
    text: 'Po vykonání každé akce Zkontrolujeme, jestli jsme nedosáhli cíle. Následující
      posloupnost akcí nás vždy dostane do dílového stavu: A, X, A, X;DB;AX AX'
    truth: 4
  4:
    pred: 4
    text: D1 = {3, 4, 5} D2 = {2 ,2,..., 9,10;112. omezení;11 z1. overení
    truth: 1
  9:
    pred: 4
    text: 'Umělá inteligence se využívá v různých oborech: matematika, statistika,
      medicína, ekonomie, impormatika;„Strojové učení'
    truth: 1
  14:
    pred: 4
    text: Je nutné, aby agent dostával odměny průběžně (počet odměn odvozen např.
      od délky řešení Chodné Málo potěm může způsobit nejednoznačnost postupu, takže
      se agent nemusí třídě. dostat do cíle.
    truth: 3
a59e81da1b3adf890fe6c32a90507d3c:
  4:
    pred: 4
    text: D1;D2;C /;/ / /;/;/;/ o;/;An;7 4 / /;8;* / /;q;*;/;10;XII.;/;D1 = {53, D2
      = {13, D1} = 243
    truth: 4
a95f81531d5247f5a1082ca2f27c10ce:
  4:
    pred: 4
    text: k;£5;6;19 77 Druhý pokus X3 (Kl => N3 = 3, 1, 2, 3, 43, x71 3x2ʒ x3 => 42ť1;Str;D1
      = {2, 3, 4, 5} D2 = {23, 40} D3 = {1, 2, 3, 4};FeeR;6;x1 S 1, 29 49 + 10) 3
      = 95 = 12;14 StŘEDA;D1x/2 D2 2/3/4 6 2/9 10 D31 2 3
    truth: 3
  5:
    pred: 0
    text: 'Odhad ú provedeme jako průměr dat, zvlášť pro každý rozměr, tj. průměr
      z x - ových hodnot a y-ových hodnot! ú = (x, η). Samozřejmě bereme pouze data
      patřící do dané třídy. O vypočtení (odh. klasicky, ale s využitím př. Pro třídu
      pak máme 2D normální rozložení N (ú, jez), které využijeme pro výpočet pravděpodobnosti
      náležitosti k třídě.;Každá třída má svoji ZD gausovku s parametry u - střed
      a p2-rozptyl. Tyto parametry jsou dvourozměrné, tj. dvojice: u = (myny), P(P2,
      Py). Jsou to tedy tři 2D parametry, tj. 6 reálných čísel.;Vzorec pro ZD z hlavy
      nedám...'
    truth: 0
  13:
    pred: 2
    text: Tyto modely se učí váhy/pravděpodobností výskytu daného slova tomto kontextu.
      Dado by se tedy říct, že modelují tci (Ax) = p (slovo/slova před slova po))
      V případě nízké pravděpodobnosti zkoumají širší kontexty.
    truth: 1
ae04cdd739eceeae85fda0bd00049cd7:
  1:
    pred: 4
    text: 'provedu 3 krát akci A a zručeně budu ve stavu 2 potom provedu sekvenci
      akcí vedoucí ze stavu 2 do PB stavu X, např. nejkratší: BX tedy: AAABX (podobně
      BBAX)'
    truth: 4
  5:
    pred: 2
    text: tyl pro každou třídu. mají podobu jen = 1/4 kn a 8 x = 1/4 2 x - y) parametry
      odhadneme pomocí maximálně věrohodného odhadu arg max p(X|M, &?) = arg max T
      p(x|m|m, 82) tzn. hledáme takové parametry MNO, které maximalizují funkci. pokud
      p(class) � p(class) tak bude vzor patřit do třídy 1 (class);je potřeba odhadnout
      střední hodnotu a rozp
    truth: 1
afe81d7a80453838440677e5234cabd3:
  1:
    pred: 0
    text: A;pomrzla ale;SXXABA;D3
    truth: 1
  10:
    pred: 0
    text: úplný, agresivní, orientovaný
    truth: 2
b6d73a834ec5aad1c8b3b05ccf9b43c0:
  1:
    pred: 2
    text: vyhovíme akci v postupnosti A a|B -> A -> B -> x
    truth: 4
  3:
    pred: 4
    text: 'grady - smrch: w(problem, 0, R) DFS: a (problem, 9;o)'
    truth: 2
  4:
    pred: 4
    text: 'xx1: D1 = E223, 453 D3 = 21, 43 D2 = 21. 108 FALKERY: D2 = 813 D2 = 848
      D1 = 853 x1: 455 v x 3. 12 4 V;D1 = 853 D2 = § 13 b3 = 543'
    truth: 4
  7:
    pred: 4
    text: model druhého rádu (R=2) sa pokuša k tátom napasovať parabolu x - model
      generalizuje protože, pre danú veľkosť parametru k máme dostatek dát;- aby model
      NE generalizoval potrebovali by sme buď k nastavit na vyšším hodnotu napr. 8
      � alebo mať 1 z V malý počet dát pro zvolené k
    truth: 4
bf4039f02a2e6a6e0a4ebb98806aaf90:
  6:
    pred: 0
    text: '- diskriminativy model - logistická regresia - generativy nodel - linearna
      regresia;- generativy model sa snaží odhadnuť pravdepodobnostné rozdělenie a
      na základě nebo klasifikovať. Používa apriuri. P(X|C) a P(C) vodí P(C|X). -
      diskriminativny na snaži na priamo prirodiť datu triedu P(C|X) generativy nepotřebuje
      toliko dát ale je meněj úspešny. Diskrimativy potřebuje vive dát a je prosnejší.'
    truth: 1
  12:
    pred: 0
    text: O, závisí na I, O2 závisí na I, a I2
    truth: 3
c7262a745405372830d5c0a21157e71d:
  2:
    pred: 4
    text: MAX;MIN;10;nebudou prohledávat úspora je;2
    truth: 4
  3:
    pred: 4
    text: greedy sedrd:;g=0, h=h*;DES igeo, neo
    truth: 2
  4:
    pred: 3
    text: 28/8 P2DXXXX x 63;IX/X XX xx;+ xx + V;RELXB 302 2/3 12 3.1153;V roku;xod3x2;D;D1,
      = 253 D2 = {13 D3 = {4
    truth: 4
  9:
    pred: 0
    text: učení s učitelem učení bez učitele posilované učení
    truth: 1
c9c4060106249fda11a3043c33e8d8a2:
  1:
    pred: 4
    text: 6;XAXA
    truth: 4
  2:
    pred: 4
    text: 'MAX;MIN;O;nepřehladáva;Max úspora: 2 uzly Hráč (super) vyberá mininezáleží
      aké ohodnotenie majú poslední dva uzly, keď ten prvý má 1, a to je menšie, než
      3, a 3> hráč nad faku maximalizuje, teda určitě pôjde fakt, kt. vedie k zisku
      5.'
    truth: 4
  3:
    pred: 4
    text: 'greedy search: a* (problem, 0, W);depth-first search: a* (problem, g*);
      0)'
    truth: 2
  4:
    pred: 4
    text: 'D1;1;10;3. D3: 23, 6, 9; 12) 3. D2 = L 3, 6, 9, 12, 25; 18, - 39,;D;XIX;X;x;x;D1=2
      = D= 1=1=1=1=1=2,-2,-2,-10,-2, =10,-2, = 10 kg DNB - D3 = 1, 24 = Da = 22, 109
      D3 = 21,2,38 = D, 2, 2, 2, 2, 10 5 - D3 = 21, 2, 3, 49 = D2 = 2, 4, 10 D) som
      zvolila 5, lebo najmainej obměřickí 8 D1 teoreticky môže byť tohotude z 22,3,
      n, Na Da 10) nemá uplyn.;D1= 254 D2, 22, ... 105 D3 = {1, 2, 3, 4};„ale čím
      je nižší je;tým ciac done edujedu'
    truth: 0
  6:
    pred: 0
    text: Generativny model gaussovský klasifikátor;Diskriminativny model lineárna
      regresia;-> výpočetne náročnejší výhodnější je vtedy, ale máme nějaké info /
      tušíme aké majú data rozloženie / hustotu počíta najsbór pravd. p(x|c) a p(c)
      a tak použije poe výpočet p(c|x) pomocou Bayesovho vzorca;· hladá deliacu hranicu
      medzi tředami dát � stačí mu menej dát;� odhaduje pravdepodobnosť p(c|x) priamo
    truth: 1
  7:
    pred: 3
    text: '- bodly sú trénovacíe dáta - priankol (výsledek regresie);polyn. regrese
      k =2;Body (� sú dané dáta, nachádza sa v nich aj šum. Model (piankas) generalizuje,
      lebo neprechádza pramo, všelkými bodmi ale iba přibližue. Generalizujeme aj
      pre to, že máme dostatek dát. Aby sme negeneralizovali. � buď by sme měřili
      počet trénovacích dát zalelo by sme vyšli stupeň polynómu;(rybvaté 3, dato zpôvodných
      výsl. parabola idebrian černej'
    truth: 4
  13:
    pred: 0
    text: Rozdelujú veku na tokeny (slová) a snažia sa predikovať aké slovo bude následovat.
      Na začátku je token START a na konci toheu OND. ARE, You řou,;START bYToU AKCE
      YOŮ
    truth: 3
  14:
    pred: 2
    text: Vhodné je aby ju dostával aj přebežne.;Ak by nedostával priebežne a máme
      nejaký velmi rozsiahle problém, agend vůbec necie a smenuje k splneniu úlohy
      � trénovanie môže byť zložitejšie, zaberá nac času...
    truth: 3
caa43cc5a94bfc67bf4e1bc08953c835:
  1:
    pred: 0
    text: So;BBAB
    truth: 2
  2:
    pred: 4
    text: MAX;MIN;2 u zly
    truth: 4
  3:
    pred: 2
    text: 'greety search:;freturn 03;h = h*;PFS: go Ereturn 1 3 h = kretura 03'
    truth: 2
  7:
    pred: 4
    text: K = 2, teda modelem je parabola. Model generalizuje, protože pohynom 2.
      rádu dobre popisuje "tvar" dát. Kdyby sme změnili stupeň na vyšší, tak by sa
      model pravdepodobně potřeboval alebo keby sme mali iné dáta, kterých tvar sa
      nedá aproximovať polynomom 2. ráda.
    truth: 4
  10:
    pred: 4
    text: Acyklický;graf;NORD1;WORD2;KORDJ;START;KORPM;KOROZ
    truth: 3
  11:
    pred: 0
    text: hodnoty vo "filtrech“ - kernel/jadro;počet vstupných kanálov - šírka jadra
      - výška jadra - počet výstupných kanál.
    truth: 4
  14:
    pred: 4
    text: Ano. vhodné mu dať odmenu ať pri splnení úlohy;Takto dovolíme agentovi experimentovat
      a tým sa učí nové;Keby ho odmeníme po každom kroku, tak sa nič nové nenaučí.
    truth: 1
cd3566ec8a54afb4c8f0ad4f22b7a48e:
  2:
    pred: 0
    text: MAX;MIN;D;66
    truth: 4
  6:
    pred: 2
    text: funkcie hustoty pravdepodobnosti generativní - ide a zistenie rozdelenia
      pravděpodobnost;- napr. gaussovský klasifikátor - nevhodné pre velké úlohy;diskriminativní
      - ideo zavadenie do triedy, nie pravdepodobnosti (aj bed napr. log. regrese
      pravděpodobnosti vracia) - nape. logistická regrese
    truth: 1
  7:
    pred: 4
    text: '- generalizuje, nie je preučený na trénovacie dáta.;- negeneralizuje -
      ak regresiu neobmedzíme na urč. stupeň polynómu;- pozn.: rovnový vstup přeučený
      na trénovacie dáta J ak obmedzíme regresiu na 2. rad, do určitej bude vždy generalizovať
      vó väčšine prípadoch (ak je dostatok bodov a majú nějaký rozptyl)'
    truth: 2
ce1e0e61482d8d323c9af9f6dddd0a6b:
  1:
    pred: 0
    text: opakování posloup. akcí ABX až do dosažení cíle;OB
    truth: 1
  2:
    pred: 4
    text: MAX;MIN;5;3
    truth: 4
  5:
    pred: 3
    text: 'třídy;P(c|x);posteriorní pravd. 2 Parametry: (C = množ. tříd) Kč ru - stř.
      hodnota N O2 - rozptyl = 1/4 s (xo-u) čeč reálná čísla odhad metodou maximální
      věrohodnosti (Pro které param. je věrohodnost největší?);X);apriorní pravd.;+;-
      odhad (gauss) pravd. pro danou třídu - data celkem podoba čítelných hodnot 0-1
      (pravděpodobností) pro každý ze 3 param P(c) a P(x) výpočet pravděp. na základě
      dat, P(x|c) odhadem parametrů.;výpočet pravděpo;data'
    truth: 1
  14:
    pred: 2
    text: průběžně, aby byl agent naveden
    truth: 2
cefd5c86a5a731b024525b6a26663cc8:
  1:
    pred: 4
    text: 'BS= 20, 1, 2, 3, 43 35, = 8 � 1, 2, 45 l 352 = 81,23 /14 � BSŽ = 223/3
      � = 213 IX � 3 BSP = 903;A ->;x;posloupnost akcí: A, A, A, B, X, X, X'
    truth: 4
  3:
    pred: 4
    text: 'greedy search:;g=0;h = h*;min;DFS: g = g h=0'
    truth: 4
  6:
    pred: 1
    text: generativní model - modeluje na stotu rozdělení pravděpodobnosti z jaké
      byla data generována. Tento model dále využívá z rozho dnutí u nových tat do
      jaké třídy patří. - Pro natrénování stačí méně dat. - Model může být negativně
      ovlivněn odlehlými hodnotami Diskriminativní model - snaží se rovnou najít rozhodovací
      hranici. funguje lépe na větších datech - vizito přetrénování;GM - Směsice gausovských
      rozložení D. M. - Lineární logistická regrese
    truth: 2
  11:
    pred: 0
    text: konvoluční jádra;počet vstupních - kanálů x počet - jeder x (hrana-jádra)
    truth: 4
  12:
    pred: 0
    text: 02;T2
    truth: 4
d5505c6e738d0a635e0ca6d2d07340a8:
  1:
    pred: 2
    text: PB;alčí Postuposť x [A, x, A, x]
    truth: 4
  4:
    pred: 4
    text: 2 34;5;7 8 minimum;12x;xxxx x x x;D, = {1, 2, 3, 4, 5} D2 = {2, 3, 4, 5,
      6, 7, 8, 10} 3 = 1, 2, 3, 4 �
    truth: 1
  7:
    pred: 4
    text: '- nakreslil nom dáta, které hali vytvorené nošumenou parabolou. Keďže máme
      lineárnu regariu druhého radu, dokue generalizuje tieho dáta, keďže jej odhadom
      hier paralola (3, x 3, x 3, 4) môže byť;- aby model negeneralizoval potuchovali
      by mne výžiť k tah, aby začal bližšie opisovať dáha, aby určal operfiktivy.
      Model sa bude mořiť minimalizovať loss funkciu (MSE) a dostatočně velké K mu
      dovolí podložiť funkciu dátomi - overfitting extrémny'
    truth: 4
  14:
    pred: 3
    text: Existuje problém, aby agent na svoj hrch vôbec dostal nejakú odmenu. V takove
      prípade môže učenie uviaznuť na mútvom hode. Rovnalo, led odmena príde po veľmi
      dhhom čase agent si nemusí byť idý kov, které akcie túto odmenu drzal. Preho
      je vhodné dávať odmeny aj na vhodné za cieľu približovanie a správamie Moře
      ustať problém, kedy je agent odmeňovaný kompromise, které priamo nevedne k cieľu
      (napr. agent je odmeňovaný za dosiukutie nonej obrovsky � agent rozehnutý na
      pareraní TV). (vídenie) Preto je nutné vhodne zvolit, za akci mimo čela agent
      řeka admenu.
    truth: 4
d7aab42d4569ee5a25f14e40629baac8:
  12:
    pred: 4
    text: O;O, závisí nad Oo a I, Oe závisí nad O, a I2
    truth: 2
  13:
    pred: 0
    text: Drobnej writes test;euchatér;Š Ondrej píše písemnou;1. Jenodór dostane naxistuj
      context a vetu vjazyka preloží prvé slovo 3. postupne nový kontext dolej 4.
      vrucia sa do 2 ným nepreloží vetu
    truth: 2
  14:
    pred: 4
    text: je vhodné aby dostal priebežne odmenu;Tebo sa učí že postupuje správným
      smerom. do cielu;propro závodávt kde dostane odmenu na základe prejdenej szdialenosti
      nie len či ukončil závod;g;može sa stať že sa poevší na zlý parameter [ (napr.
      bude pokračovat aj potom čo závod skončil) tebo prejde väcšiu vzdialenosť
    truth: 4
d93e16d9eedd00e09bdea8e2562b9e78:
  1:
    pred: 0
    text: o;ApRESIDENT VES S = EX, A, Y
    truth: 4
  2:
    pred: 4
    text: B= 0;MAX;8;1919;129;10;MIN;Nebudou prohledávat
    truth: 4
  3:
    pred: 1
    text: 65;DFS;� h= hľ h = podle;- return 0;;fakt off- (uzel) k return 1/uzel. depth
    truth: 3
  4:
    pred: 4
    text: 3x27;Dr P2/0;S;2 J;3 O;4 x;XXXIX;5 110;x;6;X;x;7;X;x;899;x;x;X;X;10;X;3/XIX
      XIO;X;x;X;x;D1 = 2 BANATI D2 = {13 D3 = {43
    truth: 4
  9:
    pred: 0
    text: Strojové učení Neuronové sítě Prohledávání stavového prostoru Gnozeologie
      AI (protože kdo by se nebál singularity)
    truth: 4
  14:
    pred: 0
    text: Průběžně, odhad optimální trajektorie jinak optižné odhadnout (roste exponenciálně);-
      nevýhoda - při nesprávném nesprávném nemusí dostat do cíle (lokální maximum)
      nacenění
    truth: 4
da6d7974b094aff71a711f08f4b890d0:
  1:
    pred: 0
    text: A;Pro libovolný stavu posloupnost A_bax přiveze k stavu o s tím, že posloupnost
      budeme muset DB zapomovat pokud ještě nebo souhlí cílový stav;DA
    truth: 1
  5:
    pred: 1
    text: Potřebujeme odhadnout štřední hodnotu M a stondartní odchylku 5. zboží hodnoty
      reprezent setnina reálným číslem. Použijeme maximální věrohodnostní odhad těchto
      parametrů. Pod pomocí těchto parametru dokažeme ZŠISA potřebné data pro brejesovský
      vzorec;P(class|obs) =;p(obsluhass). P(C|X|OSS);P(obs);6. Ke stavbě klasifikátoru
      můžeme využít generativní model nebo můžeme použít nebo můžeme použít model
      trénovaný diskriminativně. V čem se tyto dva přístupy liší? Uveďte konkrétní
      příklady modelů/klasifikátorů pro oba přístupy. Jaké jsou jejich výhody a nevýhody?
    truth: 1
  9:
    pred: 1
    text: '- strojové učení - hluboké učení úspěšně - počítačové vídení rozpoznavání
      obrazu.'
    truth: 3
  13:
    pred: 0
    text: vstupní text se zovoduje se do torenu. � vznikní kontextní věktor Pak procházím
      slovo po slovu a počítám p-ost 50 me slovo patří na dané místo. P(toren) � vy
      Vyberu slovo s největší p-osti, davom ho na výstup a sílam do kontextu pro další
      slovo. P-ost nastetujícího slov a počítam s ohledem na předmozi slova p(woren)
    truth: 4
  14:
    pred: 0
    text: Ne, to není vhodné. V tonovém to případě agent bude se velice pomocí se
      učit (skoro vůbec) Pubežné výsledky busou směrovou genta ke správnímu řešení
      a urychluj to ceny proces Ale bez odměny v cíly, agent muže ponořit do lokálního
      stavu, který není cílový ale však dostane v něm odměnu.
    truth: 4
de9177b9575ef89d4b2f4e2c3a9d3cb0:
  7:
    pred: 2
    text: ralizoval?;- výsledný regresný polynóm nekopíruje presne trénovacie dáta
      keď mi půda nějaký nový bod, nám ho zaradiť. Ale je to ten polynóm druhého rádu,
      tak ak mám dostatek veľa tr dát, tak sa nemůže stať, že bude prechádzať cez
      jednotlivé body teda argitting. - aby model negeneralizoval, tak je třeba dosiahnuť
      argittingu - polynóm bude prechádzať cez (všetky) body. Dosáhnem to napr. zvýšením
      rádu polynómu.
    truth: 4
  10:
    pred: 0
    text: nemůže byť v nich cyklus;w,
    truth: 2
  12:
    pred: 0
    text: O;F2-
    truth: 4
  13:
    pred: 0
    text: Na začiatku majú nejaká množinu slov, kterými začínajú vetu podľa nějakej
      pravdepodobnosti. Takto vygenerujú slovo w, Následne sa dalšie slovo generuje
      podľa podmienený pravdepodobnosti P(w2/ W1), potom tretie P(w2|w2, w2, w2) atd.
    truth: 3
  14:
    pred: 0
    text: taký, že nejlepší výsledek může ležať při velmi zlých výsledkech a pri přizbožných
      odmenách tam chcieť íšť nebude.;Ak dám průběžné odmeny, tak natrénujem rychlejšie.
      Problém může nastat
    truth: 4
e3d02a7e3b33f83005dc53baa3b1f72e:
  2:
    pred: 4
    text: MAX;MIN;88;Maximálna úspora za 2 uzly.
    truth: 4
  4:
    pred: 4
    text: XI;X2;1;X;Ihr;2;3;5;6;X;7;X;8;X;X;10;X;x1 E 33, 953 x2 c k 1,239,516,73,103
      x3 c q 123,93;3;x;X;x;x;X;x
    truth: 4
  9:
    pred: 0
    text: '- strojové učenie - počítačové vidence - spracovanie reči, zvuku - zpracovanie
      textu - spracovanie, klasifikácia a predikcia vzorov a udalostí v EEE predikná
      počasia - extrakcia znalostí'
    truth: 4
  10:
    pred: 0
    text: konvolučná vrstva;- nesmí mať cykly (RNN nemajú oficery) - označené vstupy
      a výstupy - označený typ vrstiev;2);- nemá cyklus;- má výhled - ale
    truth: 1
  13:
    pred: 1
    text: 'Modelují funkciu P(wx, wz, wz..., won) = Tiadel P(woj-y, wird, ..., was),
      teda generují slovo po slove a počítají, aké je najprvdepodobnějšie slov na
      základě vstupu a predchádzajúcich slov. Postop: 1. Eukodér zaháduje vstupná
      sekvence do kontestového vektoru. 2. Tento vektor sa dá na vstup spolu s špeciálnym
      slovem START. 3. Vygeneruje za slovo. 4. Toto slovo sa dá na vstup a vracím
      sa na krok 3, až kým mě je vygeverované špeciálne slovo reprezentujíce STOP.;Dekadér
      transformuje vektor reprezentující slovo na slovo.'
    truth: 4
  14:
    pred: 4
    text: Posilované učenie zieši problémy, které upoznáme odpoveď, ale vieme posádiť
      správnost (napríklad protesn folding). Zedže nepoznáme odpoveď, tak cesta k
      nej už vůbec nie, a teda je nemožné dávať odmenu za správnou cestu, kterú nepoznáme.
      správa Ale by sme cestu poznali, je otázne, či je posilované učenie správa cesta.;Ak
      by sme chceli priebožně vyhodnotiť správnosť riešenia, tak je rizika že NN za
      zasedne v nejakom lokálnom minime, nebo nemá motivácia hladať správne ciešenie.
      Ale mohlo by to spôsobiť rychlejšie trénovanie. Či je to vhodné teda závisí
      od konkrétnej úlohy.
    truth: 4
e3fb369e536a528a79919619d3ccb301:
  3:
    pred: 4
    text: greedy;g = return o h = h*;b(n) = g(n) + h(n);D;� zložitejšie, keďže ná
      íst najprv dole.... nie som si istý či by to bolo validné, ale niečo na štýl
      g = - 1x len (path) h = 0
    truth: 4
  7:
    pred: 2
    text: '- ak by negeneralizoval tak by prechádzal jednotlivými bodami, nevedel
      by "zavšeobecňovat'
    truth: 1
e3fcfce792cba2bd9b1f688e09b8636d:
  1:
    pred: 0
    text: XAXAX
    truth: 4
  7:
    pred: 0
    text: generalizuje - snaží se proložit všechny body - overfitting, je potřeba
      upravit parametry
    truth: 1
e48e0794dca4b5b891f98b423b16fbe9:
  1:
    pred: 0
    text: 'Betreb: 0 1234 ná 4 nebo A není 12 A 2 8 x;012 34;B 134 B 34 B;3;A;Možné
      riešenia: AABX, BBAX;oj;z'
    truth: 4
  2:
    pred: 0
    text: MAX;MIN;10;9;608
    truth: 4
  3:
    pred: 4
    text: Greedy search = a* (problem, 0, h) DFS = a* (problem, 0, 0)
    truth: 2
  9:
    pred: 0
    text: a neuron - basel neuronové svate, r 1984;Založené na prehlídávaní stavového
      přestavu/matematických modelech
    truth: 2
  10:
    pred: 0
    text: Musí to byť konkrétní Ug - váhy;orientovaný grat;px2 -> (60) - (politica)
      -> out;(ReLU)
    truth: 4
  13:
    pred: 2
    text: Tisto modely generují vety na základě postupného generovaná tokanov (například
      slov) na základe dopoust vygenerovanej sekvencie. tzn. že modeluje p(dělíš taken/wo,
      was ) počem Wofillance sú vědky předchádzajúce vygenerované tokeny. Ako prvé
      nám kontextovo zakóduje vstup dekodér, z kterého enkoder dostane vektor „exbodem
      dáme štastovací takou (napr. start) a dále tento eukodic postupuje generuje
      tolary, ale je popísané vyššie. Dekorace funguje na přinášce generovania vektorových
      příznakové (produkce taken) na základě kontextu, v ktorova se nachádza, tiefo
      natrénované vektory sú následuje získavané z LVT tabulky. Ak máme vektory vstupnej
      vcty, tátovate sa zakóduje pomocou objasnených rekurentných vrstven do vektoru,
      který jet stypu pre eukodér 14. Je při posilovaném učení vhodné, aby agent dostal
      odměnu jen při splnění úlohy, nebo i průběžně podle toho, jak se blíží splnění
      úlohy? Proč? Může to naopak způsobit nějaké problémy?
    truth: 3
e89c2ef8845bc8936dfb0dced67540b5:
  3:
    pred: 0
    text: aby simulovala greedy search a depth-first search (DFS)?;greedy wazek se
      orientuje pouze podle kewidity tedy g =0, k = ohodnocení heuristiky daného stavu
      (cena do cíle) (tady je to asi outopat funkce kit?);- je neinformovaná metoda,
      neorientuje se tedy podle žádných hodnot (využívá zásobota) (zde opět předám
      že lit a je zná hodnotu � nastaneme tedy h = nh + a g = - g* � začínáme s vysokou
      cenou h (jsme daleko od cíle) a čím více se vzdalujeme tím se cena snižuje (-gx)
      � algoritmus má tedy tendenci procházet co nejvzdálenější uzly, tedy chovat
      se jako DFS.
    truth: 3
  4:
    pred: 4
    text: XI;12;2;3;XXX.;4;X;6;7;89;10;XXXXIX;D1 zůstane nezměněná. D2 je omezena
      pravidlem 3X2> X3 na D2 = {4, 5..., 103 D3 je omezena pravidlem na D3 = 21,
      2, 3, 45
    truth: 0
  14:
    pred: 0
    text: hlavním cílem je zde danou úlohu splnit -> tedy dát odměnu při úspěšném
      splnění problému (je jedno jakým způsobem byl doražen) pokud jsou ohodnocovány
      malé hroby může to v krátkém horizontu mít pozitivní následky, ale ve výsledku
      nemusí být problém vyřešen což jde proti celému smyslu na druhou stranu může
      toto postupné vyhodnocování vést k lepším žením -> více efektivnímu než při
      ohodnocení výsledků na celém problému
    truth: 4
eae9dd0163ad1161a9ef65474a7ad30a:
  2:
    pred: 4
    text: MAX;MIN;DD Morimální úsporu jsou 2 voly (už obrázek), které jsou přerávy,
      protože MIN jistě už zvolí horší řešení, než jde z levého podstromu.
    truth: 4
  3:
    pred: 3
    text: 'greaty mach: ignoruje cestu, pro príle kernstily, tj: g = landa puth 0
      k = h*;DFS:;+ chmely po interesci D+ E23, 4, 59;D2 = {1, ..., 10} R = 21,'
    truth: 2
  7:
    pred: 4
    text: Nahodil jsem trénovací data vycházející z funkce p - x dochovává o zimu.
      Vzhledem ke stupni K=2 se tady regrese dokáže tuto funkci dobře hmot a v případě
      vidání nových dat, model bude stále dobře odpovídat, tj. generalizovat. Pokud
      by data odpovídala funkci, co není možné pooddovat ve tvaru y = w1 + w2 x w2
      x + b, pak by vodel negeneralizoval. Napríklad pokud by trénovací data pokácela
      z funkce y = sinx x na intervalu LO, F2, podal by se nejspíše probodu naučil,
      ale již by neparalizoval voják pro interval 20, 25 %
    truth: 4
  8:
    pred: 0
    text: P(naložen) = 0,2 P(pozitivní (nakonec) = 0,9 P(zdravý/poutumé) = 0,1 P(poutní)
      =?;(soutvory) / poutovné) =;P(peritivní) P(nohan / portrétní) = 1-P(zdravý)
      pouluvní z;plochový, pozitivní;= 0,4;P(rdsový) = 1 p(vichrin) = 0,8 P(pozitivní
      skl vchodu) = P(vekvin) P(vniterní) = P(pritrní) neuronovén) P(volovan) P(nahradí
      poutníci);poutovní). P(vektorán / poctivní);0,2;9, 9.;0,0;P2
    truth: 4
  9:
    pred: 3
    text: -;hlouchá manélce inteligence - prohledávání kavalerie bored umuzované přírodou
      - rohoumé na verovilě - neurovové sítě stropové viení - včení s vritelem vs
      bez vrtale. posilované viení
    truth: 4
  12:
    pred: 2
    text: ON;pojídání stář;On závisí na I, a poráběním stavu O2 zákesí na I, I z a
      pozáběrnim stavu
    truth: 4
edfb9f97b5b92200783594b400a493aa:
  1:
    pred: 0
    text: 'řešení: A A A B X;(alternativa BBAX)'
    truth: 4
  4:
    pred: 4
    text: 1.793,43;1,22,34 l;1,213 - 1169 � 1,2;6 35X3;2) 3x27 X3;ex;D1 = {2, 3, 4,
      5} D3 = {1, 2, 3, 4} D3 = {1, 23 D2 = {1, 2, 3} D2 = {2, 3, 4, 5} D2 = {1, 3,
      nedostačující podmínky D3 = {1, 2} k dosažení jednoznačných hodnot
    truth: 0
  7:
    pred: 4
    text: pokud by se nacházely nějaké extrémní hodnoty pak by model nemusel vyslibo
      trenel většiny dat;Model vystihuje trend růstu dat, je pravděpodobně, že i pro
      další data bude model odpovídat.;:;negeneralizuje
    truth: 2
  9:
    pred: 0
    text: strojové učení, zpracování obrazu, data acience
    truth: 3
  10:
    pred: 0
    text: orientovaný acyklický graf;8 -> X -> IRdu) � 3;Softmax;peka
    truth: 4
  12:
    pred: 0
    text: 17;12;VA 1;VIII
    truth: 3
  13:
    pred: 3
    text: Tyto modely se skládají typicky se 2 části - eukoděr a dekoděr;enkoděr -
      zakóduje vstupní sekvenci do vektoru příznaků, který slouží jako jeden ze vstupů
      dekoděru dehoděr - generuje výstup po jednotlivých takenech, výstup každého
      kroku je vstupem následujícího - na začátku bere z enkoderu vektor příznaků
      FV a token START, při dokončení sekvence generuje token END;EnD;Inspekce IV
      Svatop.;(strana);dekoděr
    truth: 3
  14:
    pred: 4
    text: Pokud je k dosažení cíle potřeba velké množství akcí, tak odměny pouze za
      dosažení cíle mohou být nedostačující, protože se nedá přesně určit, které akce
      k výsledku nejvíce přispěly. V takovém případě je dobré nějaké odměny zavést
      i v průběžně za nějaké významné milníky. Na druhou stranu, pokud budeme agenta
      odměňovat za každou blbost, co nám přijde správně, tak se agent sice naučí úlohu
      řešit tak, jak chceme my, ale přicházíme tak o výhodu posilovaného učení, kdy
      agent sám přijde na nějakou optimální strategii pro řešení problému, která může
      být mnohem lepší, než ta naše
    truth: 4
ee4b7041a56afa5dba176c9bb60a631d:
  1:
    pred: 0
    text: 7 AxBx;x Ax Ax Bx;r;S
    truth: 4
  4:
    pred: 4
    text: z;3;10;Listopad;D.;D2;x;O;x x;x;X;X;X;O x;X X;x X;X x;X;x;33;x;x;X;8;x;X;X;x;+;X;D1
      = {5};= E13 D3 = 243
    truth: 4
  9:
    pred: 0
    text: Tady, if else neuronly silná a slabá, špiculinová generat;6 0 1.) Teóni
      hier Strojové učenie
    truth: 2
  14:
    pred: 0
    text: Zabraňuje to stagnácii, pretože mu to stále dám mstiváciu ísť dálej. Môže
      to spomaliť nájdeme riešenie ak odmeníme, bad patho
    truth: 4
ef8bd6fc8702840dba8cc2d5d44d2119:
  2:
    pred: 4
    text: MAX;MIN;O;S;vždy označení x nebudeme prohledávat úspora 2 verby
    truth: 4
  5:
    pred: 3
    text: třeba odhodnou střední hodnotu a kovarianční matici k. u = [*I) - vektor,
      který vdává střed gausovky X - udává "roztažení guesark v davém MŽ = EX, ý)
      směru a K„2 karelaci dat zápasnou či počítání nebo rádia. - všechny z to parametry
      můžeme vypočítat z datové sady. Celkově je pro každou třídu potřeba 6 parametrů,
      celkem 18.;Pro každou třídu bude pod tr K čtyřp
    truth: 1
  7:
    pred: 3
    text: 'model generalizuje v případě, že pracuje správně nejen pro Erenovací data,
      ale i jiná data, která dostane. Pokud by negeneralizoval znamená to, že by pracoval
      správě je pro data trénovací.;X;následující - model generalizuje neboť pokud
      by přišlo nové dato, tak by se nacházelo v blízkosti přímk. k ratas, platila
      pro všechna příchozí data;Na následujícím obrázku negenealizuje:'
    truth: 2
  8:
    pred: 4
    text: pozitivní - pak, negativní - veg, nakažený - nak, zdroj - zdrav;(nak) =
      20% nakl ney počí ľak) = 90% -> P( P(poslední řekou) = 10% stav pár zbraně pokl
      zdrav (par I nak);= 10%;P(YB|MA);P(nak (par) = P(nak). P(poz Inak);P(pur) P(poz)
      = P(nak). P(P) par (nak) P(nakl poz);0,2;s;0,9;0,9;0,2
    truth: 2
  9:
    pred: 0
    text: Strojové učení, Počítačové vědění, i urovnané sítě...
    truth: 3
  11:
    pred: 3
    text: počet výstupních parametrů);s
    truth: 4
  13:
    pred: 0
    text: 'Tyto modely generují výstupní sekvence na základě pravděpodobnosti dané
      posloupností slov. Tudíž pro jednotlivcí slova bude vypadat výpočet pravděpodobnosti
      následovně: P(w|w1 w1) P(w3|m, my) P(w|w|w|w) w2 w sw �'
    truth: 3
f3ae7233a5cdc2f3d8fb9c4e75e21814:
  1:
    pred: 0
    text: X A se vždy dostanu sem;Tedy ale;4xA, B, X/4 A; B;;Počet akcí A je libovolný
      neboť gytlém nad stavem 2;Provedo 3x alcí A, z libovolného stavu se dat dostanu
      do 2) Provedu akci B 1 a následně akci x
    truth: 4
  2:
    pred: 1
    text: Musím vyhodnotit;MAX;MIN;2;o;Úprava 2 versy;Ugaře zde uspořim B - uzly.
      Levou větev musím vytvořit celou. Prostřední tabě Jakmile uvidím že v poslední
      větvi je ohodnocení - 5, nemusím dál hodnotit poslední dva úzký
    truth: 4
  11:
    pred: 0
    text: Konvoluční filtr
    truth: 1
  12:
    pred: 4
    text: 01 zavisí na I, 02 zavedeno 72;t7 I.;PT 72;72
    truth: 3
  13:
    pred: 4
    text: 'Výstupní sekvence se generuje jednak na základě aktuálního vstupu. A jednak
      na základě jež vygenerovaného výstupu.;Pro pravděpodobnost vygenerovaní slov
      W1, W2 .. W n je tedy vydán vzorec: P(w2, w2, wa) = II P(w|lwi-, wisz.. w1)
      Je tedy výňata podměnená pravděpodobnost na základě vygenerovaných slov. Rovnosobeno
      pak: P(w2 s, W2... W2) = P(W2) P(W|W|w2)...'
    truth: 3
f45027d0227e0535990c00bf0827e2af:
  1:
    pred: 0
    text: z
    truth: 4
  6:
    pred: 1
    text: 'diskriminativní: rovnou se snaží odhadnout, do jaké třídy příchozí dato
      patří p(c|x) bez odhadování opičné podmínění pst. Je podstatně jednodušší a
      rychlejší. Zajímá ho pouze klasifikační hranice mezi třídami, nikdv celé rozložení
      tříd Stačí mu tedy určit pouze křívku reprezentující hranici, ale hůře se taková
      křívka hledá pro slúžitější modely u různě „propletených“ datech z různých tříd.
      - příklad: logistická lineární regrese'
    truth: 4
  10:
    pred: 0
    text: a yklický, orientovaný grat; může mít více výstupů;STM;- konservatoř;.;25
    truth: 4
  12:
    pred: 3
    text: BANEA;OLIER, I1 ONFI Už;vovati
    truth: 1
f854b378222faa337e5645aacaecd948:
  6:
    pred: 0
    text: vstupných parametrov Gen. model - modelované rozloženie Gaussovský klasifikátor
      môže mať priveľa zbytečných vstupných parametrov priamo výstupných tříd Diskr.
      model - modelované rozloženie lineárna regresia naraztá vesnosť s množstvom
      dát
    truth: 1
  11:
    pred: 2
    text: váhy jadra rozmezy jadra x počet filtrov
    truth: 3
  12:
    pred: 4
    text: O1 - vstup I1 + ľubovalý vstupný vektor 02 - vstup 2 + výstup 01
    truth: 2
fd4c95ac222b1b1ce4780a446a0662ff:
  4:
    pred: 4
    text: Dr. D2 D3;xx x XX XXXXxxx O x x x xxx XXX XXX x x COXXXX x XX;Dy = {53 D2
      = {13 D3 = 243
    truth: 4
  10:
    pred: 0
    text: '- nesmie byť cyklický;stavy;tva);vrstva?;vstup;IVSTUP'
    truth: 3
  13:
    pred: 0
    text: Mon) SYn, / whilway was;- každé slovo, čoberieme, tak berieme s pravdepodobnosťou
      aj všetkých prodchá dzajúcich slov zo sekvence
    truth: 2
fdb0df15e7ad924fe4403d60cca91fc6:
  13:
    pred: 1
    text: Sden;Tieto modely generují jednotlivé subsekrencie v;podobe slov, kde potom
      autoregresná funkcia vyhodnotí vygenerovaní sekvenciu a na základe za původního
      vstupu nejv regeneruje dalšíu sehrenciu slov.
    truth: 1
  14:
    pred: 0
    text: Príliš časté odmenovanie môže mať za následok, že agent sa nenaučí nic "nové",
      resp. len to, 2 čomu ho programátor do vedie. Naopak pri odmeňovaní len za dosiamotie
      cieľa sa agent nemusí naučiť nič ak je cielový stav vzdialený, mými slovami,
      agent nebude vedicť čo má robiť.
    truth: 4
