03ba496bc2d137a3a094d1f420246958:
  2:
    pred: 4
    text: MAX;MIN;360
    truth: 4
  6:
    pred: 4
    text: p (nakazeny) p (nakazeny) =0, 2;p (per (nakazeny) = 0,9 p (reg /nenakazený)
      = 0,9 p (vor) = ? p (nenakazegy) = 1 = 1 (nak) = 0, 8 p (poz (nevak) = 1 - p
      (neg(nenak) =0, 1;p(poz) = p(poz, nakazeny) + p(por, nenakaz p (par, nak) =
      p (nak) . p (poz / nak) = 0, 18 p (poz, nenak) = p (nenak) p (poz / nenak) =
      0,0;(p (poz) = 0,18 + 0,09 =0,27
    truth: 3
  10:
    pred: 4
    text: 'Gradient je vektor parciálnych derivácií stratavý (loss) funkcie podľa
      parametru modelu;w uvdáte sváh: Nová hodnota váh vznikne odčítaním násobku gradientu
      chybovej funkcie (násobot je daný učiveou konstantou 2) od starej hodnoty váh.;öder
      L (D, w);Trénovanie neurónových sietí možno práve v únoru váh tak, aby minimali
      hodnotu funkcie. V případě, že je update vich neuvedený po LOSS dovednou prechode
      nad celým datasetem, ide o gradientý zastup, ať ho me časti datasetu, jedná
      se o mini-batch / stochastic gradient descent.'
    truth: 4
  11:
    pred: 2
    text: '3x3;5x5;kanála 1. athiásie;aktivizační many : 5x5 16 vstupného obrázku:
      7x 7x35 kanály vstupu'
    truth: 4
  13:
    pred: 3
    text: Attention je vrstva, která priradí váhy jednotlivým prvkem vstupnej setupencie
      (iným než práve mrazovánový vrst) na základě podobnosti medzi query vektorem
      spravedávaného parku, tey vektoram iného prvku a jeho valne vektorovi S týmito
      váhami a prvkami následne provedie vážený súčet. Základná myšlienka je bojovať
      vzatí vanisking gradient problému Attention je schopný detekovať závislosti
      medci prukami, a to aj nadlíš vzdialenosti. Priradená váha = sila závislosti.;Použiva
      sa napríklad vci strojovém vceklade, macnaní textu, v jazykovýc modeloch, otď.
    truth: 4
05417b2097b772d46de8a5f0353320e1:
  10:
    pred: 2
    text: Určuje smer v ktorom funkcia najvice klesá - v NN nám určuje, kterým smerom
      I v sme mali upraviť naše parametry aby nám lepšie klasifikovali dáta;VANN sa
      gradient používa pri vyhodnotení loss funkcie � na základě vypočítaných hodnoť
      gradientu sa upravujú váhy modelu, a tak prebieha samotné učenie modelu
    truth: 3
  13:
    pred: 3
    text: 'Attention - berie v potaz dáta, ktoré sa nashádzajú v jeho okolí (papr.
      pri spracovaní slov berie v potaz slová ktoré sa nachádzajú napravo a nalavó
      od daného slova narozdiel od rekurentných vrstiev nie je závislý iba od jeho
      predeslého vstupu (slov čo za nachadzajú před daným slovem).;z;Využitie: odhadovanie
      slova, ktoré sa má nachadzať uprostred textu na základě okolitých slov, určovanie
      slovných druhov -> používa sa aj v Gethub Copilot (automatické doplňovanie kódu)'
    truth: 2
05bb8bab96cd66903de8541d992ec881:
  1:
    pred: 1
    text: R;Pamatuji si, že 56 je řešitelé;IND P veřejitelství řešitelé;německém řešit;DT2;Pokud
      si pamatuji, že některý uzel je řešitelný a později ho objevím jako následníka
      OR uzlu, tak nemusím řešit ostatní následníky tohoto OD uvln.;nevim řešitelny;větším
    truth: 1
  2:
    pred: 1
    text: MAX;MIN;5606 Ax;Mik
    truth: 4
  3:
    pred: 4
    text: 5 (50) l (6) = 40 h(60n) -0
    truth: 4
  4:
    pred: 2
    text: 1234567 9 10;X52x11;x 3 x 2;XI X2 XII. XI 83=8;* 3) XXXxxx x XX xxxxxx xxxxx
      (9);xxxx e xx;x32341 x3 641 = 7 157
    truth: 3
  5:
    pred: 3
    text: G;rozložení prav. pro jednu i druhou třídu. Každé z nich je popsáno prametrem
      pro střed (3 dim. vektor) a kovarianční maticí (3x3). Tyto parametry odhadneme
      pomocí Max. likelyhood odhadu. Dále jsou potřeba 2 (nesp. 1, druhý je doplněk
      do jedničky) parametry pro apriorní p. tříd. Ty jsou buď určené, nebo se odhadnou
      zdat jako P(c=1) = 7° C) a P(c=o) = 1-P(c=1), kde nax je počet trén. dat st.
      1. Celkem je potřeba 2 - (3+3, 3) + 2 nebot = 24 nesp, 23 neál. čísel.;Využijeme
      Bayesův vzorec P(c-1|x);P(x|Mon) P(C=2) P(x|Max);Uk.;je g. ros. prav pro tř.
      t
    truth: 3
  8:
    pred: 2
    text: Generativní - model předpokládá, že data jsou generována z nějakého rozložení
      prav. a snaží se naučit parametry těchto rozložení - nevýhoda - využívá více
      parametrů výhoda - lze použít ke generování - např. gaus. klasifikátor diskriminativní
      - modeluje přímo posteriorní pravděpodobnost p(c=1|x) - výhoda - méně parametrů
      - např. logistická regrese
    truth: 3
  9:
    pred: 2
    text: schopnost učit se dovednosti, pamatovat si znalosti -I řešit dříve neviděné
      problémy;Nemusí vyhazovat všechny
    truth: 3
  10:
    pred: 2
    text: parciální derivace chybové funkce podle vektoru vah používá se při hledání
      minima chybové funkce např. metodou gradientského sestupu
    truth: 4
  11:
    pred: 3
    text: vstupní obraz 7+7 pixelů výstup 1. vrstvy 5x5
    truth: 4
  13:
    pred: 1
    text: Používá se například při zpracování jazyko-např. překlad
    truth: 1
0cab81d7505839d36bcf11ca74e5baf6:
  2:
    pred: 4
    text: MAX-BIR;MIN JO, 21-3;O 6;G;Š ořezané větvě;Předpokládejme, že algoritmus
      začíná vždy levým podstromem. V tom případě na uspořádání levého podstromu nezáleží.
      V pravém podstromu je naopak nejlepší mít uzel s hodnotou - 3 v levo a tím pádem
      bude MINLMAX a zbylé větve je možné ořezat.
    truth: 4
  4:
    pred: 4
    text: 2 XIX X X X XIX IX;3;4/5/6/7;0 X;X X X X x IX;+;x;X2;X;x;x;x;8;x IX;o;x
      10;x;10;x;X;x
    truth: 4
  5:
    pred: 2
    text: 'Potřebujeme: -2 Gaussovské rozdělení - pro každou třídu jeden jednání;-
      2 apriorní pravděpodobnosti - opět pro každou třídu jednu a nebo pouze 1 pravděpodobnost
      a druhou lze získat jako k (x|=1-6|X);Gaussovské rozložení je reprezentováno
      rozptylení a střední hodnotou Apriorní pravděpodobnost číslem v rozmezí 0, 17.
      a získává se podílem dat v dané třídě /celkový počet.'
    truth: 0
  7:
    pred: 2
    text: 5;Na obrázku je možné vidět funkci modelu, který negeneralizuje, jelikož
      zjevně není schopen modelovat růst hodnot v rozsahu 0-5 na obou osách. aby byl
      model schopen správně generalizovat tato data, musel by se zvýšit řád polynomiální
      regrese na alespon 3. Tento model by šlo nazvat jako underfitted. Pokud bychom
      naopak zvolili příliš vysoký řád, mohla by nastat situace, kdy bude tzv. overfitted.
    truth: 2
  8:
    pred: 2
    text: Generativní model je založen na určitém pravděpodobnostním rozložení (např.
      normální rozdělení). Při trénování se zjišťují potřebné parametry rozložení
      pomocí metody ML - Most Likelihood, kde chceme maximalizovat součin pravděpodobností
      se zvolenými parametry. Dále se využívá Bayesova vzorce k určení pravděpodobnosti,
      že daný dato spadá do dané třídy. (Příklad Gaussův klasifikátor). Model trénovaný
      diskriminativně využívá např. logistickou regresi. Pomoci ní se určí hranice,
      podle kterých bude klasifikátor pracovat.
    truth: 1
  9:
    pred: 3
    text: Dokáže reagovat na prostředí, učit se z předchozích kroků, vyhodnocovat
      kterou akcí se nejvíce přiblíží k cíli...;Jsou různé druhy agentů a každy splňuje
      nějaké aspekty. Rozhodně však nemusí vykazovat všechny najednou.
    truth: 2
  12:
    pred: 2
    text: Obousměrná vrstva má k dispozici informace nejen z předchozího oshodování,
      ale také z „budoucího“. Při generování textu má například kontex o řetězcích
      generovaných před i po daném řeštěnci.
    truth: 2
0e33e15598be65ed678dd18f9f2bff79:
  10:
    pred: 2
    text: 6 radient je vektor parciálních derivací (míra růstu);Při počítání loss
      funkce Pro aktuální hodnotu spočítám gradient objektivní funkce -> iterativně
      počítáme gradient a pohybujeme se proti směru růstu až najdeme O gradient (minimum
      loss funkce)
    truth: 2
1069b3fc4fb47f279610ef035bf163d4:
  12:
    pred: 3
    text: 'předchozí;následující;obou - dopředné složitější, časově náročnější - výhody:
      efektivnější předávání;i zpětné propojení;of vrstev'
    truth: 2
  13:
    pred: 3
    text: '- výpočet pravděpodobnosti výskytu nějakého znaku např. zpracování textu
      - může být rychlejší, přesnější než rekurentní vrstvy'
    truth: 1
13a036ceabe98bc5840a382a0558bafc:
  2:
    pred: 4
    text: MAX;MIN;660;MAX;MIN;6;č;D;o
    truth: 1
  3:
    pred: 2
    text: 2;b(4) =
    truth: 2
  5:
    pred: 3
    text: 'jsou potřeba parametry: ja... střední hodnota poradny rozdělení naduto
      rozdělení, na 1/2 x y = 1-2 (x) = su pravdy jen zprazdním jednu českým číslem
      pravdy lze odhadnout naučení šerohodnosti: na [py] = E= O je odhadnaný a ono
      je horkou mezi svojí - popřát pravděpodobnosti, kam nový vzor patří, spoutání
      - jsou potřeba z probry: jen... střetní hodnota, skupiny sektor z řeckých čísel,
      že je hodnotící natie 2x2 (4 radšú část), parametry lze odhodnotit netudou nacionální
      šerohodnosti P(x|c) � � porady použijeme pro výpočet hudby pravděpodobnosti
      TLA apriorní sociálního rozdělení, kterou pak lze použít v hubičce pot p(x|c)
      . p(c) s Rogesovým provedlem k výpočtu pravděpodobnosti, kur patří svoj;v;p(c|x)
      =;P(x) - hustota'
    truth: 2
  7:
    pred: 2
    text: správně odhadnout hodnotu pro nový vzorek dat pro generalizaci je sobě předt
      něco třemanět dat, za kterých by se mohl model učit a takhle přijať by mohla
      pouze svou žílu polynomu na 1 (regresní příští příklad);- málo tvrzovanost dat,
      kvůli tomu model vyexercizuje, což zároveň, že přímo podaří věrnosti body a
      sení rohož
    truth: 4
  9:
    pred: 2
    text: odměnář, matořka, paneť, ukoušenější, učení se, ... agent nemusí vyhovovat
      všechny aspekty istilizujeme
    truth: 4
  10:
    pred: 3
    text: gradiet udává měr, jehož se znaží hodnota lze bude při změně parametrů používá
      se pro aktualizaci parametrů tak, aby fakta loss bright byla co výtvorné počítá
      se přes porušení derivace mět parametrů hledáme ktobě ničímu (gradient se blíží
      k 0) - ve výsvědomí grafu se používá řetězové provide (snaží se pořádní derivace
      dělník pevně)
    truth: 4
  12:
    pred: 2
    text: 'obdařená jediná z rakurství prsty: 1 pro pohled do kurtoře (podaří vektorů
      zprava dobra) a 1 pro pohled do budoucnosti (protože vektorá velmoce doma poruchní
      používá jen 7 pro vzhled do historie (peníze se dívat do udržosti) výhoda obdarmé:
      je potreba mít konfliktově data (nebo použít spř. pro přesně řeči z pokročky,
      která stále probíhá - je natře žít celou nohinku) Kniha'
    truth: 4
  14:
    pred: 2
    text: učení s učitelem a naše třešnová data (vstupy a odpovídající výstupy), síce
      jaký má být výstup modelu (značně výsledky, používáno je pro trénování intelu)
      víme, jaký to týče výstup úkoly přihnání měsíce nemáme přesné výsledky, kterých
      chceme dosáhnout k smp. chce vyhrát hra, ale serže jak), model datová aderace
      po vyhování určitého počtu králů (někdy může dostat odměn, až když vybroje fun,
      jak model zatím dá naučený vyhovět, takže k výhře se sedadne a vrátí se z čeho
      učit) univerz
    truth: 3
1f3bbb6d06cc8023a7fba63eb4200b65:
  2:
    pred: 4
    text: MIN = 1;MAX;MIN;Vždy vyhodnotené;56;MAX;60 vyhodnotené Preusponiedať A neoplatí
      - min (succ (b) = 3 = 3 pri preusponizovaní A B, by sa vyhodnotil o nejsú v
      celé B, potom celé A (mín k succ A3 = 2) max. prevezance;e odřezané;MIN
    truth: 4
  7:
    pred: 4
    text: 'Ax Bo+ Bix + B2x2;vegetace dokonale se naučil všechny trénovacie dáta overfitting.;čím:
      - málo trenovacích dát/příliš vysoký stupeň polynómu.;- aho opraviť: viacej
      dát na trénovanie, alebo: zvířit stupeň polynómu, alebo inak obnodovať, čo je
      schopný sa naučit - napr. regularizacím váh (3);Co?: polynomiálny model, který
      se dokonale naučil trénovací dáta = overfisting. Prečo: Negeneralizovať = model
      má problém s prodékovaním doposice nevidělých dát (trénovacie a reálne výsledky
      nie sú konzistentně) — Je málo pravděp. že reálne dáta presne kopírujú naučený
      polynóm - hlavně ak uvážíme, že v tvé rozvacích dátach je šum a teda majorita
      hodnot pre nejaké x môže byť inde ako sample pro rovnaké x ktoré je v datasete'
    truth: 3
  12:
    pred: 2
    text: 'koverstva, kedy výstupy jednotlivých je to nstra kde jednotlivé výstupy
      závisí ako na texte pred, rahaj na texte po. Je to docílené holmbiněcion 2 jednosmatných
      · rekurentních vrstiev - jedna číta text spredu, druhé zázadu. · ako sa liší
      od normálnej - obsahuje 2 protiřídnice normálně“ rekurentní vrstvy. sémantický
      - výhody: číta text zákadu aj opredu = lepší kontext pri produkované výstupu.
      nevýhody: ohrem hĺbky (problém RNN) a sekvenčního učení a.je to hlavne nemožnosť
      generovať výstup realitime = musí mať celú vrtul text.'
    truth: 5
21506657c66da50152abe1ec8f832181:
  1:
    pred: 2
    text: Pokud si zapamatujeme, že c3 vede k řešení, tak tuto informaci můžeme využit
      při přešení valu B2, který ví, že C3 je řešitelný. Nemusí, tak procházet jeho
      podstrom ani stavy CH a CS.;and;AN
    truth: 2
  2:
    pred: 4
    text: 'MAX;MIN;60 maximální: prořezávání;60;D'
    truth: 4
  4:
    pred: 3
    text: 'D1;63;J;3;X x IX X;4;l X X;5;X X X;6;X X X;7 X X;X;};a;10;Po interesanci:
      D1 = 533 D2 = {9} D3 = 573'
    truth: 2
  6:
    pred: 4
    text: 018;xxx;p(pozitival) = 0,9;p(naz) nak) =;ní;158;200;1555;250 250;n. (positivní
      na rok) pos);nahazeny;P(pozit.;P(poz;10 1/10 Služba 50 4/50;aktovka;18 5 7 79
      70;P(nakosen) = 0,2 P(zdravy) =0,8 p(poz) nakazen) = 0,9 n (poz / zdravy) -0,
      1 Ríhovi =? Ninak) =? proti Ples p(poz) = p(nakosen) a poz(nakazené) n (zdrogy).
      Ip(pozdravuj) p (poz) = 10 1/5 10 2/6 50 Prvoroděpodobnost, že test bude u náhodné
      osoby pozitivní se;Nárok) plnác);(nož) probírač);p(naklonos);P(geg) = 0,8
    truth: 4
  7:
    pred: 2
    text: = wo + wh - x + w2 x Polynomiální regrese je jen speciální případ regrese
      lineární.;model negeneralizuje, pokud nesobecní řešení. Může například procházet
      přesně vstupnémi body, zdá se okrejbý, ale je úplně k ničemu pro nová data Pro
      generalizaci je třeba více dat, nebo snížt nároky na MSE.
    truth: 2
  9:
    pred: 3
    text: Agent nemusí splňovat všechny aspekty inteligence, aby byl;požadován za
      inteligentního. Agenta lze v nějakém prostředí považovat za inteligentního i
      když nalezne cestu z bodu Adolfu B. Nevykazuje, ale žádné schopnosti kognitivní
      inteligence.
    truth: 1
2b1500702cc62787245e747cf6e7e907:
  3:
    pred: 0
    text: Start
    truth: 4
  6:
    pred: 4
    text: poslnak;nat / pos;P(nab) = 0,2 P(posl. k) = 0,9 p(neg /nenak) = 0,9;PharYpsko,1
      p (neg /nab) = 0,1 p(posluenak) =0,1;p (nab) x pl p(po) poslance phab) xp /;=
      (pos) = plnableos) p(pos) = 02 x 0,9 dni;P(pos) = 0,26
    truth: 3
  10:
    pred: 1
    text: vektor největšího růstu v bodě pro upravení vah a biasů
    truth: 1
  11:
    pred: 1
    text: ponechání výstup 1. výstup 5x16 5x5x3 vstupní obrázek;1;6459216;3.;64x64x32
    truth: 1
  14:
    pred: 2
    text: učení s učitelem — síť se učí na datech s výsledky;velikonocement konviny
      - hodnotíme kroby které síť udělala - ne každý krok je boncovy a nemá vždy jednoznačné
      řešení
    truth: 2
2c0ccd57a3f729705c53275a21979d4e:
  3:
    pred: 3
    text: 17;ty) u stavu;cena;hrany.;heuristika;(4);špatná konvictika (neeptimistická);alternativní
      ohodnocení hebristikou případně se dá řešit i tak, že udělám krok doleva, ale
      nakonec bude mít v prioritní frontě stav na levé cestě i se špatnou heuristika
      nejmenší hodnotu) dobrodruhů
    truth: 4
  7:
    pred: 3
    text: možné;model prokládá data relativně přesně, ale na okrajích nutně nemusí
      kopírovat skutečný trend příčiny vysoký stupeň pokynomu málo trénovacích dat;ABY
      generalizoval � více dat - snížit stupeň polynomu?
    truth: 1
  8:
    pred: 3
    text: ogenerativní - modeluje posteriorní pst i tam nepotřebujeme (p(class) diskriminativní
      - modeluje pouze pst členství do třídy (p(c=1|X);kg otes);2.);generativní -
      gaussovský k. diskriminativní - signalida (logistická regrese) gen - modeluje
      rozložení, pokud ho potřebujeme dis - rychlejší, základ pro NN
    truth: 1
  9:
    pred: 2
    text: sebevnímání;STRONG AI � Turingův test;racionalita;· usuzování o vnímání
      interakce, předvídám;učení;WEAKAI;spam Filtry vyhledala ače řízení automabilů
      - doporučení;za inteligentní je považován systém, pokud jeho odpovědi nejsem
      schopný odlišit od odpovědí člověka
    truth: 3
  10:
    pred: 2
    text: 'gradient je vektor parciálních derivací funkce podle jednotlivých proměnných
      pro učení se využívají loss funkce (ohodnocení, jak moc se model „třefil“. �
      mnou loss funkce je "objektivní fce", jejíž nadučit hodnotu se snažíme minimalizovat
      � derivace � gradient � gradientní sestup (jako metoda gradient optimalizace
      parametrů NN) Wish Wilson pro učení: learning rate'
    truth: 4
  11:
    pred: 4
    text: výstup Sobota;Dale;s;64x64x3;c) c2 (3, 3) 8b (5, 5);výstup c2;b Exemplace
      (Odpoledne);velikost = 9x25 = 225 pixelů vstupu = 25 výstupů d
    truth: 2
  13:
    pred: 3
    text: v rekurentních sítích se může ztratit nebo zašumět informace ze začátku
      vstupu u attention se mohu „podívat“ kamkoliv do textu, který mě pro aktuální
      krok výpočtu zajímal a podle potřeby naváhovat si (několik částí vstupu obecné
      -> příklad - překlad jazyka, kde mi nestačí normální rek. model (francouzština
      a členy) jsou obecně výpočetně náročnější - dá se ale celá IVN postavit attention
      modelu � transformery;�
    truth: 4
  14:
    pred: 3
    text: s učitelem - mám známou sadu, dat, na nichž se model trenuje (srovnává výstupy)
      přesně ví, co klasifikovat a je jednodušší určovat určit loss funkci;o posilované
      -;mám pouze ohodnocení kroků ve fórmě odměn, ale ne to, čeho konkrétně se má
      dosáhnout (maximalizace odměn) algoritmus se učí až z celého výsledku, který
      ale obecně nemusí ani nastat (výhra v 60) a i když nastane, tak je složité odvodit,
      na základě jakých kroků se tak stalo že
    truth: 4
2de1ac8e1214010d396cb407a91c1f99:
  4:
    pred: 1
    text: x1 = §33 x26 93 x3 = 27,83
    truth: 2
  9:
    pred: 2
    text: Nemusí všechno, stačí většina.;- Schopnost pronést správné rozhodnutí -
      zlepšování svých výsledků.
    truth: 2
3482488a15f00a9aad6021001c1ad921:
  3:
    pred: 4
    text: hl/=4;Sir;RA = 2;128 -> zvolí pravý azol potom už pedie len jedna cesta
      do cieťa Ale je odhad nadhodnotený provnakom heuristiky v dobrom pomezí heuristika
      bude fungovat.
    truth: 4
  5:
    pred: 3
    text: 'Potřebujeme střední hodnotu a rozptyl gausovských rozdelení pre obe triedy.
      Pre každá triedu dve čísla, dvojica (M, 82), spolu 4. pre dve triedy.;z trůd.;Pravdepodobnosť
      výskytu prvku z triedy (průorná pravdepodobnosť) pre dve triedy stačí jedno
      číslo, druhá sa dopočíta ako 1 - P(trieda 1).;Odhad pravdepodobnosti: P(trieda
      / vlastnost) = rozborovnej);Odhad si a j pre triedu pomocou metódy maximálnej
      nerohodnosti. Vezmeme trénovacie dáta pre triedu (sú na sebe nezávislé a předpokladá
      ře majú gausovské rozloženie. Preto platí p (X|n) = TT p(x|n). Potom: p = arg
      max T p(x|m);všecky tradice;třídy E, P(vlastnosť) x;prvky nad bikelstvod z gausového
      rozloženia (vlastnosť / srieda). P(trieda);P(vlastnost);veklo;apriori'
    truth: 1
  6:
    pred: 4
    text: dvorý 20% 80% zdra;test shorý procitiv 90%;zdravý pozitiv 10% P(pozit|chorý)
      = 0,9 P(pozit / zdravý) = 0,1 P(chorý) = 0,2 p (pozit) P(cokový / pozit);p(pozitiv|chorý;P(chorý,
      posit) P(whow|pozit) P(nozit);P(chorý);P(choropozit) = p(pozit);P(chorý|pozit);0,9
      . 0,2 + 0,9 . 0,8;p(pozitiv|chový). P(chový) + p(pocitiv/zdravý) - p(zdravý
    truth: 4
  9:
    pred: 3
    text: '- schopnosť odvodrovať ziešenia paušátať si kreativita - komunikácia (vidence,
      text, zvuk);- vyhodnocovať ako sa zachovať;,;- nemusí, pre niektoré úlohy stačia
      len niebktoré'
    truth: 4
  13:
    pred: 3
    text: priradzuje hodnotu rôzným častiam vstupnej sekvencie (napr. slovám) podľa
      ich dôležitosti pre spracovanie aktuálne spracovávanej časti (slova).;napr.
      pre preloženie slova by mali venovať pozornosť aj iným slovám vo vede. Určí
      či a akým. Vyššia pozornosť vyšší ohodnotenie slova.
    truth: 3
368727a468c4c2bd143091516e713558:
  4:
    pred: 4
    text: 1234 5 7 8 9 10 XI x XXXX XXXXIX X x/xxXxxxxÄ XXXXIX X D X 3 LXXX x x x
      x 2 x X;852:341 8LAV
    truth: 4
  5:
    pred: 2
    text: 'Podepisujeme odhadnút rozloženie hustoty pravdepodobnosti pre 2. třídy
      s 3D dátami Garsontof tlasifikátor pro 3 premené potrebuje vektor pr = [2ý],
      který udává stred uvolněnia a malicu rozptylen (e) rídava rozptyl dál a korelácií.
      potrebujeme 2: 6 reálych čísel i teď 2:5 pretože na gažnej diagovále o ní čísla
      navratí Odhadneme ich pomocou metódy nacionálnej verstolnosti Odhadnuté parametre
      využijeme na výpočet na vdepdohodě, že dané dato patrí do ty kravědy p (x|c)
      1-p(x|c) � vzorce predruhú smědu dalo daná truda'
    truth: 1
  6:
    pred: 3
    text: P(P)? P(PI2) = P(z) P(p) = P(z). P(P|PIZ);(p) P(z|p);Bude ctorý a text výzde
      pozitivý. x bude zdravý a tak vyvede pritíry =0,2-0,9 + 0,8.0,1 = 0,18 + 0,08
      = 0,26;P(zlp) P(P) = 0, 8. 0,1;(9, 8) = P(p). P(c|P) P(c). P(plc)
    truth: 3
  10:
    pred: 4
    text: Gradient je velkor todnot, který bez údana smer a velkť. Tento gradient
      sa pčíha do derivácia chybnej funkcie a moží na nás na vieť do minina tejlo
      funkce aby sme minimalizovali dýlní funk a tým pádem měli lepší model jednotlivé
      váhy sa attralizuje podla nebo w jej, = w, -d A] I graduent - mez, kterým talla
      upravit váhy hlavnici rate -> ale jídlo attrokie ať vály
    truth: 4
368de756a1007b97d767e4d76497ae92:
  2:
    pred: 4
    text: MAX;MIN;S e Procházím a chci si co nejméně ublížit - vybírám co nejvyšší
      číslo zároveň teda aby mi mohl protihráč co nejméně uškodit. Protihráč se snaží
      o opak. Když přehodím větve a a b, a jdu 0 � 1 � 2, vím že za větev a získám
      nejhůře 2, pokračují 3 � 4 � 5, už n 3 vím, že ve větri b dostávám pro mě horší
      skóre, a to 3. Ks0h�5, se nemusí počítat;3
    truth: 4
  4:
    pred: 1
    text: D, = {}, 2, 3} D2 = {1, 4, 6} D2 = § 93 D3 = {8
    truth: 4
  8:
    pred: 2
    text: 10;generativní;Generativní model předpokládá, že vstupní data odpovídají;ganszovskému)
      rozložení, snaží se toto rozložení pravděpodob- 8 nosti naučit a předvídat třídu
      příchozího data (apriori pst). Model Gaussova rozložení.;Strašná;Diskriminativní
      - vstupní data rovnou rozděluje do třid - regrese. - lineární regrese, polynomiální
      regrese, log. regrese... - většinou více dat Každý model má trochu jiné využití,
      záleží na záměru. Oba potřebují nějakou míru generalizace, oba se mohou přeučit.
    truth: 0
38fa78e2f7bd7cd06dab384ef7ff8c05:
  2:
    pred: 3
    text: MAX;MIN;6606;60;6;D
    truth: 4
  3:
    pred: 4
    text: O;h=70;3;430;uvažujme cenu;Stavy odhadovaná a cena cesty;bude násobená;10;h
      = 22;pri hranoch je cena cesty a odhodovaná ceno zvyšnej cesty je vidiet, že
      aj teď neuristika ne pomíka optimistický odhad ceny, najde optima/ne riešenie,
      a to pravý stranu grafu
    truth: 2
  4:
    pred: 3
    text: o/1 2/3;4;5;6 17;8;DR Dr D2 D3 X z podmínky;*;X;� 22x11 x34x2 x36 x 3 x
      ? = x 2 2x + 1;X;x;XXX;x;X x X. XXX *2= x2 može, z φ vyradiť čísla račšie o
      to J naopak z D2 vyrodíme tie, které nic sú z moc uvažujme najhorší sekenor,
      teda x1 =0, potom x3 )1 najvačšie x2 = 9 potom x3 69 nech x3 = 2 (najmenšia
      hodnota) potom x2 = 72 vyškrtneme podle D2 nebude o ani 1 nech x1 = 2 potom
      x 3 %;x IX IX x IX X;X;X. X;XX;X;XIX;X;X
    truth: 4
  6:
    pred: 4
    text: P(zdravý) p(nakazený (pozitivny) naházeny (negativny) zdravý) = 0,9 � P(pozitivng/zdravý)
      = 0,1 P(pozitivny) = P(pozitivny, zdravy) + P(pozitivný, chorý) P(pozit, zdravý)
      = P(pozit / zdravý). P(zdravý) 0,1 . 0,8 = 0,08 P(pocit, chorý) = P(pozit|chorý).
      P(chorý) 0,9 . 0,2 = 0,18 P(pozit) = 0,18 + 0,08 = 0,26;Sv Rule
    truth: 4
4213cbc24a62d7aac83c860a66d64701:
  9:
    pred: 3
    text: '- pamät - uvažovanie motorika - schopnosť komunikovat kompresia - schopnosť
      zaučiť - schopnosť sa orientovať v priestore Nemusí ich vyhazovať všetky, stačí
      ak vyhazuje iba tic, ktoré ní potřebné na řešenie oknej úlohy'
    truth: 3
  14:
    pred: 3
    text: Učenie s učitelem prebieha tak, že na vstupe máme dáta a požadovaný výstup
      Systém si na základe požadovaného výstupu upraví svoje parametre a tak pokračuje
      cez všetky vstupné dáta. Pti Je potřebný „učitel“, který dodáva požadované výstupy.
      Při posilovanom učení to funguje podobne akurát výsledky systému prechádzajú
      dalšími funkciami, které ich analyzujú a vpravujú do vhodnej podobný a posléhajú
      ich naspát do systému na další výhodnotenie
    truth: 1
4701ad87d7f1c9e2341736c8aedc6c39:
  3:
    pred: 4
    text: počističný uzel;hodnota humistiky k nie je optimistický odhad, ale aji tak
      bude zvolený tento vzor kvůli nižší celkovej cene z počátečního uzlu;dělový
      uzel.
    truth: 4
  4:
    pred: 3
    text: 2;3;4;5 6 7;8;10;x X;x;X;X3 = 8
    truth: 3
  9:
    pred: 2
    text: kreativita;intuiria vnímanie samého sebe schopnosť riešenia problémov schopnosť
      učiť sa;agent nemusí splňať všechny aspekty, ale ten niektoré z nich, které
      považujme za dôležitejšie, lebo se nejedná o presní definiciu.
    truth: 5
  10:
    pred: 2
    text: gradient je brandách určujúca smer najvičšího rastu objektivnej funkcie
      (v kontextu neuronových sietí);pri učení ho môžeme využíť na nájdovie hľákaho
      měníme objektívej funkcie, a tuto parametru použijeme na alkoholizáci váh
    truth: 2
  14:
    pred: 2
    text: Při učení s učiteľom definujeme úlohu pomocou datasetu (vstupy a výstupy)
      Při posilovanom učení definujeme úlohu prostředím a akciami, s kterými agent
      operuje
    truth: 2
488161096b8f6d7fd824d74f19461a9e:
  1:
    pred: 3
    text: 6 S - splnitelný;2) - stejný stav jelikož lený syn az je splnitelný a praví
      že an, na který jsme již v prohledávání leného syna narazili a tedy víme, že
      že splnitelné pak i az je splnitelný bez prohledávání pravého
    truth: 4
  5:
    pred: 4
    text: parametry 30 gausova klasifikátoru jsou u (střední hodnota) a kovarianční
      mati 2x2. střední hodnota je 1P vektor odvon položeních, který uchívá střed
      hovnot konvianční matice 2x2, tedy na hlavní diagonále je velikost dané homolev
      jednotlivých směrech (pro x a x) a na vedlejší diagonále je korelace jak je
      daná noude zploštění o Celkem je tedy popsáno 6ti reálnými čísli. Odhadnout
      parametry můžeme pomocí metody maximálně něcohodného odhadu, kde hledáme maximální
      součin dat nap(x|n) = arguar TT p(w|h). Dále převedem do logaritmické dověny,
      z násobení se chce sčítání, které se snáze derivuje. spočteme devinaci, postavíme
      nomu o řešení nám dává odhady jednotlivých parametrů. Každá třída má svoje rozložení,
      díky parametrům jsme schopní zjistit pravděpodobnost pro jednotlivé handle a
      ta která nám vrátí vyšší číslo, tak řekne, že do ni nové dato patří
    truth: 1
  6:
    pred: 3
    text: p(pocit i naházel. p(naházení) = p(nakažení/pozitivní p(pozitivní) P(unkažení)
      =0,2 P(zdraví) = 0,02 P(PŘ) P(pozitivní|mluvení) = 0,9 p (negativní|vyhození)
      = 0. 1 p(regativní) zdaní) = o. 9 p(pozitivní) zdraví) = asi p (pozitivní) =
      P(pozitivní nahražení) . P(nakažený) + P(pozitivní tedvací). P(zdravý) = 0,9
      .0,2 + 0,1. 0,8 = 0,13 + 0,08 50,26 � 26%;Plna kažený) = 0.2 P(zdravý) = 0.3
      p(pozitivní) nakažení) = 0,9 R (negativní i nahražen) = 0. 1 p(negativní) zdraví)
      = 0. 9 P(poniem) � 0. 1 ptpozitivní) =?;(používaní)
    truth: 4
  9:
    pred: 3
    text: 'Aspekty: motorika (zvládat pohyb) cit soucit možnost učit se novým věcem
      představovat si co se stane čí co ještě neviděl uvědomění sebe sama a mnoho
      dalších.;považován Ne, agent nemusí vyhovovat všechny tyto aspecty, aby byl
      za inteligentního.'
    truth: 4
4b005bb75b23a34a6289d304ef47be74:
  2:
    pred: 4
    text: MAX;MIN;S 560 od;prevežene texto dva lebo dělej nemá zmusel, hedže min.
      -3 je menej jako min -1 z vedlajšej vetry čo by nám vnutil hráč čo minimálizy
    truth: 4
  5:
    pred: 4
    text: Nutná 3D gausová � střední hodnota � 3 čísla v každej den pre jednu tržedu
      � rozptyl � 3 čísla v každej den � symetrická matica � 3 čísla korelácie;3D
      dáta pepisci;2 triedy;� horelácia;� klasifikátor má 2(3-3 tř.) parametrov tř.
      1x parametrov � reprezentované 18 reálnými číslami � metra středních hodnot
      � pre 3 dimenzie L43 � kovovíenčná matice (5, 9, 12, 2, 2) a symetrická � obsahuje
      korelátie " medzi jednotlivými din. 53 � Odnad parametrov pomocou metódy maximálnej
      vierohodnosti optimalizujeme p(X) ~ N|9, ž) � výpočet pravdepodobnosti vrátáme
      na základě apriornej ho který pravdepodobnosti, pravdepodobnostnej funkcie pre
      dané dáta. třídu určíme podle toho Následne;te vš
    truth: 2
  8:
    pred: 3
    text: � Generativní Napr. Gausev klasifikátor Otroka � � pravdepodobnost’ vzorku
      určujeme pomocou apriornej a posteriornej pravdepodobnosti � vieme tímto modelom
      generovať nové vzorky z rovnakého rozloženia � výhody � dobre funguje na malom
      datasete, určuje presne onou pravdepodobnost on patrí daný vzorek do triedy
      � nevýhody � čela parametrov � Diskriminativny určujeme dy � iba na základe
      dát, nepredpokladáme žíadné rozdělenie. V niektorých prípadech pravdepodobnosť
      nemodelujeme � logistická regresia alebo sum vóbec. Nemáme pravdepodobnosť s
      akou nepatrí do žiadnej triedy;k
    truth: 1
  9:
    pred: 3
    text: logika � vlastnosti, které majú � redomie, motorika, súcit atd. " iudia
      + � Agent nemusí vykazovať všetky aspekty, stačí niektoré
    truth: 4
  12:
    pred: 3
    text: � zložené dve rekonventně siete s tym že jedna ide "opačné" ako druhá �
      výhody � výstup vpredu dostáva vstupy zo zadu a naopak;RNN;Styp
    truth: 3
4bf747ef2120d309620fbd78fe771b7f:
  7:
    pred: 1
    text: spo-;- naučená regresní funkce kopíruje přesně trénovací data, je to kvůli
      tomu, že dat je velice málo, proto vy bylo nutné získat více dat nebo směnit
      polynom funkce;-> rejská datová data jsou Ka, která se předala
    truth: 2
  9:
    pred: 4
    text: '- intuice, schopnost učení, uvědomování si sám sebe, prožívání emocí, schopnost
      pohybu, rozhodování, schopnost komunikace,... nemusí, zda inteligentní se zjistí
      jiným způsobem (Turingův test např.'
    truth: 4
  13:
    pred: 3
    text: '- attention se dívá na libovolné pozice výstupu, nemusí se dívat pouze
      na minulé slovo jako rekurentní - učí se parametry, které minulé výstupy mě
      zajímají - výhoda = mnohem lépe vidí celý kontext, navíc ji nevadí přeházené
      pořadí slov - použití = překlad'
    truth: 3
  14:
    pred: 4
    text: '- učení s učitelem poskytne anatovaná data a víme jaké je správné chování
      (ihned reagujeme) posilované učení neví jaký je správný výsledek, jaké je optimální
      chování, jsme pouze schopni říct, zda se provedlo to, co mělo, ale nevíme jestli
      to provedlo nejlépe jak mohlo - s učitelem = klasifikace (vidím ihned zda správně
      nebo ne) posilované = self-driving auto (vidím až později, jestli jsem dojel
      tam měl, nebo jsem naboural)'
    truth: 2
4ebe757a98261ca6cf7f8809fc99cd6e:
  4:
    pred: 2
    text: xh - x2;D1 = {1, 2, 3};D2=D3 = 51, 2, 31, 4, 5, 6, 7, 8, 9, 10;EM12.33-D1;91,
      41, 93 - 02 D3 = {1, 2, 3, 4, 5, 6, 8, 9, 10,;x34 x 2;x33 2x41 02 = 51,2,3,4,6,7,8,
      9, 103 D3 = {8, 9, 10};x35 x 2;R = 21, 2, 33;DA = {1, 2, 3};D3 = 23 = 0;X35X2;D3
      - {1, 2, 4, 5, 9, 8} D2 - {2. 3, 4, 9, 6, 9, 84, D1 = {1, 2, 3};1, 2 x 2;D2
      = 23 = 3;D1 = {1, 2, 3} 2 = 21, 4, 93;X302x11;DI = {1, 2, 3, 4} 03 = 24, 6,
      3, 16 DA = {33 02 =;D2S EMITTATS Dy = {1, 2. 3, 3} 03 = {5, 9, 1} 3;502 = {1,
      4} Dn = sp. 2, 3);OBET;93 D3 = 883;II;v;v„;5;o;5 x;xx xx xx0 v;�;o;·;�;s;o
    truth: 4
  9:
    pred: 3
    text: INTELIGENTNY ALENt BY MAL BYT JEHODNÝ MAxIMALIZOVAT SVODE MOŽNÉ OBRÁCHY
      POLIT celého svadha života. Niž ne znaLne nemusí vedle Ti k tomu mo môže pomoct
      ať si prikaze PAMÁTNĚ V AKOM JEDNE ČO AKA NA NACIA SP􁀓SOBILA NECH JE EFEKTÍVNĚJŠÍ.
      ALE NIE AE po NUTIC;ASPEKTI INTELIGENCIE A POJNAT PROŠTICHIV � PAMÁTOS SÍČO
      SNĚJIVÁ AKADEMIE � PAMATICKY ČI ŽO SISSOMI AKA BYTOMATESIA � VIE SA ROZhODNOU
      CO JE V PANEM SITUACI NACE PSIE z více sa vony na chybach.
    truth: 2
  10:
    pred: 3
    text: GRADIENT JE UDALA SKION A SMEM RASTU VAH. PRIQUI SA VYUŽÍVA PÁL SÁSTNOM
      PRECHJDE NeuMOMOTIVU SÍETŽU NA KOREACIU VÁH - PRÍCOM SPORO MASOBIMU HODNOTU
      PRAMENTU HODNOTOU K (UZENIA SA) ZÍSKAVANÉ NOVE OHEBERISTECKÉ PAHIE ČÍM JE GRADIENT
      AKCIELE O tYM JE RASY. POMALU, RESP. NICOJY.
    truth: 2
4f9e1fa54dccf75374f4a9b85be8a433:
  2:
    pred: 4
    text: MAX;MIN;Seb;56;prohladováme naypr lavu čast podstr aby to dávalo rmy;těsto
      dva nebude vyhodnocovat Na lavej straně nezaleží prejdeme celu, najdeme min-2,
      a potom prohladavame pravu najdeme - 3 a nepokračujeme takže určíme 2 roky
    truth: 4
  7:
    pred: 2
    text: model;K = 2;podél negeneralizuje kvoli nedostatku dat pridaním važšího množstva
      dát by sme zarazili generalizovanie modelu. alebo zmenšit polynóm pre danu ulohu
      napr.;- podncionálne další ktoré nemáme k dispozicii;k = 1;- prechadza prezne
      cez body negeneralizují ale předpokládáme že další by bolí s gauss žumom;reg;rikpa
      věce generalizuje
    truth: 4
  8:
    pred: 3
    text: Generativny model - vychodia z tohe že předpokládáme že naše data bolí generované
      z nějakého rozloženia, a my sa snažíme toto rozloženie modelovať a potom pomocou
      bayksovka vzorcu vecovať pozteriornu pravdepodobnosť Diskriminativny - nihľada
      rozloženie ale rovno so snaži odhadnuť pozteriornu pravdepodobnost pre dané
      dato. - hladce rozhodovaciu hromůdu medzi priedami - generativny model - napriklad
      model gauzovského rozložení ZD (gaussovský Dasibilator - diskriminativny model
      - logická regresia Výhoda diskr. � ak ma velcí dat, setri parametre a lepšie
      vysledky, ak malo dat negenerovaný Výhoda generativny SY na malom vzorku nedochadza
      k overfitingu nevyhoda zvočna nadelejem � nachylné na out nevodrelné vekla za
      linery (disk)
    truth: 4
  10:
    pred: 2
    text: '- gradient v kontexte neuronových sietie je ktorý dostaneme položení rovných
      ako vysledek parcialních deriváců voči váham * parciana derivacia lossfunkcie
      a voly vrstev. Tento vektor nam určuje sklon a velkosť stupania funkcie v danom
      bode. Orda možně to využiť pri algorit gradient dezcent kedy počítame gradienty
      a upravujeme vahy tak že odpočítame gradient * nejaka learnig rote. Efektivní
      hladome iterativne minimum našej loss funkcie'
    truth: 4
  13:
    pred: 3
    text: základna myslienka že jednotlivé informacie sa nepropagujú sekvenční ale
      možu sa propagovať z horiktorého uzlu danej vrstvy kedy každej urol môže mať
      aj ine váhy propogocie výhoda dokáže zpracovať aj delšíe sekuncie a dokáže lepšie
      vyžívať informacie z celej zelevonně kedy za to može využívať napríklad na preklad
      textu a ve inom pocyku je inj alowozled a ine pokrase informace na vyhodnocenie
      dalšího slova.;earning) v tom, čím
    truth: 4
  14:
    pred: 2
    text: '- pri učení s učiteľom máme jasný výsledek ato ma vyzeroť (anotovane data)
      � vzut a výstup;pri posilnovanom učení máme len financialny stav celý chceme
      dosídnuť nevieme akou schoncou akcii sa tom dostaneme. Napríklad hranie zachovej
      partie alebo riadenie auta.;- hlavný rozdíl je v tom že pri reinboranci pomocou
      odmien učíme agenta robit rozhodnutia, a je na něm oko splní danu ubohu � komunikacia
      s prostředím'
    truth: 3
50568a87cf2aab80a607af9913d3482c:
  1:
    pred: 0
    text: So;66;62
    truth: 1
  6:
    pred: 4
    text: 20% — v POLUDACI;nEgativní;narušený;0,1 -;Všechno;0,2;ZDRAVÍ;8;pozitivní
      0,9 -;0,18;0,1 - pozitivní - 0,08 g - NEGATIVNÍ;pravděpodobnost pozitivity je
      26%
    truth: 4
  10:
    pred: 2
    text: je směr (vyjádřen vektorem) k vÝNiMU funkce, je počítán nad obJeKTNNÍ FUNKCÍ
      A nA ZÁKLADĚ NEJ UPRAVUJEME PARAMETRY MODELU učící KONSTANTY;Abychom zmenšili
      chybu;mohl.
    truth: 4
  11:
    pred: 4
    text: . 2.;M;ofyry 6x6 VSTUPNÍHO OBRÁZKU Ex 5 VÝSTUPU 1. VRSTVY
    truth: 3
50d5da4c697fc4f98eeb652074521890:
  6:
    pred: 4
    text: 2;V;Kalhoty 1. Ledna 1919;14/;ReKtor;72%;8%;P(R|=1);=> P(pro 1, N) = p(postava)
      + p(possel, 1 = 18+8 = 26%;2%;18%
    truth: 4
  9:
    pred: 3
    text: '- nemusí nutně vykazovat všechny, například apart;- mytorika - kognitivní
      schopnosti - plánovací - představivost - empatie, emoce - uvedomělí sebevam
      - vnímání;který bude fungovat ve vrtuálním prostředí bez prostoru nemusí vykazovat
      schopnosti metodiky a třeba erpatre a stále ho můžeme považovat za int tedy
      stačí libovolná podkročina agrebátů'
    truth: 4
520cd07ba31519b54f3f2093e83f1545:
  3:
    pred: 3
    text: optimální je cesta 1 -> 2 -> 4, která se nalezne, přestože h(n) - délka
      ces k cílovému;g(n) = 1 f(n) = 6;gli- 3 Graf Čtvrtek 7. 6. 1942 toto spali Teodor;g6n)
      = 2 flü/=6;Cno;cena tohoto uzlu se v alg. nespočte, protože nebude rozgenerován
    truth: 1
  5:
    pred: 4
    text: potřebujeme pro obě třídy střední hodnotu a kovarianční matici gaussovského
      rozdělení, kterým byly vygenerovány střední hodnota bude reprezentována 3 čísly,
      kovarianční motice 9 odhadneme je metodou maximální věrohodnosti Z parametrů
      jsme pak schopni určit p (class), p (obervation) a p (observation / dass), z
      čehož jsme bayesovským vzorcem schopni spočísť p (class / observation) jako
      p (cllus) - p(observation) class) p (class|observation) =;p (observation)
    truth: 2
  7:
    pred: 2
    text: model přesně vstupní prochází vstupnímu daty, protože těchto dat je jen
      K+1. Tím pádem negeneralizuje. Aby generalizoval, muselo by přibýt více dat,
      aby nebylo možné model vytvořit pouze tím, že se data propojí křivkou polynomu
      druhého řádu.
    truth: 4
  8:
    pred: 2
    text: Generativní model modeluje pravděpodobnostní rozložení a pro výpočet pravděpodobnosti,
      do které třídy patří nový vstup využíva baygessovský vzorec. Např. gaussovský
      klasifikátor. Lze užít v případě, že jsou třídy nezávislé a funguje production
      rule Výhodou je, že funguje pro menší množství dat. Další nevýhodou je, že potřebuje
      mnoho parametrů Diskriminativní model se učí určovat pravděpodobnost třídy napřímo.
      Výhodou je, že potřebuje méně parametrů, nevýhodou je, že se na málo datech
      snadno přeučí. Např. logistická regrese
    truth: 2
  9:
    pred: 3
    text: 9. Jaké jsou různé aspekty inteligence? (jen vyjmenovat) Musí agent- abyste
      ho považovali za inteligentního? Například vědomí, sebeuvědomění, schopnost
      se učit, společenská inteligence, schopnost logického uvažování, racionalita
      produktivnost Inteligentní agent nemusí splňovat všechny aspekty inteligence,
      ale měl by splňovat alespoň nějaké
    truth: 4
565919f2a81ff4e380cfb3cc8f51ae70:
  2:
    pred: 4
    text: MAX;MIN;6000;MAX;MAX;MIN;MIN;č. 6;O
    truth: 4
  5:
    pred: 2
    text: 1. Vektor středních hodnot pro 2 třídy 2. Kovarianční matici pro 2 třídy
      celkově 10 parametrů. Zpuion ní pravdepodobnost pro 2 třídy 4. Rozložení hustoty
      pst. pro 2 třídy 5. posteniorní pravde pokrost pro 2 třídy. 1. Vypočítamé apriorní
      pst, pro oběť Voktor [x, 3, 3, 3] 3 + 3 třídy např. p(med = nedo 5|6) kor. matice
      [4. 1. 1989 2. Vypočítame rozl. hostoty prav. pro obětí. 3. Vypočteme post.
      pst. pro obě třídy. 4 zprionní pravdepodnost p(c|x) na nově příchozí datu vypočítanou
      3+3 pomocí post. pst. s jakou pst. nezložení hestoty postaniouní pravdepodobnost
      velkou 30 čísel, do dané třídy patří
    truth: 1
  10:
    pred: 4
    text: Pomocí panciálních denivací spočítame vektor (guadient) který nám určuje,
      jak moc (dílka šipky) a jakým sněnem noste. Snažíme se najít bod, kde se parc.
      demivie 0 V tomto bodě se nachází influe. bod (lok. max., lok. min., Dokud jsme
      našli lok. Mezinam jsme v cíli Při počítání gradientu metodou (quadrent descent)
      Jdeme algoritmucky a upravujeme v každém kroku hodnotu parametrů pomocí hodnoty
      gradientu. Využívá se k nalezení optimálních panometrů pro modely DECM) Neuronových
      sítí.
    truth: 3
  11:
    pred: 1
    text: Ex5r;ŠTORSKÝ VE;St 513 = 79
    truth: 2
  14:
    pred: 2
    text: Určení s učitelem máme na začátku vstupní data, která jsou ohodnocena. AL
      máme pouze nějakou úlohu k vyřešení a podle uspěšnosti něčem je zl odměněn.
      Učení sečitelen - např. klasifikace, negaese Vytvoříme model na označených datech
      a tem pak používáme RL - na vstup dáme úlohu. Roztopně se ke znaší úloh řešít
      a pokud uspěje je odměněn. Postupně se tak učí způsob, jakým danou úloha vyřešit.
      v SV - pevně daný vstup, výstup.
    truth: 3
59ff42c707eba1e5ec087a66fb4612ac:
  2:
    pred: 4
    text: MAX;MIN;6 000;pořadí z leva doprava v MAX znova dolova o MN -1;1 a o pravého
      problemu si vynechajú
    truth: 4
  6:
    pred: 4
    text: P(X|5) = 02 01;nahožen;P(X|S);pozitivní;P(X) =0, 8 P(G|X) = 01 .. P(y|x)
      = 0,1;PV, S - 02 09;pyk P(xy) + P(R|Y);98;0,8. 09 = 7 (X, 5);P(X|9) - p(y) =
      p(Y|X) P(X) P(X|Y) I PUD = PY|X) P(X) - PWIx) PLSD = PISIX P(X) 0,9 .002 =0,1.
      0,8;P(F|9-8|B) = p(X|7) P(Y) - 99.0,2) = 0,1.98 ply = 0,1.0,8 + 0,9 .02 půj)
      = 0,08 + 0,18 =0,26 PLYN = 0,26
    truth: 4
  7:
    pred: 2
    text: reálné předpovědi;model téměř prochází 4. trénovacíy body, model negonevalizuje
      z důvodu přeučení na trénovací data, protože dat je cvalla, model může nesprávně
      předpovídat nová data pro generalizně by bylo potřeba změřit trénovací data
    truth: 3
  9:
    pred: 2
    text: motorika, pohyb schopnost učit se - porozumět celku;-;- většinou je agent
      považován za inteligentního, pokud splňuje nějakou podmetice aspektů (přip.
      jeden a pekt) - pro text, zda je agent inteligentní (jeho člověk) lze provést
      Turčagův Test
    truth: 3
  14:
    pred: 3
    text: '- a učení s učitelem je v úloze detinované jaké jsou vstup a přeju to má
      odpovídat nástupcem;posilované učení neměl přesvědčovat výsledky, pro nás ale
      hodnotící funkci. provedeného kroku'
    truth: 3
5b9dc6511750b1dc138b7722ad0af615:
  1:
    pred: 2
    text: Exa vyskytne v dvoch and vetviach pričom jedna zvyká na vyhodnotení D. Ak
      si zapomôitáme, že E je splnitelné môžeme tuto informaciu dálej využiť pri riešení
      uzlu C, kde budeme musieť vyhodnotit len F
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;6606;65;3;nemusíme přehlčedávať keďže už vieme. že je horšie ohodnotenie
      ako vo vedlajšej možnosti
    truth: 4
  4:
    pred: 4
    text: 0;1;z;3;„;5;G;7;8;9;10;D1 D2;D3;x x X;X;X;X;X x;X;X /;X;X X;X X X;X;X;x;X;X;X;X;X;X;X
    truth: 4
  9:
    pred: 3
    text: '- schopnosť komunikovať robiť rozhodnutia - cielavedomosť premýšlanie uvědomenie
      si samého sebou - (zájezd) - emocie světem vnímanie okolia a reakcia na podnety
      z okolí a - fantázia nové nevidené úlohy - dôvtip - schopnosť riešiť úlohy -
      ete...;-;nemusí splňať všetky avšak čím více ich splňu tým tažšie je ho rozoznať
      od človeka'
    truth: 4
5c55ddf6cabad401d3e98d861f0c8205:
  9:
    pred: 2
    text: Aspekty - vědomí, myšlení, emoce, uvědomění, porozumění, smysl, orientace
      v prostor Isenzory - hmot řek) Je jich moc.;Nemusí vykazovat všechny, stačí
      aby nebyl v nějakém úkolu rozeznatelný od člověka (překladač);Za inteligentního
      ggenta bereme nerozeznatelný od člověka;� Turingův stroj (tím to testujeme)
    truth: 3
  12:
    pred: 3
    text: obousměrná rekurentní vrstva je taková vrstva, která se učí jedním a potom
      druhým směrem rozdíl "normální" se učí jen jedním směrem - výhoda dá se použít
      při překladu (mapovaní není 1:1) - normální se rozhoduje pouze předchozími sekvencemi
      (slovy např.) - nevýhoda je pomalejší
    truth: 1
  14:
    pred: 3
    text: 'Učení s učitelem - máme vstupní a vystupní data. Výstupní porovnávame s
      tím co AI nám vyřešila — Známe výsledek dopředu proto s učitelem. Příklad: facereografion
      Posilované učení � dávame odměny. resp. enviroment dáva odměny, když se agent
      blíží k cíli nebo aspoň správný krok k cíli. Příklad: snaha (jiná hra)'
    truth: 3
5dff9e7052fea9930bd73c07a81648b0:
  3:
    pred: 4
    text: 4 pluk 3-3;15;h(a) = 30;5; hlas = 10;70 KART.
    truth: 4
  10:
    pred: 1
    text: Je to funkce, jejímž výstupem je rektor parciálních derivací. Používá se
      v algoritmech založené na gradientním sestupu pro buchpropropagation si z trétové
      funkce. Ponoví hledání globálního minima;upravují váhy modelu
    truth: 3
  13:
    pred: 2
    text: oproti rekurentním vrstvám? V jakých úlohách se například používají? skoro
      Podle nich se určuje místo, kde se nachází v celém kontrastu část vstupu;porovnat,
      používají se hn;Výhoda;x něco jiného. Nemusí v paměti ukládat tolik dat. Používají
      se například k extrakci z textu na základě otázky
    truth: 1
  14:
    pred: 2
    text: Při učení s učitelem je pevně daný výsledek, například vchazí filace člověka
      v obrázku. Frénovací jsou anotována a dle odhalení a jednotlivé ground - tento
      je model upraven, úloha tedy definujeme trénovacími validačními daty a vystupem
      U posilovaného učení se úloha definice pohaltami a odměny pro rozhodnutí.
    truth: 3
5e6e373a14626c45fa2ca5e6ef8fc78d:
  2:
    pred: 4
    text: MAX;MÍN;5;O;o;6;G;-> ví, že HRÁČ BY ZVOLÍ PŘI NEJlEPŠÍM HODNOTU —33 KTERÁ
      JE pro hráče a nevýhodná A NEBUDE SE ZABÝVAT dále daným podstromem. úzly s hodnotami
      o a 1 se nebudou vyhodnocovat. Dorazí do pravého podstromu, už ví že pro hráče
      Je maximum -2, proto jakmile nalezne jako první Hodnotu -3, už ví že nemusí
      dále prohledávat, protože ví;pravý podstrom bude mít tento;oběd jak má al;31;tvar:;Hráč
      B z levého po OSTROMU VÝBĚRE Jako minimum �;odmotov
    truth: 4
  9:
    pred: 3
    text: '- SCHOPNOST CÍTĚNÍ, VIDĚT -KOGNITIVNÍ A MOTORICKÉ FUNKCE SCHOPNOST PAMATOVAT
      SI A APLIKOVAT Chyby z minulost (počít se jim) - schopnost slyšet, mluvit;LaGent
      nemusí umět všechny aspekty. Stačí pouze část, resp. vybrané aspekty, které
      stačí dk tomu aby AGEMT ZVLÁDU se úlohu naučit a úspěšně vyřešit. V tu chvíly
      ho lze považovat za inteligentního.'
    truth: 4
  12:
    pred: 3
    text: U obOU SMĚRNĚ MÁM PRŮCHOD SÍTÍ (WRSTVAMI) JAK od začátku tak i od konce
      současně omezení spočívá v tom že musím mít vstup v statické PODOBĚ (ODSTAVEC
      TEXTU) KTERÝ ZPRACOVÁVÁ. MOHU TEDY JÍT i od konce (posledního slova). Pokud
      bych měl překlad reči v real-time, tak od konce jít nemohu, protože ao nemám.
      OBOUSMĚRNÁ SÍŤ JE SCHOPNA SE UČIT RYCHLEJI A přesněji
    truth: 3
  13:
    pred: 2
    text: '- Myšlenka je, že si pamatuji pozice;DANÉHO SLOVA/PISMENA VE VĚTĚ/SLOVĚ.;používá
      se u překladů. Kdy slova záviset na jiných slovech ve větě. Třeba jejich správný
      TVAR.;INAPŘ. ČASEN a, the, skloňování VE FRANCOUSTINĚ (CA ...);- Je to aUTerNativa
      k rNN, které mají problémy s dlouhými vetami 5 Ú LÝ 35 �;TRANSL'
    truth: 3
  14:
    pred: 3
    text: UČENÍ S UČITELEM - data tRÉNOVACÍ I TESTOVACÍ Mám aNotovaná. Jsem schopen
      říct, popsat jak K vÝsLedku dojít. Síť se učí podle dAT. NAPŘ. klasifikace,
      regrese;Posilované učení - mám pouze zadání, co se má SÍť naučit, ale zřídka
      má k dispozici postup JAK TOHO DOGÁHNOUT NEJSOU ŽÁDNÉ TRÉNOVACÍ DATA. Jsem schopen
      pouze říct jestli výsledek je dobrý nebo špatný. Síť se učí podle ReWARDŮ za
      výsledek. NAPŘ. PANÁČEK SE NAUČÍ CHODIT, Držet postoj, SÍť se naučí hrát starorozt
    truth: 4
60e6b9e7b1eb6d3f2de9c8763a64f929:
  5:
    pred: 2
    text: p(c) (a), plnit plaz, ale plaz = 1 - plav;Potřebujeme číže to shalárei parametres.
      z Čalej potřebujeme parametre pre p(x|c), moc pre rozborná N(N|X|X). Pri každou
      je vektor 3 odh hodnot, a událne symetracká, stačí 6 čísel (0ž 0ž2 0ž3, a kovariancie
      pre xixi (x1x1 a x3) Čištění 2x (3 + 6) = 18. reálných spolu MINIMÁLNě � spolu
      (z oken nevyužijeme symetre ODHAD POMOCOU ML, p(c|l = ?) NA = DEX) = 21 N2 a
      na byzde EVŽ É E CENTRALIZACE = pro eme ML - p(x|p) = arg přeporam (x|c) .p(c)
      pleb, vyšším 3/3 (p(x|k) plk) Ivančice Využitie -> p(c|x) rem. Pro tento virus
      máme nákresu asp. 30 Procent populace se nakazilo určitým blíže nesj. k dispozici
      test, který je pozitivní pouze pro 90% lidí nakažených tímto virem. Pokud člověk
      nenípa- nakažen, je šance, že mu test vyjde negativní, také 90%. Jestliže u
      osoby náhodně vybrané z celé populace provedeme test, jaká je pravděpodobnost,
      že výsledek testu bude pozitivní?;matica 3x5 l, ale hodně je diago;každé;tureze);ROK;platit
      pl;plk./
    truth: 4
  7:
    pred: 4
    text: de lebo regularizátor lepšie generalizovat, čo znamená, velel dobré Odhadovať
      správný výsledek (očekávaná hodnota pme y vzhledou na dané x) j pre dáta krom
      nevidel (ale sú v rozumej mreve podobné týn. na kto Frém;le;rytíř hlavním;Máme
      kvadratický tvar (lego model 2. vádu, čte y = prochádzu všetkýho bohati, či
      že pretrénovaný, onestrainvy, negeneralizuje lebo sa plně prispůsobil trénovacím
      datum. Dolo by třeba vrac dát, (případně znášíť pokyn problémem počet dát).
      Potom by
    truth: 4
  10:
    pred: 4
    text: 'RASTU ZÍSKA SA DERIVÁCIOU LOOSS FUNKCIE, využ na parametre. Podľa nebo
      potom upravuje parametre tak, aby sa blížilo minimu pre Loss Pa: Napri gratiat
      desient : w = w - 2 [LIb], kre Loss je funkcia volant nad trénovacími dátami
      x, využívající LING purametru who vektor), derivovaná pedia a konstanta, a t
      je učinna konstanta. lné aptimatizační algoritmy např s věrnou koetickou pracují
      and (dynamicky ho nením). Brudsent sa da získať z parovázky ch derivácia podľa
      jednotlivých parametrov, vypovindaných vo vektore'
    truth: 4
  11:
    pred: 1
    text: 500;43-1) (543-1) = 7;o;Lih pixelov;dobře zní;1. VIII. Tkanice pikolon
    truth: 4
676057f1a2cb6ed8578579152ec1452a:
  2:
    pred: 4
    text: MAX;MIN;o;bereme vzlp zlevas;Nebude se vyhodnocovat;bereme vzty z prava
    truth: 4
  5:
    pred: 4
    text: cov,;P(9) �;konferenční Střední hodnoty matice 3e? odhadneme aritmetickým
      průměrem a z parametrů vytvořím odhad Normalního rozložení z pravdepodobnosti
      celkem 20realných čísel P(třída) = PIG o pro vypočet pravdepodobnosti použijeme
      bojů v vzorece p(třída/Vzorek) = pro kterou třída je výsledek větší, tak jí
      klasifikujeme f(Vzorch / třída) P(třída);(a2) apriorní pravdepodobnost p(c)
      = počet a;počet a + počet;p(c) = obdobně;P(vzorek) P(vzorovic) = EP (vzorek
      (třídě);127
    truth: 3
  10:
    pred: 1
    text: Dle gradientů se upravují váhy NS pro dosažení lepších výsledků. Gradient
      popisuje jak se mají změnit hodnoty při bachpropagaci
    truth: 2
688c2754432d58f63f516f2cf5958c11:
  2:
    pred: 4
    text: MAX;MIN;5. a 6. uzol zo nevyhodnotia, lehc 4. uzel je menší ale lubovolný
      uzal v na lovej vetve - uzly za chudé vyhodnocovat
    truth: 4
  5:
    pred: 2
    text: parametre sú vo vektore u a matici k pre trojrozmezné normálně rozdelenie;majú
      podobnou desativných čísel zapíraných vo vektore a matici závazková pre každú
      triedu je osobitné trojrozmerné normálne rozdelenie preto ich je dokopy 3.2+9.2
      = 24, ale nicktoré parametre majú rovnaké hodnoty, teda 3.2+6.2 = 18 parametrov
      dokopy odhadneme ich nehodou maximálnej viesohodnosti pre trojrozmezné normálne
      rozdelenie Pro výpočet pravdepodobnosti nového vzorku dosadíme jeho hodnoty
      parametrov do oboch normálnych rozdělení a zarodíme ho do triedy pre letošní
      je najvřeňia pravdepodobnosť z týchto rozdelení
    truth: 3
  7:
    pred: 2
    text: KART.;K =2 negeneralizuje lebo ako za blíži kO tak chyba narastá, teda za
      odkláňo od navezaných dát dála sú vygenerované s náhodným šumom od polynómu
      3 rádu, teda 4 = až + betered kedže však učíme model druhého zádu tak za nie
      je schopný naučiť takúto závislosť v dátach Ale zvýšíme rád na K=3 tak bude
      generalizovat dodržování
    truth: 2
691b3e014c609607f10df53d1d8cfa0b:
  4:
    pred: 2
    text: KART. 5 Dec 15 Postupně aplikujeme omezení (a zpětně kontrolujeme platnost).;6/7/8/9/10
      XXX XI O X;D2;D1= §3, D2 = {}9}, D3 = §83
    truth: 4
  6:
    pred: 4
    text: 'P(nakažený) = 0,2 P(zdravý) = 1 = p (nakažený) = 0,8 P(pozitivní|nakažený)
      =0,9 P(pozitivní zdravý) = 0,1 (1-0,9) P(pozitivní) =?;Summale: P(petitissm)
      = Ep(class, observation) Product rule: P(class, observation) = P(class|observation).
      P(observatis obě pravidla spojíme: P(pozitivní) = pozitivní, nakažený) + p(pozitivní
      zdra zp (pozitivní/nakažený). � (nakažený) +p(pozitivní / zdravý) - P(zdravý)
      = 0,9 .0,2+ 0,10,18,8 = 0,18 + 0,08 = 0,26'
    truth: 4
  9:
    pred: 3
    text: Učení, intuice, predikce, sebeuvědomnění, atd. Agent nemusí splňovat všechny
      aspekty, abychom mohli označovat za inteligentního.
    truth: 4
  10:
    pred: 3
    text: gradient - je to funkce, která nám vrací vektor největšího růstu z vybraného
      bodu vektor nám říká směr největšího růstu a délka rektoru strmost růstu). -
      mess-entropy - místo maximalizace hledáme naopak minimální chybu (logistická
      regrese), zde hovoříme o gradient descent, přičemž jdeme opačným směrem než
      vektor největšího růstu (hledáme minimum) - využití při odhadu parametrů
    truth: 4
  14:
    pred: 2
    text: Při učení s učitelem máme trénovacích dat páry vstupů a výstupů (výstupy
      obsahují target neboli očekávanou třídu) Při reinforcement learning u trénovacích
      dat nemáme očekávanou třídu, ale namísto toho máme hodnotící funkci, která dává
      zpětnou vazbu.
    truth: 2
72819d573f479644e0f732b57bc8f13b:
  2:
    pred: 0
    text: MAX;MIN;6000;06666
    truth: 4
  6:
    pred: 4
    text: P(N) = 0, 2 P(+ IN) = 0,9 -IN) =0,1 P(-12) =0,9 -|N) = 0, 1;PlN;+;RIHL;P(4)
      = P(4|N) + P(2) P(+|||||||||||||) 91 9,8 92
    truth: 4
822e8aa7d1298ea2436fe611946b994f:
  2:
    pred: 4
    text: 'MAX;MIN;6666;c);60 560;- v pvój rete je vybratě vin-- z - v druhej první
      prvk je -3 : říše je jasné, že je menší zko prvou v 1. vetre � hedže dalšía
      vrstva je PAX, legiony sa bude brať váží prav, kt. je v povoj sestre a kdyže
      v tejto vetre sme našli 3, větší prvok ale z určit větve;nerozezname leto hladíme
      nejmenší povoz'
    truth: 4
  3:
    pred: 4
    text: '- hodnoty v stavech - ceny hrán;- nednota pri hranách - neuristiky;heuristika
      je horšía zko skutočnosť, no je únerý horší a pre všetky cesty'
    truth: 3
  6:
    pred: 4
    text: '0,1 p(P) p(PI N|=0, a) P(P|N) = P(PIN) = 01 P(N|FEOIZ, PLNIKO, 8;skutečné
      pozitivny: 0,2 . 0, 9 = 0,19 fotočne pozitivny: 0,9 . 0,1 = 0,08;0,26'
    truth: 4
  7:
    pred: 4
    text: 'druhého řádu:;W2x + N1 x 1 w|x ?;negeneralizuje - teda nie je dostatočne
      všeobecný na to, aby modeloval aj iné ako trénovacie dáto v tomto případe nemodeluje
      správne znitie;- to že model negeneralizuje môže byť sposobeně vizovými fotekrmi
      - môže problémom môže byť malý počet dát, k čo spôsobuje pretrénovanie - řešenie:
      víze dát - pri polynomiálnej regresí je ale všešinou hlavný problém v zvolenom
      ráde polynomickej funkcie, řešenie - zníženie řádu -'
    truth: 1
  8:
    pred: 2
    text: generativny meder - modeluje rozloženie pravdepodobnosti, z kterého je výsledne
      možné pomocou experovat vzorce dopočítat pravdepodobnosti před - výhodou je
      že je "obnedzený" nejakým rozložením a z toho dovodu nemá - napr. goussovský
      klasifikátor z tendenciu diregovať diskriminativny model - priorno modeluje
      pravdepodobnosti tříd - napr. logistická regresie
    truth: 1
  13:
    pred: 3
    text: offention mechanizmus je založený na tom, že pri klasifikáční resp. inej
      úlohe provincij s textem, většinou vyskytujúcích so nezáleží len na slove /
      tokene na danej pozicii, ale aj na slovácký rovenoch pred zlobo za daným stavem
      v selvencích - aby táto informacia bola dobre dostupná (nemusela si postupne
      propagovať cez prvky rekurentnej vrstvy, čím se degeneruje) je možně použiť
      attention, který spočíva v tom, že uprý prvot má přístup ku všetkým slovům/tmenou
      daněj vstupej sekvencie, vety přímo pri affektion má každé slovo vstupnej very
      definovanú váhu, která hovoří ako velmi slovo  ouplynuje práce určované slovo,
      třeto váhy sú predmetam učenia;používa se nápríklad při prehradě textu do mého
      jazyka
    truth: 4
8310871a91f6396928f7e50acd47c2d3:
  4:
    pred: 4
    text: 2;„;5;6;7;8;10;*;X;5;X;X;X;X;+;+;X;D2;X;X;X;X;X;X;X;X;O;X;D2;X;x;X;X;X;X;X;0;X;X;D1
      = 233 23 D2 D3
    truth: 4
  13:
    pred: 2
    text: '- základnou myšlenkou, je pridanie určitej významnosti slov vo víte. máme
      nejdie vstupné tokeny slov a každé slovo má svoju pravdepodobnostnú hodnotu
      na základe, kt. sa rozhoduje, že ktoré skoro udáva význam, čo pomáha popríklad
      pri preklade do iného jazyka, případne pochopenie kontextu na doplnenie napríklad
      skúmanej otázky'
    truth: 2
  14:
    pred: 2
    text: učenie s učiteľem. pointa spočíva v tom, že dáta sú anotované čiže model
      sa učí na základě toho;posilované model dostane race data a sám musí zjistiť
      výsledek, po správnom dokončení úlohy dostáva nejakú odmenu a na základe toho
      sa učí - dá sa využíť napríklad na hru stayeraft, šach..
    truth: 2
845c61b8d1361a7636cf773d6064cb46:
  1:
    pred: 1
    text: zapamatování;těchto;starší;dodávky do obo-;se vydá rovnou směrem k uzlu.
      Díky zapamatování a nevěří tudíž zbytečně levé a prostřední podstromy
    truth: 0
  6:
    pred: 0
    text: PINAKI = 0.2 � P(POS||NAK) = 0.9 P(NEG/Z) =0. 9. p(posla =?);P(POSIZ) =0.
      1;p(pos) . P(NAKIPOS) P(POSINAK) = PINAKI P(POS||NAK) = PIPOSINÁL) PINAKI =
      0, 9. 9. 92-0. P(pos, z) = PIPOSIFIZ) - P(z) =0. 1. 0,8 - P(POS) = S P(POS,
      x) = 0, 18408-0,
    truth: 4
  13:
    pred: 2
    text: lépe pracuje s odměnami v rámci učení NS při rozpoznávání textu, odpovědi
      na textové otázky
    truth: 1
87b28a4dac30a111c366b6933f33c004:
  3:
    pred: 4
    text: klub (erl. gtn);H;tolní=;hints;o;h(h) - 10 gluko;e sa cestou ryperie bližšou
      k heuristike aj heď nedávno optimist. odhad;bez;10 není galez - 0 t(u) = 12;piklus";g(4)
      =5 thal = 9;hCul=o g(n) =11 tín) = 11;0 2;h(hlubo g(n) = 8 thl = 8
    truth: 4
  4:
    pred: 4
    text: D1 = {1. p. J. L, F, F, F, R. X, 163 D2 = {1, 7, 7, 8, 8, 8, 8, 9, 163 D3
      = {1, 2, 3, 4, 5, 8, 8, 163;D1 = {3 Disk 93 D3 = {8}
    truth: 4
  7:
    pred: 2
    text: OBR.;trénovacie dáta;N = 13;blížící očakávaná naučená funkcia;OBL. 2. 9;N
      = 13 k = 12;po;naučená v skutočno pri stupni velkom;alebo ak sme zvolili príliš
      velký stúpeň shájíť ho zmenšiť = ale pre prípad k =2 je vhodné nagenerovať riac,
      tr V prípade, že by sme zůolili velký;OBR. 3:;h = 2;očakávaná ako na;obr.;+
      ne;presné;zle k = 2;en;stupeň polynómu môže dôšsť k pretrénovaniu aho na obr.
      2, ale pri и = 2 sa môže stať, že máme malé množstvo dát a natrénovaná funkcia
      nebude vhodne generalizovat.- Preto pri dobre zvolenom stupni <<2 � pridať více
      dát mocen napr. gausovským šumom 8. Ke stavbě klasifikátoru můžeme využít generativní
      model nebo můžeme použít model trénovaný diskriminativně. V čem se tyto dva
      přístupy liší? Uveďte konkrétní příklady modelů/klasifikátorů pro oba přístupy.
      Jaké jsou jejich výhody a nevýhody?;naše
    truth: 2
  13:
    pred: 3
    text: Využíva sa napr. pr) doplňovaní textu na klávesnicích resp. aké je potencionálne
      dalšie slovo, pretože sa předpokladať, že sme viteli slová v určitom kontext
      tak je pravdepodobné, že nabudúce tak budú použité znovu.
    truth: 1
  14:
    pred: 3
    text: Při učení s učiteľom zvyčujue presne vlevae aký je presný požadovan výsledek,
      zatiať Eo pri RZ sa potřebujeme dostať do nějakého očakáva stavu ale netušíme
      ako konkrétne, přičom RC algoritmy môžu nájsť až prekvapivý výsledek akým dosiakliciel.
      Pri supervised learningu máme oanotované dáta, zatiať čo pri RL je aggent len
      vedený formou odmien za vykonané akce.
    truth: 3
87ec428b0fefd4586143fa90a6fa0581:
  2:
    pred: 4
    text: MIN;D;6;zde je to sebou;vstupné aby byl 1. dala podstromu;MAX;MIN;Se;o;počítací
      řez;výsledky strom
    truth: 4
  6:
    pred: 4
    text: P(zakončeno) = 0,2 P(pozitivní) vykosaný = 0,9 P(negativní) zdravý) = 0,
      a P(pozitivní) soký) = 0, 1;P(A|B);povětrnostní P(pozitivní) = P(zakoseno, pozitivní)
      + P(prvý, vozítení) P(nositní) = P(plnátní) vědecký). P(nkoro) + P(pozitiv|
      (soko). P(soko) P(pozitivní) = Ord. 0,2 + 0,10,8 = 0,18 + 0,08 = 10,26;P(posílání)
      = 0,26
    truth: 4
  9:
    pred: 3
    text: 'schopnost komprese internace (učení) - schopnost realizovat věznou setrioriální
      úlohu na základě skušenosti - sdorost interpretovat informace - schopnost vidět
      nemusí Př: tzv. varow AI být tyto osoby sakrem součastně. Stačí, aby algoritmus
      realizoval nějak specibidaci Činnost dobře.'
    truth: 3
  10:
    pred: 4
    text: V kontextu neuronových sítí se snažíme optimalizovat nějakou objektivní
      bunku. Uvozuje, že furu L je objektivní behee, potom gradient udává směr největšího
      nárůstu buku L - uhledem z malé změněné všech vrh. Jedná se 22 = grafick) tedy
      o soutěži parciálních derivací ve směru všech vah. Model optodrojene následovně
      obstarávané o 1/2 0 - 1. 20 jsme krásní vůči všem permatům Ostatní váhy C nové
      vody učící Martovka
    truth: 4
880e6fd1ec018d28c458796c730c184e:
  2:
    pred: 4
    text: MAX;MIN;Bože!;6006 38;V Taram podstavce má Ináč Min - 2, to znamená, že
      ak v pravo nájdeme číslo neužic ale -2, tráv max si aj tak rybovie - 2 a dalšie
      uzly teda nie je potřebně vyhodnocovať O Nehodu nemiť porodie, takže ešte nemáme
      žiada natrány a 3
    truth: 4
  5:
    pred: 1
    text: elen Doro je popísaný vektorem jen, který podstavuje převem hod Kvalita
      Pak potokujeme korenianční maticu ?. Sne v 30 a teda jen obsahuje 3 čísla, 2
      je natisa o velkosti 3x3, je rozdělenie zítra 3x3 - 12 veškerých čísel. Potřebujeme
      získať odhad je z rozděleních � 24 čísiel. Ponavek je možné odhodnuť meládou
      ML. P(dass|observation) = P(observation l doss) . P(class) P(observation) �
      EP(dservation loke) P(doss) obras Na základe rozdělením je možné vypočítať P(dekarchival
      das), P(class) máme z dat.
    truth: 4
  6:
    pred: 4
    text: P(poz) = ?;1;8 (poz Kult plných) = plastik (poz., plan) - Fyzika ) P(pozdrav)
      Pluk) P(vah X poz) GPLANI;P(poz Inak) = 0,9 P(neglinal) = 0,0;Olga -;(p(poz)
      = 0.9+0. 2. 0,1+0,8) p(p(poe) = 0,15 + 0,08 = 0,;dop;1vok) -0, 1,;p (poz) =
      p(poz) rak) . p(vak) p(pozitivak) p(znal);2
    truth: 3
  7:
    pred: 2
    text: dáta (tenoracie skutečná distib.;V takovomto píseme model nese pretína témacie
      dáta, které máme k dispozicii. Skutečná distribucia však má sběr lineárny tend.
      Pre lyžím generalizaci by sme v tomto prípadě mohli zvířiť stupeň pohynem alebo
      dodať moc hémanésch dát, kde by sa nejevila data preténováného modelu.;více
      dát a k =2
    truth: 4
  11:
    pred: 2
    text: con;64x64 x 3;�;o;omezený;xxx 3,3x16;BuRA 5x5x32;1 px vidí se ta;64 x 64
      x 32;prvej vrstvy;64x64 x 16 1 pixel vidí 3x3 px a 3 honičky;1 pr vidí 7x7 px
      z povodného vstupu
    truth: 4
  12:
    pred: 3
    text: Bidinechoval vek. vstra spravována vstup schenčie z oboch svera (od zač.
      po horizo + od horca pro zač.) oproti běžnej vehrenkej uste, která pracuje ten
      jednosverze. Výstupy obsah nechodou a pak hodnocené pe vyhodnotenie výsledku.
      Nevýhodou je samozřejmě zlobitejší (neuronyjší) výpočet (více operací). Musíme
      takhle poznať honiec danej schencie a teď schopny jie obrátit. Výhodou je, že
      pri rozhodovaní môže spracovat širší hodlest, využit informacie z dalších „z
      budúcnosti“, které vek. vrstva uvidí.
    truth: 4
  14:
    pred: 2
    text: Učenie s učitelem - dáta sú dvojice (vstup, ciolog, výstup). Máme teda jasne
      definovaný cid. Vieme, že sa má daná NN naučiť, prevenc řešenie. Reinforcement
      learning - viel nie je jasne detinerový. Chceme aby sa agent videm dostal, ničeo
      změnil a za to získana odmeny. Nevieve však ale tohoto dorama docíliť, očala
      veme, že to ogar získá a naučí sa. Agent musí najet všesonie, napomóc ho dopadne.
      Nichody však nače byť podléhám vůbec výš správce vietnie problému. Agent vytvořena
      akcie, které hodnotíme odverenou alebo získa odnem až na konci.;Vrouc ohodnotit
      úpladky porovnat loss fcie, u kterej sve schopný počítať gradient. Pri posilovani
      není však može být vyslechnu nejdá hodnota počítať gradiew
    truth: 4
89b8ce031e1483c47fb6f8f8aa150a96:
  5:
    pred: 4
    text: 'Pro gaussovský klasifikátor je třeba pravděpodobnost každé třídy (prior)
      P(A), P(B) oba se počítají podílem mezi počtem prvků zdaně třídy a počtem prvků
      celkově. Dále je třeba hustota pravděpodobností pro každou třídu: p(data) třída)
      kterou aproximujeme pomocí gaussovského rozložení, tedy je třeba spočítat střední
      hodnotu u a rozptyl 0? Takto máme vše co je potřebné pro výpočet Baxessova vzorce
      P(class) P(dato Htída) P(cluss|duto) = P(dato) Celkově tedy 6 reálnými čísly
      2x prior, 2x ju, 2x0? Parametry je, o odhadu Ze vzorců, které se dají vypočítat
      metodou maximální věrohodnosti. Poté co přijde dato, pravděpodobnost pro všechny
      třídy a poté zaleží, jaký přístup volíme - Jestli nám stačí P větší než 50%
      nebo potřebuje nic toto.'
    truth: 2
  10:
    pred: 4
    text: Gradient obecně udává směr růstu nějaké funkce, proto se využívá největšího
      při trénování neuronových sítí, kde naopak potřebujeme směr největšího klesaní
      (stačí vžít opačný směr, než nám vdává gradient). Díky němu je možné adekrátně
      upravit váhy jednotlivých neuronů po vypočítání loss funkce.
    truth: 3
  11:
    pred: 4
    text: '3. 16. 3. 32.32 - 5.3;= 322.25.27.2 = 32 50.27;3.16.3.32 = 27.16.3;2;Perceptive
      field: 64x64 x (27.16.32)'
    truth: 1
  12:
    pred: 3
    text: 'Obousměrná rekurentní tříd umožňuje neuron. sítim vnímat lépe kontext v
      textu, jelikož narozdíl od normálních bere v potaz i části textu po aktuálně
      "počítaném" slově. Výhody: Lépe vnímá význam celé věty, či delšího textu Nevýhody:
      Náročnější výpočet'
    truth: 4
8da82df4606715cb145f7f979908efc1:
  5:
    pred: 4
    text: 'Pro každou třídu (2x): Pro každou dimenzi (3x): střední hodnota u Rozptyl;pro
      rozdělení;celkem 12 parametrů;Parametry odhadneme např. metodou maximální věrohodnosti
      Pravděpodobnost je určena na základě hustoty pravděpodobnosti'
    truth: 1
  14:
    pred: 2
    text: Při učení s učitelem jsou dány příklady a jejich řešení, zatímco v reinforcement
      learningu jsou stavy hodnoceny dle určité metriky/ zdatnosti
    truth: 2
8e74b62c6d2cfebfb003da2801a4b51c:
  4:
    pred: 4
    text: X1=xxx2 x32x41 X3LXR x3 LX? 2x1 KX3LXA X1=3 333 X2=9 X3-8 Platí omezení
    truth: 3
  10:
    pred: 3
    text: Jedná se o výpočech chyby pro danou neuronovou vrstvu a využívá se následně
      pro přepočet daných noh ve vrstvě
    truth: 1
  12:
    pred: 3
    text: Jedná se o vestu které jsou symetricky napojeny to znamená, že je obousměrně
      propojena. Výhoda je že prochází se více napojení, tedy jednotlivé vstupy mají
      mezi sebou více informací nevyhodou je, že se prodlužuje trevování takovéto
      vrsty a je náročná na vypočetní zdroje
    truth: 1
  13:
    pred: 3
    text: Jedná se o nechanismus kde jsou zakomponovávány kontextové informace. Výhoda
      oproti rekurentním vrstvám Je taková že nejsou přímo na sebe napojeny pozorně.
      Používá se třeba u klasifikace textu protože zde můžou být jednotlivá slova
      na sebe napojeny skeze kontext věty a né čistě pozičně jednotlivá slova je tedy
      potřeba brát v potaz kontext jednotlivých slov vůči ostatním
    truth: 2
95170a66b5c9d563dbc0e4b54257ce21:
  3:
    pred: 4
    text: počet hran do konečného stavu;x
    truth: 4
  4:
    pred: 4
    text: s;7 89 10;XI 123 92 456.78 xX2 = 9, 11 (2, 4) (3, 9) x3=2x1=1=1, 4=1) z
      levé soboty s;X1 = 3 x2=9 = 8
    truth: 3
  5:
    pred: 4
    text: Střední hodnoty — 2 realná čísla (pozse;v 2D);rozptyl - 1 malné číslo Celkově
      6 reálných čísel (3 pro každou třídu) Vypočítáme odhad (maximálně věrohodný
      odhad) a rozptylupro každou třídu zvlášť. Pole toho těchto parametru a přichozího
      vzoru spočítáme hodnoty funkce pro obě třídy a třída s větší hodnotou bude výsledek;zdat,
      střední hodnoty
    truth: 1
  10:
    pred: 0
    text: Vektor parametrů neuronové sítě pro ,který dojde k nejlepšímu zlepšení Loss
      funkce. změny
    truth: 3
  11:
    pred: 0
    text: B
    truth: 4
9781c25581b0bc5fc82354b7451d0ecb:
  2:
    pred: 4
    text: MAX;MIN;6606;366;6;Zde se bude urourávat.
    truth: 4
  9:
    pred: 3
    text: '- Schoanool se Mozhedoval - Schopnost si pamatovat - Schopnost zhodnotit
      nezavislost, autonomie - Schounost se učil;Ne, například automanie, někteří
      agenti potřebují nápovědu, řízení, plán. Přesto se dají povinnost za inteligentní'
    truth: 3
  10:
    pred: 4
    text: Vysvětlím na alg. suudient descent, který se používá ve dávi;optimalizace
      při ladění parametrů NS. Paunelu je n- raněný vektor (souřadnice) v nějakém
      x - rozměrném prostoru, resurentně fci ve kterém je fce NS. Pomocí derivace
      - hledání lok. max/min můžeme říci, jakým sněhem se máme ubírat. se Parciální
      derivace � gradient � sněm růdu Puchtický p. Spočítáme součástí derivace a odečteme
      od souřadnic summetrů daný vektor Hledáme totiž minimum.
    truth: 4
a09c8d53abd337abc16d29197cdb3114:
  5:
    pred: 2
    text: '- klasifikátor je popsán rozdělením pravděpodobnosti pro každou třídu +
      jejími apůjčování pravděpodobnostmi (P(P|x|c) a P(c) pro každou třídu) s;na
      datech je tedy nutné odhadnout dané P(x|c) a P(C) pravděpodobnostní rozdělení
      každé třídy je popsáno Gaussovskou funkcí (která se získá odhadem jejich parametrů
      - střední hodnota + rozptyl z metody max-likely hood) (2 čísla) pravděpodobnost
      třídy je jen jedna čísla (jedno číslo) odhad zjistíme z dat pomocí metody max-likelyhood
      (prav. rozdělení P(X|C) a odhadem p(c) jednoduchým výpočtem poč. prvků dané
      třídy;P(C|X) =;oslavný poč. prvků;využití parametrů k výpočtu, že x patří do
      dané třídy;P(X|C) P(c) 5 PLXIY; PIYSTOL;o třídy'
    truth: 2
  10:
    pred: 3
    text: '- gradient slouží k úpravě vah při učení - počítá se parciálními derivacemi
      - ukazuje směr „posunu“ vah tak, aby lépe odhadovaly“ (aby odhad s jejich pomocí
      byl přesnější pomocí gradientu se hledá v „hodnotící“ funkci při úpravě vah
      se dělají drobné kroky dle směru gradientu (často proti směru)'
    truth: 4
  12:
    pred: 1
    text: „informace“ (zakódovaná) putuje neuronovou sítí oběmi směry místa pouze
      jedním nedochází tak k takový ztrátám informace při průchodu celou sítí oproti
      klasické rekurentní vrstvy (je ale výpočetně náročnější než její jednosměrná
      varianta) - pořád pro zachování informace existují i „lepší“ způsoby;záleží
      dle čeho hodnotím
    truth: 2
  13:
    pred: 2
    text: '- oproti klasickým rekurentním vrstvám se ve vstupní sekvenci vyhodnotí
      procento relevance daného prvku k aktuálnímu výstupu sítě řeší ztrátu informace
      průchodem skrze neuronovou síť, navíc odhaduje vliv každého „slova“ na konkrétní
      výstup používá se při zpracování řeči;8. 8. far? Z výše vstupu do volenie'
    truth: 3
a2ea1b9fdebff19434d6aebe076014c3:
  3:
    pred: 4
    text: huj=13;3+13 = 16;hon/=12 - zr2 = 19;1 hen = q;K;a + 8 - 17;12 619;6;h(n)
      = 9 soused 10+9=19 nalezli jsme o primální řešení, i když odtud nebyl o primistický.
      ne vždy ale tomu tak bude, můžeme nalézt řešení (pokud by jich bylo víc), které
      nebude o primální Proto je lepší dodržovat, aby byl odhad oprimistický ozn menší,
      než cena zbývající
    truth: 4
  6:
    pred: 4
    text: 20 je nemocných;nakážených;+10 20 = 18;P(polizirnú/naktors) � P(negativní|pokažený)
      � p(pozicivní (tedy ví) 1/10 P(negocioní/zdraví);10;tvrdému výjde pozitivní
      a 1/20. 50 400 z celé popule nakaženému vyjde pozicivní � 3. 2 = 28 10 4/10
      100 pravděpodobnost že náhodný člověk z celé populace bude pozitivní je 21,00
      = 26 %;1
    truth: 4
  9:
    pred: 3
    text: Musí být schopen samostatné práce, samovolně vykonávat nejrůznější činnosti
      Rotvijer se vklanném Nerozeznatelný od člověka � Turingův test � ten slouží
      jako test tak je AI inteligentní, ale rozporuje mu to test s historický s činskou
      knihou Dněšní AI spíše nástroje v jednotlivých úlohách. lepší než lidé (hra
      šachy), ale ta inteligentní je všeobecně nepovažujeme, protože je to to jedině
      co dokážou
    truth: 2
  11:
    pred: 3
    text: '...;ObA =;32;192 :32 = 6;12;2;Bluma;ANSEZL: 2 = 4;u 1. na oblasti 12 x
      12 u 2. na oblasti 6x6'
    truth: 1
a361f97e453d3152ae439fc90420519d:
  1:
    pred: 3
    text: OOR;AND;Z uzlu AND musí všechny poduzly vést k řešení. Je tedy nutné si
      zapamatovat, zda jeho podvzty k řešení vedou. Pokud výme, že vzel 1 k řešení
      vede, není nutné ho vyhodnocovat
    truth: 2
  3:
    pred: 4
    text: 59;být;Platná heuristika - musí optimistický odhad ceny daného vxlu do cíle.
      Reálná cena musí být větší Heuristika levé větve je větší než skutečná cena,
      přesto je toto řešení optimální.
    truth: 1
  4:
    pred: 4
    text: D1 = 51, 2, 33 � 4 D2 = {1, 4, 9} D3 = {3, 5, 7, 7} 8;D, = {2, 3} D2 = {4,
      9};D1 = {3 D2 = {9} D, = {63
    truth: 4
  11:
    pred: 2
    text: pix obrázku;16x3x3;aktivační mapy;Dein;strana na počátku 4 des Ausganges
      der Gegner po nich na konci roku 1950.
    truth: 2
  14:
    pred: 2
    text: Učení s učitelem - sada oanotovaných trenovacích příkladů posilované učení
      - pouze cílový stav a funkce hodnotící akvální stav/posloupnost kroků
    truth: 3
a445e40a2ec10752c52981cc84406d80:
  1:
    pred: 1
    text: tato vetra vedie k riešeníu, takže si zapa mufám, že je řešitelná a keď
      sa objaví zasi tak ju nemusim skumať znova;� vrstávač - J splna;a viem, že tatu
      je splnitelně, takže nemusím to skumeť zas
    truth: 0
  2:
    pred: 4
    text: MAX;MIN;C;Tu moc ušpetriademie až tak nezaujmu - může ostať;Tím pádem odpadne
      potreba prohladávať 2 vzty - lebo už bude mať proťihráč aspoň - 3 a pre mňa
      už vtedy je výhodnějšia -2 z ľavého podstro;e;58;nebudú sa vyhodnocovať
    truth: 4
  5:
    pred: 1
    text: gausovský klasifikátor pre 3D data bude danř dáta sú 3d, tak to bude vektor
      Ex, y, z3 a kovarianční matica, ktorá bude např. -> např. -> např. sú popisané
      3 + 3.3 = 12 reálnými u rozmere 3x3 ! 001/1 číslami - odhadneme ich pomocou
      maximum likelthad metodou pre odhad parametrov;n- ču je strašná hodnota ale,
      keď že;p(c|x) = p(X|c) . poj;pex);tie parametre nám pomôžu vrátat tuto hodnotu
      p(x|c) je to rozloženie třech dat;pri;1D;pexio);observation
    truth: 1
  6:
    pred: 0
    text: p(nakazení) = 0,2;p(pozitivní|nakazení) = 0,9;P(nenakazenří = 0, 8);pozitivního
      úřadu;P(negativní|nenakazení) = 0, 9;AUTORITMEM KAMENDACE;P(pozitivní - nenakonec)
      = 0,5;p(pozitivní) =?;P(pozitivní nakazení) =;Rozpočtem = p(reztrum) nakazení
      � (nakažení) = od ...;nakazení pozitivní);P(vybudování hornicemi:;P(pozitivní
      = EP(poz, r) = Pozitinakuzenci = P(nakazy + P(pozinomako) - p(nenakaz) =0,900,2
      + 0,10,000, 8 = 0,18 + 0, 08 = 0, 26
    truth: 4
  7:
    pred: 2
    text: k=2 = kvadratická fca;je nakreslená perfektní parabola, která přechádza
      všetkými trénovacími bodmi a správa sa perfektně na třénovacích dátach - aby
      generalizoval (správal sa rovnako dobré aj na novích dátach) tak by sme museli
      pridať veľ a dalších trénovacích dát alebo napr zvířat stupeň polynomu (pri
      vysokých palmonu)
    truth: 4
  12:
    pred: 3
    text: v obojsmernej rekurentnej vrstve sú spracovávanľ dáta vobou smeroch - aj
      od začátku na komlec - až od konce na začátek normálna rek. vrstva spracováva
      vstupně dáta iba v jednom smere výhodou obojsmetné je to, že teď náhodou spracováva
      aktuální text a je na nejakom slove; tak ted že sa k něj dostali data aj z druhej
      stranu textu (od konca) tak má nějaké informace aj o té předchádzujúcé časti
      textu za daným slovem, ktoré může vružit pri spracovaní
    truth: 3
  13:
    pred: 2
    text: používa sa napríklad při přepise ručného písma na tlačené pozera sa na aktuálnu
      poziciu a řeši tú � pozerá sa aj na predoště váhy v representative � R reprezentative
      � E;-> oproti rekurentněj môže brť výhoda to, že su informacia nepředává medzi
      jednotlivými vrstvami kde může dojít k strate kontextu
    truth: 2
  14:
    pred: 2
    text: priučení s učitelem trénujeme nejaký model na vstupních dátach a dáme mu
      aj požadovaně vřstupni takže sa učí mapovat vstup na výstup - aby neskór vedel
      spracovávať nejaké nové, zatial nevídeně vstup na výstup;učenie s učiteľom má
      trochu inř pristup, kedy mi akgoritmu povieme čoho chceme dostahnúť (napr. vrhaj
      hru v Go); môžeme mu dať aj nejaký dataset nejakých hier odohranžen;� ale myšlenka
      učenia je založená na odmeňovaní agenta po tom ako dosiahne nejakú úspěšný stav
      a musí sa sám učiť rôzne sekvencie funcov, ktoré sú dobré a to sa učí pomocou
      odmien, které dostává
    truth: 3
a9136ac9b16f7ea1952a9452789ba685:
  2:
    pred: 4
    text: MAX;MIN;660;O;MAX;MÍN;56;nebudou vyhodnocovat)
    truth: 4
  3:
    pred: 4
    text: o;- půjde prvou optimální stravou, jelikož je i Jak reoplanistické turistiky
      stojí horší jako prvá
    truth: 4
  5:
    pred: 3
    text: P(x|= p (x|x|c) = to) = N|X|XIX - parametry pro tento klasifikátor jsou
      N a Z odhadnu je pomocí rozumu likelihood (M2);VEROJE IST;z 3 pometry pro střed
      navrátilého rozdělení ve 3D;-střed i korespondenční matici napočítáme pro každou
      za dvou tříd (ML odhad z dat) tím získám rozdělení pravdepodobností oken tříd
      K výpočtu než příchozího nám využijí Byasin navec;- odhad;pt;100 I;ekonomické
      ratio 3x3 diagnúlně spatrická přišuš koroptvou mezi jednotlivými složkami;Ex
      y Erz ĚNY EXY ETY Str 927 ka ka - NDALE - NDT - odhad;P(třída|x) = p(x|třída)
      . p(třída,;žili z;Pfrücke) - 2 dat NF, da;P(x);P(X|třída) - zde využijí ML odhad
      P(x) = E. Pix|trina) P(třída)
    truth: 4
  7:
    pred: 3
    text: jelikož je K vyššího řádu jak 1 přejdu o lineární funkci, ale obecně složitější
      tuto funkci jsem rozkreslil jako hodnotickou (nebo jí blízkou) tato model na
      pravděpodobně vynikací váhy no ani - nodel regererativní, jelikož ve spodní
      části dostatečně naproximuje body - může to být způsobeno malým množství dat,
      což není nutně tento případ, větším problému je nalé číslo polynom, muselo by
      se tedy zvolit musí polynom KP2
    truth: 1
  9:
    pred: 3
    text: '- agent nemusí vykozovat všechny aspekty inteligence, stačí jen některé,
      přesný popis inteligence nelze říct a není ani detinován (asi vážne co k inteligenci
      vede) - schopnost učit si - mínání - intrice - vědomí sama sebe - dorozumívání'
    truth: 4
  12:
    pred: 3
    text: '- data v ní provádí oběma směry, nejdřív a poté se propagují zpět nevýhody
      - pri učení se rychleji ztrácí gradienty a nemohou být příliš dlouhé;z jedné
      strany na druhou'
    truth: 1
  13:
    pred: 3
    text: Využívají se při zpracování textu (často dlouhého) - myšlenka je určit pravděpodobnost,
      že předchozí slovo má na aktuální výstup silný vliv algoritmus poté v každý
      racet vidí celý předchozí vstup a na základě těchto pravděpodobností si vybere
      pro něj rekvartní data - výhoda je, že se nemusí v průběhu práce nevracen síti
      ztratit informace, která byla na začátku a například kompletní ovlivň výsledek
      - nepříklad na začátku věty bude „Neplatí, že...“ a následují dlouhá útrp u
      takovostních sítí by se tato regard ztratila
    truth: 4
ae33cbac77078f1eda59f172d652d171:
  3:
    pred: 4
    text: e = 2 h = 10;e-2 h - 8;R=2 h = 15 e=2 h= 20;/2 = 1. R = 5
    truth: 2
  7:
    pred: 4
    text: Pokud řešení negeneralizuje, znamená to, že byl na trénovacích datech přetrénován,
      což v tomto případě znamená že následuje každičké dato. i když se zjevně jedná
      o extrémní případy/auomálie. Jedním z řešení by bylo buďto trénovací data vyčistit
      o anomálie anebo sehnat více trénovacích dat, které zahluší případné anomálie.
    truth: 1
aeef4c7ede8edca955193889aacf551d:
  7:
    pred: 2
    text: teď si nevspomenu jestli lineární fce je x =1|x50 Jintce pokud by to bylo
      k =9, tak K =2 by parakela ale následující byla parabda. nebo M nakreslil jsem
      x který minima sqvere error, aby fce správně reprezentovala určená data. Model
      negeneralizuje protože vstupních dat neobjevují odtehlé hodnoty.;Pro generalizaci
      stačí zanést dostat dostatečný počet, aby reprezentoval data.;*
    truth: 1
  9:
    pred: 3
    text: Aspekty jsou - precepce - autonomitu - sebere Alexe atd...;Agent nemusí
      vytažovat všechny aspekty, abychom ho považovali za inteligentního
    truth: 3
  12:
    pred: 2
    text: obousměnná retrurentní vrstva povoluje zpracování dějina směry dl;normální
      referentní vrstva dokáže pouze dopředné zpracování ->;nevýhody - je komplexnější
      výběr
    truth: 2
b1d20c748b7d25f2fd7a96cd3b7b8658:
  3:
    pred: 4
    text: hib;=2100;999;665;h(0) = 3 � nadhodnocení (má být max. 1 KART.;� heuristika
      -> pokud se stane, že je heuristika nadhodnocená „rovnoměrně“ (tedy navíc tak,
      aby se zachovalo pořadí hodnot fIl) jako u vhodné heuristické funkce), pak to
      obecně nemusí tolik radit...
    truth: 4
  4:
    pred: 1
    text: X a 9;10;D3 = 84
    truth: 4
  6:
    pred: 4
    text: p(observation) class);p(class|observation);p (observation);p(pozitivní)
      � 2?;- obsahující pouze testy podivné;prezidiavant;p(class);p class = nakažený;observation
      = pozitivní;p(nakažený) = 20% p(pozitivní (nakažený) = 90% p(nezatažený|negativní)
      - 90% p(negativní|nezakažený) = 90%;(pozitivní, nakažení) = p(pozitivní) nakažení)
      x p(na) p(přízna) z 09. = 20% 90% = 18% plánovacích loss p(pozitivní, nenakažený)
      = p(pozitivní|nenakažený). p(nenakažen p(pozitivní|nenakažený) =10% = 10% (100%
      - 20%) = = 0,8.0,1 = 89 o (pozitivní) = p(pozit, nakaž) + p(pozitivní, nenákaž)
      =
    truth: 4
  7:
    pred: 4
    text: 'data:;model: f(x|x) = x? (w|=1, w|=0, wo =0);- model přímo prochází všemi
      vstromími body � pokud předpokládám, že je v datech přítomen gaussovský šum,
      pak je model přetrénovaný a tedy negeneralizuje. � potřebujeme trénovat na více
      datech, ideálně se stejnou x - souřadníci tzn. odvidně zašuměná data, kde ta
      = fut e, např.: č'
    truth: 1
  8:
    pred: 2
    text: 'generativní model se snaží odhadnout hustotu pravděpodobnosti, např. pro
      dané třídy a jejich sledované znaky = garanesovská klasifikace model trénovaný
      diskriminativně se naopak snaží najít pouze Obecnou funkci, která dokáže nejlépe
      oddělit třídy a klasifikovat je logistická regrese;Výhody generativního + funguje
      dobře i pro malou sadu trénovacích dat + skládá se ze samostatných podmodelů
      - při jednoduchém modelu je snadno uchopitelný, ale model se obtížně škáluje
      diskriminativní: - potřebuje relativně více dat aby se naučil přesně klasifikovat
      + poskytuje end-to-end řešení, lépe se skaluje, protože neobsahuje submodely
      nemůže ani tolik narůstat jeho komplexita více používaný'
    truth: 2
  11:
    pred: 3
    text: Velikost perceptiva;fild aktivací 2 vrstvy;je 7x7 pixelů;5x5 1. vrstvy;5
      tit. 1) x (5+11) =77
    truth: 4
  12:
    pred: 3
    text: V bidioectional vrstvě, probíhá a zpět přes jednotlivé iterace Sobota de
      výhody - umí zpěnně propagovat hodnoty předchozím iteracím � vhodné např. u
      složitějších překladů, kde existuje více variant slovo sledu -> pomalejší než
      „normální“ rekorentní vrstvy. Ne vždy je použitelno pro danou úlohu, ne vždy
      chceme, aby následující iterace ovlivňovaly výpočet u předchozích;výpočet průchodu
      tam
    truth: 2
  13:
    pred: 3
    text: � používá se v úlohách pro zpracování textu, jazyka.;� myšlenka je taková,
      že NS má přehled o pozici znaku/slova ve zpracovávaném slovu/větě;Výhody a nevýhody
      tlépe funguje na dlouhé víty / slova, které musí procházet mnoha úrovněmi rekurentních
      vrstev Může se hůře implementovat než RV, je pomalejší a nani nemusí být tak
      přesný.
    truth: 2
bc5bddaab7c3d9e082e47cbf3ff88fb8:
  4:
    pred: 4
    text: D, = {} H, 3, 3, 5, 6, 7, 8, 10} = 133 D2 = 2/2, 7, 8, A, 9, 2, 9, 103 =
      293 D = 21,2,3, 4,5,6, 8, D, 103 = 2, 2,83
    truth: 4
  14:
    pred: 2
    text: POSILOVNÉ UČENÍ MÁ ÚLOHY TVOŘENÉ VELKÝM SOUBOREM AKCÍ, A JEJICH VÝSLEDEK
      SE PAK OHODNOTÍ UČENÍ S UČITELEM MAPUJE VSTUP NA VÝSTUP.
    truth: 1
be96c674bbbb81dd11ef4e2551e7e813:
  4:
    pred: 2
    text: '*/ XX/x3 12 XXXIX *3/X x x;D1 = k 35 D2 = d 93 D3 = {5 8};+ X X X 3/6;A
      * X;8;X;8;X;1x;9 *;sp;12'
    truth: 4
  9:
    pred: 3
    text: '- inteligentní odpovědi (to, co agent říká musí mít hlavu a potu) - schopnost
      učit se entolie.;uvědomování si sebe sama;Určitě nemusí, stačí když bude vykazovat
      jenom některé astekty. Tady záleží člověk od člověka, co bude požadovat za důležité
      a jak moc, Dále bude záviset na typu narození agenta.'
    truth: 3
  11:
    pred: 4
    text: Vztah;1 Conv;2. 4no;64 x 64 x3ch;316;�;1929;Piroty:;5x5 x 3x3 = 25 x 9 £224
      pixelů (14 x 15) (na každý kanál vstupu;Aktivační moha:;545x32 x 3x16 x 64 64
      432
    truth: 1
  12:
    pred: 2
    text: Florická reluventní vrstva "vidí" pouze minulost. Pokud tedy použijeme Z
      sítě, kdy jedno otočíme“ naopak, pak výslední síť uvidí jak minulost, tak budoucnost.
    truth: 4
c22548046f82977bab5cf4ddd15e85e4:
  6:
    pred: 4
    text: aeroplan po 10;10 4/10;50 5/50 Z;100;26%
    truth: 2
  8:
    pred: 4
    text: '- generativní klasifikátor odhaduje rozložení hustoty pravděpodobnosti
      třídy diskriminativní klasifikátor odhaduje pravděpodobnost třídy - př: generativní:
      gaussovský (normální rozložení) diskriminativní: logistická regrese'
    truth: 2
  12:
    pred: 2
    text: '- Běžná rekurentní vrstva zpracovává sekvenci jedním směrem, což může pro
      delší sekvence způsobit nepřesnosti a ztrátu kontextu "z minulosti". Oboumožná
      jak propaguje informaci oběma směry, což může kontext celé sekvence opřesnit.'
    truth: 3
  14:
    pred: 3
    text: '- Pro učení s učitelem máme definovanou často rozsáhlou datovou sadu příkladů
      očekávaných výsledků pro vstupy U posilovaného učení máme prostředí, ve kterém
      agent provádí určité akce. Sekvence akcí (trajektorie) je pak ohodnocena odměnou
      nebo trestem. Početované učení tedy nemá žádnou sadu očekávaných výsledků, zlepšuje
      se se zkušenostmi a mohou získat nejvyšší odměnu. U učení s učitelem záleží
      na kvalitě a rozsahu datové sady'
    truth: 4
c2d512eacfd7f2f5ec2ca854914f33dd:
  5:
    pred: 4
    text: 'rozptolu je systém střední teoretickou a;třídineusinálů = vektor a velikosti
      3 spoju - (1/2) � kvarianční velice pro vztyl = a;3+9 = 12 - pro 1 třídu tedy
      24 pro 2 třídy.;mysly TN (x, pro, a) DParametry na těchto datech parametrů ML:
      PON Paurijeme Bayesův vzorec P(x|y) = D(x|X|X)'
    truth: 2
  8:
    pred: 1
    text: V dnešní době víc diskriminativní. O nebo 1 používá se signoida log. regrese
      rychlejší, míň parametrů, ale více dat. (přesnější);generativní model - linearní
      regrese - míň dat a používá MSE (mean sqrave error)
    truth: 1
  9:
    pred: 2
    text: '- ne nemusí všechny vybasovat, zda je inteligentní se určuje pomocí Teuringova
      testu;- přemýšlení, empatie, exerce, patyt, zastodování se'
    truth: 3
  10:
    pred: 2
    text: funkci, Paurává se pro aptimalizaci řešení vep jedná se o aptimalizační
      algoritmus (absektivní;- paraci gradientů se počíta labeilní minimum to díky
      parciálním derivacím - tato „aptimus“ lokální minima se hledá snáš pokud máme
      více dámen, oblast nevadí nám když to nepojdeme
    truth: 1
  13:
    pred: 3
    text: Používá se pro získání kontextu víry, můžeme procházet dopředu / dorodu
      a ne se dívat pouze na vektorátu 1 slovo, které je popojeno se všem rekurentním
      vrstvám je teoritickým na překlad jazyka pratocéd bývá v různých jazicích různá
      skladba vítr;Pavýáži se u otázek, skládá se ze ZNS, 1. vytváří vektor otázky
      např. Od kdy do bojů a2. NS hledá v specifikovaném odstoupi odpověď např L -
      ... od ... do 1 - "čtárlovú NS "
    truth: 2
  14:
    pred: 2
    text: nevidoucnost jeho definicience svalem stojanu pí;S učitelem - dostane trénovací
      data, nakterých se snaží nacvičit (naučit model správné rozhodovat, model je
      poté rozlišován další datovou sadou tentokrát i s odpovědně odhodnot - regrese
      - snaží se navagovat, dosad neuvidíme date;Reinfarmenant - silato pro vyřešení
      bez popisu, agent se snaží získat nejvíce hodů (největší skóre) nějakou postoupostí
      aperací (sipka dobrovol doprava) a autička co se snaží ujat na kopec nebo bít
      panáčka, další doba na třenist - hledá např silniční cestu podle pst. Policy
      gradient - atochvcuje akce
    truth: 3
c3c31375a3563d49cfe6448288177c8f:
  1:
    pred: 2
    text: 5;Pri prohladávaní s neistotou musíme expandovat všetky za spočítanie napríklad
      priemerného výsledku, který můžeme dosáhnut v neistejčasti. Ak si zapamátáme
      stany ktorú vedú k riešeniu, môžeme v inej časti stromu který má rovnaké stany
      použiť zapamätanú hodnotu a nemusíme expandovat všetky stavy.
    truth: 2
  4:
    pred: 3
    text: z;3;5;6;7;8;10;1 X2 13;X X;X;X. X X;V X X;X X;X;X X X;X;X;X;X;X X;X;X D;x;X;D
      x;x;X;01 = 833 P2= 93 D3 = {8
    truth: 4
  6:
    pred: 4
    text: P(nabuzuj) = 0,2 P(to nenalezený) = 0,8 P(pozitivy (nakresy) = 0,9 (negativní
      nenakonec) 50, 9;P(t;Ra;0,9;0,18 0,08;P(Consisting) = P(pozitivy, nekurzy) +
      P(priting, negativy) 0,1. 08 P(lositis) = 0,2 0,9 P(Pozitivy) = 0,26
    truth: 4
  10:
    pred: 2
    text: Gradient sú parciálne derivace všetkých pramených koss-funkcí. Gradient;Gradient
      je vektor ktorý ukazuje smer k maximu loss funkcie. Využíváme ho na postupnú
      upravu vítr jednotlivých vrstiev NS tak, aby sme minimalizovali chybu Používa
      sa pri trénovaní. Fradient sa skladá z parciálnych derivácii pre jednotlivé
      promenné
    truth: 4
  14:
    pred: 3
    text: Pri učení s učitelim detinujeme úlohu záborom trénovacích dát, kde sú očekávané
      vstupy a očekávané výstupy. Při posilovanom učení definujeme aktuálny stav problému
      a akcie ktoré je možné vykonať. Následne definujeme hodnotiacu funkciu ktorá
      ohodnotí kvalitu lubovolného stavu. Neurónová sieť počat učenia skúša rôzne
      akcie, ktori následne ohodnotí, podľa výsledku hodnotiace, funkcie.
    truth: 3
c548f0dd09eef8e11eb900931a7c2b65:
  3:
    pred: 2
    text: R(N) = 569;JAR(A) = 100 Dalma = 100 čír;nalezne optimální řešení s cenou
      3
    truth: 4
  7:
    pred: 4
    text: Tečkami naznačeno původní funkce, ze které data pochází;vygenerovaných funkcí
      funkcí s gaussovských šum;Nahradil jsem 5 trénovacích dat a výsledek negrese
      (model). Model negeneralizuje, protože se nenaučil funkci, která tato data vytvořila,
      i když dobře probíhá trénovací data. Negeneralizace by se projevila otestováním
      modelu na více datech.;regulatizovat.;Aby model generalizoval, musel by být
      natrénovaný na více datech, můžeme také regresi
    truth: 4
  8:
    pred: 1
    text: 'Generativní model modeluje explicitně rozložení původních dat (tříd).;Diskriminativní
      model pouze hledá funkci popisující hranice mezi třídami.;Generativní model:
      gaussovský klasifikátor diskriminativní model: hogietická regrese'
    truth: 2
  11:
    pred: 2
    text: 3x5 = 15;15 x 15 pixelů vstupu;3+ (5 - 1) = 7;7x7 picelů; stride = 1;2.
    truth: 4
  14:
    pred: 3
    text: Posilované učení použijeme v úlohách, kde je těžké stanovit nejlepší akci
      ve stavu, nedokážeme/nestačí obabelovaná trénovací data. Pokud bychom se například
      učili žacty učením s učitelem, model nemůže být výrazně lepší, než hráči z trénovacích
      dat. Na druhou stranu s posílraným učením se může naučit hrát výrazně lépe.;Dalším
      problémem je obrovský strovský prostor her jako Sturcroft, kde ani nejsme schopni
      dostatečně velký dataset sestavit. V RL definujeme odměnovou funkci.
    truth: 4
c54fb9058a498e5d0a9138a3846352b4:
  8:
    pred: 3
    text: 'PISKRIMNATIVNÍ MOD.;O vÝRODA: pokud má náhonované pravděpodobnostní rozložení
      dat, mohu z něi vzorkovat data nová O výHoDA: stačí mu méně dat ONEVÝHODA: pomalu
      ší;Učí se unapování vstupních dat (x) přímo � x O NEVÝRODA: očekává více vstupních
      dat AVÝHODA: rychlejší než generativní O NEVÝHODA: snadno se přetrénuje na málo
      datech O GENERATIVNÍ MODEL modeluje pravděpodobnostní rozložení dat P(X|Y) a
      prior (apriorní pravděpodobnost) P(Y) PŘÍKLAD:;na výstup rabely (Y) příklad:
      logistická regrese k - nejbližších sousedů;Gansovský kvalifikátor'
    truth: 3
  9:
    pred: 3
    text: AGENTA považujeme (dle Turingova testu) za inteligentního, když nedokážeme
      rozpoznat, zda jsme odpověď na otázku obdrželi od člověka nebo od počítače (-agenta)
      Vycházíme při tomto tvrzení z předpokladu, že člověk je inteligentní.;ASPEKTU
      - porozumění problému — schopnost odpovědět na libovolný problém - schopnost
      udržet informaci o návaznosti otázek;Dle výše popsaného nemusí agent splňovat
      všechny aspekty. Stačí, když jeho chování bude velmi podobné člověku.
    truth: 1
  14:
    pred: 2
    text: UČENÍ S UČITELEM je definováno plně anotovanými daty. učení u všech dat
      ví, jaký je správný výsledek.;POSILOVANÉ UČENÍ je definováno směsí anotovanýma
      a neanotovaných dat. Alg. se nejezve naučí na anotovaných datech a poté svůj
      model potvrzuje na datech neanotovaných
    truth: 1
cd371a8615558884b8b143a0e59fa853:
  2:
    pred: 4
    text: 'MAX;MIN;obor Uspořádání vztahů: (označeno čísly) Pokud budeme vzly na listové
      úrovni procházet vzestupně od 1 do 6,;tak:;1) projdou se 2,-2, -1 a jako minimum
      se vybere -1 2) Vezme se nzel - 3 a protože - 3 r-2 a my chceme brát maximum
      (a soupeř bere minimum), zcela jistě bude pro nás výhodnější vybrat si cestu
      do -2, proto už nebudeme prozkoumávat úzly s pořadím 5,6 (a hodnotami 1 a 0)'
    truth: 4
  8:
    pred: 2
    text: Generativní model se učí rozložení jednotlivých tříd a na základě toho určíme
      pravděpodobnost každé třídy (např. Gaussovský klasifikátor). Diskriminativní
      model přímo počítá posteriorní pravděpodobnost jednotlivých tříd (např. binární
      klasifikátor).
    truth: 1
  13:
    pred: 3
    text: Attention se používá například při zpracování textu. Umožňuje např. rozdělení
      slova na jednotlivé symboly a zkoumat jejich okolí.“
    truth: 1
  14:
    pred: 3
    text: Učení s učitelem máme na vstupu trénovací data ve formě dvojic vstup - výstup.
      U posilovaného učení nemáme vstup - výstup, ale definujeme kdy dostane agent
      jakou odměnu a tím se bude učit, kterou akci má kdy provést.
    truth: 3
d232a2de95e7571e948018cd17abec91:
  5:
    pred: 4
    text: střední hodnotu a rozptyl (pro všechny tři dimenze) oboje jsou to čísla;čísly
      - 3 směrodatné oddylky x 2 třídy = 6 směrodatných odchylek 3 rozptyly x 2 třídy
      = 6 rozptylů;12;12 čísel;pro každou olimenzi každé třídy vezmeme data a spočítáme.
      střední hodnotu (průměr) a rozptyl data z discuse;o = 1/2 6m - 10);Pro nově
      příchozí data vypočítáme hodnoty funkcí rozdělení pravděpodobnosti. pro všechny
      dinenze pro obě třídy. Výsledky v rámci tříd agregujeme (např. součet nebo součin)
      a výsledky porovnáme. Nová data budou patřit do třídy s větším výsledkem.
    truth: 1
  6:
    pred: 4
    text: 'p (nes) = 80%;p(pos) = 20%;P(Tpas|pos) = 90% P(They (neg) o 90%;P(Theologies)
      = 10% P(Frost my) = 10%;Výsledek hea ples) p(mostem a slunci - P(Kulines) =
      92 Alois = 10,8 % = 0,000 = 10,72 /0,75/6 = To;P;počkal;Tras (ney Výsledek pozitivní:
      = p(pos). P(Trosleos) + p (nes) - P 20,2 . 0,9 + 0,8. 0,1 = 0,18 + 0,08 = 0,26
      = 26 %'
    truth: 4
  7:
    pred: 4
    text: To, že model negeneralizuje znamená, že přesně kopíruje trénovací data (na
      obrázku jimi prochází);Polyn. regres. Z řádu je parabela jsou trénovací data;Aby
      více generalizoval, můžeme buď přidat více testovacích dat nebo snížit řád polynomu.
      ctý To že molel generalizuje je způsobeno, že má příliš "volnosti" a díky tomu
      může přímo procházet trénovacími daty.
    truth: 3
  8:
    pred: 2
    text: Generativní:;Diskriminativní model:;Snaží se vytvořit model trénovacích
      dat. To se buď dělá pomocí modelování funkce hustoty pravděpodobnosti pro určité
      vlastnosti objektů z daných klasifikovaných tříd. Nebo lze vytvořit model pomocí
      regrese. Tedy konkrétní hodnoty vlastnosti chceme proložit funkcí, která se
      přibližně reprezentuje obvyklé hodnoty. nenerativní umí rozpoznat, pokud nová
      data epatří ani do jedné ze tříd.;Snaží se vytvořit funkci, která odděluje/rozděluje
      hodnoty vlastnosti pro dané třídy.;Piskriminativním stačí méně dat, aby měly
      přijatelné výsledky.
    truth: 1
  11:
    pred: 2
    text: 64 století;SKALI 16x383;32 x 5 x 5;25;225;vstup vstup
    truth: 2
  12:
    pred: 3
    text: Oproti klasické obsahuje tu obousměrná ještě jedna síť, která je sekvenčně
      uspořádaná opačným směrem. To umožnuje této síti analyzovat schrenční závislosti
      v obou směrech. vystup výstup p - Ost-Ost-ost... backward -> 0 -> - forkard
    truth: 4
d555cba20f78d0d585e68bb36b09b598:
  1:
    pred: 0
    text: sú rovnaké takže nemusíme vyhodnotiť dvakrát protože nejméně času si pamatoval
      abo skončil prvý výpočet. ale toto je správne takže idem do druhého podstromu
      a najdem rovnohý uzol
    truth: 4
  6:
    pred: 4
    text: P(mak);=20%;P(PO2| nok) = 90% P(NEGIZACe) = 90%;Ptabo) - 80% P(POL / zdro)
      = 109 (NEC / null) = 10%;P(POZIVACI =;PANAM;P(POZ) = P(POZIMAH);P(POZ| = PÍNA|P(POZINAN)
      + P(ZDR) P(POZI ZDR);p(pozi = 0,2 0,9 + 04 0,1 P(voz) = 0,16 + 0,08 = 0,26 26%
    truth: 4
  7:
    pred: 2
    text: N = 100%;mož příliš málo dát na to;aby dokázal odhodnout povahé rozloženie
      viz přejít Kn;trénovací dětství pro regresný problém;nepenezelizuje;treba prídat
      více dat na kterých by tu učil, případně zničit K ak je moc vysoké (nie náš
      případ)
    truth: 2
  9:
    pred: 3
    text: samostatnosť -;inteligencia nemusí - agent môžu byť vytvořený na špecifiká
      úlohu nemusia dosahovať i vo všechno;- lokalita - vedieť kde je - sebaučeno
      - všeobecnosť
    truth: 2
  10:
    pred: 2
    text: gradient je derivácia loss / objektivnej funkcie, využiva sa na učenie -
      teda aktualizaciu váh w sprodient Grodient descand, iterativne zmenšujeme w,
      snažíme se dostahnuť o Wiss = W - d DELW) distribuje za pomocou chcim rule do
      celej neuronovej siete;exercírny frostou - aho rýchlo se na
    truth: 4
  11:
    pred: 3
    text: 64 8b4 43;16x3x3 92X775;závisný na 49 půxelod ostrov obrazku 7x7 po prvej
      vrstve Spixdor � 3x3;X7 646
    truth: 3
  13:
    pred: 3
    text: nezáleží na porodi slov vo vete ale ich vyzname, napr aby sme správne preložili
      člen musíme vedřeť rod slova na ktoré sa viože. - používa se v prehlodačoch
      rekurentně ide porode a nevidí budúcnosť, ilu minulosť attention so víe poziet
      - aké slova nasledujú a no základe toho sa rozhodnút
    truth: 2
  14:
    pred: 2
    text: posilované učení - nevíme ale naď postup vyserať, výsledku - získava odmetry
      za správne riešenia / približujúce sa úlohu definopeně ako ciel ktorý chceme
      dostahnouť, nevieme oho vyzora správně rušeně, len jeho výsledek nopr - vyjdi
      kopec, vyhraj hru - musí se to naučiť sám, neb škodisticky počítat z nepatrých
      dát hier mejstra učenie učitelovi - učí sa na základě toho aby moc za pomýlil
      úlohu definujeme pomocou datasetu na kterom sa učí, kde sú oanotované správne
      výsledky učí se no základe už existujících dát, ten počet pravdepodobností že
      zvádaná akce je dobrá, sám je nevie vymyslieť
    truth: 2
da3b6e73d190569d13bfc0cc0a9420d8:
  4:
    pred: 3
    text: '1;2;3;5;6;10;XI;3;X x x x X X X X x X X inference nám ořezala jednotlivé
      domény do této podoby: D1 = {4 P2 = 59} P3=;x x X;X X X;X X X;x;X;X'
    truth: 4
  5:
    pred: 1
    text: Gausovský klasifikátor představuje generativní model (variance) je popsán
      střední hodnotou a koarianční maticí, pro odhad;parametrů pomocí Maximum likelihood
      je ještě potřeba apriory nějáká pravděpodobnost rozložení dat a pravděpodobnost
      jestliže máme třídinenzionální data, bude mít kovarianční matice podobu 3x3
      jak parametry použijeme k přiřazení do třídy? s použitím Bayesova vzorce, za
      předpokladu, že máme k dispozici approvní pravděpodobnost P(c|x) = P(X|c) .
      P(c);P(x)
    truth: 1
  10:
    pred: 4
    text: postup:;-gradient představuje nejrychlejší růst funkce (velikost grad určuje
      délku vektoru - V NN se využívá v technice Gradient descent, což je technika
      sloužící k optimalizaci chybové funkce - pro současné parametry se spočítá gradient
      a touto hodnotou nahradíme hodnotu původní. - zjistíme, jakým směrem se roste
      rychleji a vydáme se opačným směrem - takto stále počítáme gradienty, (pomocí
      ctlainvule), dokud není grad = 0, tzn. že jsme našli lokální minimum (což nám
      stačí, jelikož se často podobá vylobáním, lokální je rychlejší
    truth: 4
  12:
    pred: 2
    text: 'Rozměrná desatiletie V obousměrné rek. vrstvě se zpracovává 2 průchody,
      jeden zpracovává Zleva doprava, druhý naopak. oproti normální nek. vrstvě je
      tento způsob více efektivní, méně časově náročný. lze tedy zpracovat i více
      rozsáhlé texty;biderectional:'
    truth: 2
de7f6b87ebb6a75dfa0e4d185d920041:
  6:
    pred: 4
    text: nat;0,2;NAK ynak;8;NEG;2;72;20;80;populácia = 100;18+8;100;26;100;= 0,26
      = P(pos)
    truth: 4
  14:
    pred: 3
    text: pri supervised poskytujeme vstupné trénovacie dáta a správne výsledky (poznáme
      ich);pri reinforcement nepoznáme najlepšie možné reženie, ale motivujeme agenta
      na základě odměn, které dostává podľa měry přínosu akcií, které vykonává
    truth: 3
e18c2240077c9ff3503cb4cb2669f5c1:
  9:
    pred: 2
    text: O SCHOPNOST SE UČIT NOVÝM PROBLÉMŮM O scHopnost řešit problémy NA ÚLOŽKA
      o mít paměť OVINĚT KOMUNIKACÍ;JEN TEXTOVÉ);OPLNĚ POŽÍTEK TEXTU;ê na otázky odpovídat
      v rozumném ČASE;O JAZTK. VÝBAVENOST O TAMET OREAKCE V ROZUMNÉM ČASE DEMOLE O
      sEBEUVĚDOMĚNÍ DAPOD O POHYBOVÉ SCHOPNOSTI (ROTURIKA) o schopnost řešit problémy;NE,
      MNE BY STAČILO O KOMUNIKACE ODPADEŤ o schopnost řešit problémy OUČIT SE NOVÝm
      VĚCEM. 56 OREAKCE V ROZUMNÉM ČASE;Schopnost kOOPUNIKACE;Szole, Serence - Seel
      Aw. Gottb NeUÍZA
    truth: 4
  10:
    pred: 2
    text: OGRADIENT JE VEKTOR PARCIÁLNÍCH DERIVACÍ UDÁVÁ, KTERÝM SMĚREM FUNKCE NEJVÍCE
      ROSTEJ o my chceme ale se dostat do (lokálního) minima, ne MAXINA TAKŽE POSTUPUJEME
      V PROTISMĚRU ODEČÍTÁNÍ GADIENT VYUŽIJEME NAPŘ. V LOGISTICKÉ REGRESE GRADIENT
      SE ODEČíTÁ NÁSOBENÉ VHODNÉ ZVOLENOU UČÍCÍ KONSTANTOVÉ
    truth: 2
  13:
    pred: 2
    text: opoužití při pŘEKLADU ZE SEKVENCE SLOV NA JINOU SEKORDACE OPROTI REKURENTNÍM
      VRSTVÁM BERE V POTAZ SLOVA PO PÍSMENECIA opoužití u ručně psaných špatně čitelných
      SEKVENCÍ
    truth: 1
eb15628acdbcae020a12326ce6b1c8e3:
  2:
    pred: 4
    text: MAX;MIN;2;Následne v pravom podstrome by si mohol ako "prvó" vybrať - 3,
      no to "mg“ nechce tak ďalej ten strom už neprehľadávame.;Usporiadame ich od
      najmenšieho po najváččí, v ľavom podstrome si "protihráč" vyberie -2, ale aj
      tak prehľadá celý podstrom lebo nemá s čím tú hodnotu porovnať.
    truth: 4
  5:
    pred: 2
    text: konvariačnou maticou a odchylkou (rozptylova);klasifikátor je popíšu Matica
      3x1, rozpty 3x3, Sú reprezentované 12 timi číslami. Klasifikátor je po fietoparametre
      odhadneme paužitím MLE (arg, max p (x|h)) Uděla tomu potom vieme získať odhad
      hastoty pravdepodobnosti a apriorní pravdepodobnosť Na základe toho vieme pomocou
      bayesova vzorca vypočítač pravdepodobnost friedy pre nové dat p(x|t) p(t) p(t|x);P(X)
    truth: 1
  8:
    pred: 2
    text: 'Diskriminativny model sa snaží naučiť priamo hodnotu p(t|x). Napr.: Lineárna
      regresia;Výhody generativneho: - dokáže sa dobre naučiť aj na menšom počtu dát
      - po natrénovaní môžme generovať nové dáta (synteticke tváre,...);Výhody diskriminativneho:
      - dokáže sa rýchlejšíe naučiť'
    truth: 2
  9:
    pred: 2
    text: Kognitívne funkcie, uvedomenie si samého seba, čítať, písať, dokázať spájať
      veci do súvislostí;Nepotřebuje splňovať všetky tieto aspekty.
    truth: 4
  11:
    pred: 2
    text: 3x3 = 9 px;3x3x5x5;Závisí na 3x3 + 5 x 5
    truth: 1
  13:
    pred: 2
    text: Oproti rekurentným vrstvám je rýchlejčím, nakoľko narozdiel od nich nemusí
      čakať na výstup z predchádzajúcej vrstvy).;Používa sa napríklad k prehľade textu,
      scanovania račne písaného textu,...
    truth: 1
eb170b2998004abf17f07f3d2bdeb4cf:
  2:
    pred: 4
    text: 'MAX;MIN;od;S;MAX;A.A.;MIN;Prohledávání následovně: 2 -2. � 1 � - 3 �;Bluza;levá
      strana;pravá strana;pravá strana tak bude ihned odříznuta'
    truth: 4
  3:
    pred: 0
    text: 'Postup AX: SSAAAF h(c) není optimistický'
    truth: 4
  5:
    pred: 1
    text: 'středy rozložení: M, M2 = l k parametry normálního rozložení bude tedy
      potřeba 2. (3 + 9) čísel;=;odhadneme je např. pomocí metody max. věrohodnosti
      vypočteme p(c|x) tím, že do vzorce pro rozdělení dosadíme nově příchozí vzor,
      a vynásobíme apriorní šancí dané třídy p(c)'
    truth: 2
  10:
    pred: 2
    text: gradient je číslo které nám říká, jak máme upravit váhy, aby se nám zvětšila
      výsledná loss hodnota modelu (využívá se ale naopak - pro zmenšování chyby).
      Je výsledkem derivací, tedy je to vlastně nejen směr, ale illstrmost“ v daném
      bodu. loss“;- když jsme tady, gradient ukazuje tímto směrem �u;při učení je
      použit pro update vah vstupů
    truth: 4
  11:
    pred: 4
    text: Perceptive fild (L2) = 7x7 px Perceptive field (L22 = 4) = 5x 5 1/4X
    truth: 4
  14:
    pred: 2
    text: Zatímco u učení s učitelkem počítáme loss (chybu od správného řešení - je
      nutné tedy znát správné řešení), podle kterého model upravujeme, u RL pouze
      dáváme modelu / odměnu za provedení kroku, kterým se přiblíží k chtěnému výsledku
      a snažíme se tuto odměnu (či očekávanou průměrnou odměnu) maximalizovat. tedy
      použít
    truth: 4
ec4e79dd816915a29d6d64b954c5de69:
  1:
    pred: 4
    text: Algoritmus vyhodnotí se také větve jako stav, který k řešení vede při prohledávání
      v pravé větvi stav sz vyhodnotí rovnou jako úspěšný aniž by Stav se expandoval;S
      - cíl F - neúspěšný
    truth: 4
  2:
    pred: 4
    text: MAX;MIN;560 Kč -3 C 2.;tohle se odřeže - nebude se vyhodnocovat
    truth: 4
  3:
    pred: 3
    text: DATO/=20;S - cíl;Sklad = 10 RAPOD GALLYDY;klasic;AX přejde z počátečního
      uzlu (fils) = 20) rovnou do levého podstromu (R|s) = namísto pravého podstromu
      (p(s) = 11) najde tak rovnou optimální řešení.
    truth: 2
  5:
    pred: 4
    text: 'trojprokoný);reprezentující;u - střední hodnota - jedná se o vektor (R,
      RQ/R) 2- Rx2 matice rozptyl na ore z (R +);bolševická koalace naších;popotyl
      na ozvy (RK);Parametry: u - střední hodnota - jedná se o dvoupruhový vektor
      (R, R) 5-2x2 matice: 6 x c) rozptyl na ose n (RI) za pomocí konfirmace Bayesova
      vzorce rozptyl na ose y (R) se znalostí aj C;Parametry odhadneme pomocí metody
      maximální věrohodnosti využijeme je k výpočtu ji (c), p(c|X) si pak odvodíme'
    truth: 2
  7:
    pred: 0
    text: V
    truth: 3
  9:
    pred: 3
    text: 'např. emoční inteligence: „schopnost vnímat na vjemy, aritmetick inteligence;
      schopnost rozhodovat na základě vjemů Nejsou potřeba všechny aspekty; např.
      agent bez emoční inteligence se dá považovat za inteligentní'
    truth: 4
  13:
    pred: 3
    text: elevantních;Attention se snaží uchovávat důraz na předchozí elementy v pořadí.
      Vyhodnocuje pravděpodobnost slova na základě (minulých) slov v sekvenci. Výhodou
      například je, že zde nedochází k velkému gradient decay;Používá se například
      v překladu
    truth: 2
  14:
    pred: 3
    text: 'svou metodikou co nejpřesněji aproximovat;Učení s učitelem Program se učí
      na základě testovací sady dat, které jsou anotovány očekávánou hodnotou klasifikací.
      tak snaží aproximovat netolik Posilované učení: má definovanou Program množin
      stavů a akce nad těmito stavy. Akce má ohodnocené odměnou. Stroj se snaží modifikovat,
      provádění svých akcí v závislosti pravděpodobnost na stavech tak, aby maximalizoval
      odměnu;očekávané'
    truth: 3
ee09d9aaa8474a6513133aa8452fad6f:
  7:
    pred: 1
    text: p;tečky v grufu zobrazují tvému vací data zobrazuje regresní Čára - model;Model
      negeneralizuje z důvodů špatného rozložení tažen dat malého vzorku trén. dat
      špatného zvolení řádu polyn. regrese
    truth: 0
  9:
    pred: 3
    text: '- generalizace - uvědomění - komunikace - znalosti;- nemusí vyhovovat všechny
      aspekty'
    truth: 4
  10:
    pred: 1
    text: '- úprava parametrů při učení NN (gradient descent)'
    truth: 1
  14:
    pred: 2
    text: nemá anotovaná data reinforcement learning - výsledky jsou ohodnoceny funkcí
      - tresty za špatné výsledky / odměna za správné výsledky učení s učitelem ->
      trénovací data jsou anotována správnost modelu ověřována na testovacím a validačním
      datasetu ověřuje správnost při trénování
    truth: 3
ef1da85ed907b35a0b27aab2472edbb5:
  3:
    pred: 4
    text: 2 nebo;naša;heuristika
    truth: 4
  4:
    pred: 4
    text: XI = X2 X3 S2X11;x s2x +1 X, LX2;D1 = {1, 2, 3} D2 = {1, 4, 9} b3 = 5, 8,
      9, 10 představenstva D2 = {4} D3 = {1, 8} D, = {3 Buf;0, = 283;0, = 52 D2 =
      {93 b) = 283
    truth: 4
  14:
    pred: 2
    text: Při učení s učiteľom je úloha definovaná sadou vstupou a očekávaných výstupov.
      Pro posilované učenie je úloha definovaná cielom.
    truth: 2
f6002120d2ae8a2a54c0c5be9cec8ed3:
  6:
    pred: 4
    text: P(nakažen) = 1/5 => P(naložen;P(pozitiv|notožen) = 90 => P(nezl naložení;P(pozitiv)
      = 2 P(pozitiv|nokožen) = 90 =) P(pozitiv|nobožen) = 1/10 P(pozitiv) = P(pozitiv|motožen).
      P(notožen) + P(nozit. / nebožen). P(nakažen) =;26 %
    truth: 4
  7:
    pred: 2
    text: avo akcie;zde je viditelný liveární trend ale váš model se zbytečně moc
      zaměřuje na „outliers“ (ty jsem se snažil nakreslit méně tučně - zde bych si
      prvně prohlédl samotný grot a rozumněji zvolil stupeň nelynomu, zde by byla
      zřejmě vhodná přímka (tedy 1. stupeň)
    truth: 1
  8:
    pred: 3
    text: '- generativní model modelují rozdělaní ze kterého data nejspíše pochází;P(class|dato)
      počítá z apriorních pravděpodobností P(class|) a P(cl. 2) = stejně pro ch. 2
      = 1 - P(cl. 1), observoú P(dato / claso1itu) pomocí bayesova vzorce P(class|doba)
      = P(dato/ class|1). P(closs|);diskriminativní se snaží P(class|dato) přímo modelovat
      jako funkci, su se no trénovacích datech učí čím dál lépe aproximovat (ideálně)
      příkladem může být neuronová síť, třeba klasický MLP trénovaný na klasifikaci
      - výhoda - naučí se modelovat i extrémně složité funkce - nevýhoda - více;P(dato)
      = P(dobro cl. 1) P(cl. 1) + P(dobo) d. 2). P(d. 2) příkladem je gaussovský klasifikátor;-
      nevýhoda - omezenější na složité rozdělení;- výhoda - jedno;dušší'
    truth: 4
  9:
    pred: 3
    text: přizpůsobivost, racionalita, sebeuvědomnění, motivace a cílevědomost, (emposie?),
      schopnost tvořit obstraktní nové koncepty na základě zkušeností (observací,
      schopnost se učit, paměť to jestli musí vykazovat vše je celkem subjektivní
      záležitost, často naujařme inteligentními algoritmy splňující jen pár z někoho
      vlastností, avšak abychom o něčem prohlásili že se jedná o general AI, zřejmě
      bychom požadovali hrubou většinu těchto vlastností
    truth: 4
  10:
    pred: 4
    text: gradient funkce v daném bodě je vektor udávající směr nejrychlejšího růstu
      této funkce v tomto bodě a NN používáme gradient descent - chceme snížit loss,
      a to v závislosti na váhách sítě, tedy spočítáme derivaci d Loss a postupně
      updatujeme váhy (rychlost závisí na learning rok a Ta zavozřejmě se jedná o
      grad. descent jelikož loss chceme snížit, pohybujeme se tedy přesněvadž v směru
      než udává gradient
    truth: 4
  12:
    pred: 1
    text: signál může cestovat oběma směry, můžeme se teda lépe navrátit k minulým
      částem vstupu a tím obdržet více informací vhodných třeba pro kontext
    truth: 2
f617e2298640d040a5e03a69fb64f689:
  4:
    pred: 3
    text: P1 D2;2;X;3;X;4 X;5 X;X;6;X;X;7;X;8.;X;q;x;10;X;x2;D3;x;X;x;X;x;X;X;*;X;X;X;X;X;1=
      512, 3) R = {1, 2, 4} 3 2. 3.
    truth: 1
  5:
    pred: 3
    text: Budeme potrebovat vektor středných hodnot pro každú;dimenciu, tj [u, w2,
      w2 ] � zhodnoty kovarianční maticu 3x3. Následně potoubujeme rozptyly a variancie
      pre jednot- v kt. budú obsáhnuté -> nakolko je táto matica symetrická dimenzie
      - potrebujeme 6 hodnot máme dve trudy spolu máme 2x (3+6) = 18 hodnot použijeme
      Maximum likelihood estim. pre multijamenz. rozloženie a odhadneme parametru
      pre všetky u a Následne tieto najlepšie param. použijeme na modelovaniu dauess
      rozložení pre 1. a 2. třídu. Po dosadení nového data získaní pravdep. s akou
      patrí do kt. triedy
    truth: 3
  10:
    pred: 3
    text: Gradient počítame pri učení NN v rámci loss fce.;Gradient nám ukazuje smer,
      kt. by sme sa mali pohnuť aby sme sa dostali do stavu s vyššou hodnotou preto
      zabírame úprný opak a hodnotu gradientu od váh v NN odčítane. Pomocou gradientu
      tak postupne nájdeme ideálne váhy NN
    truth: 4
  14:
    pred: 2
    text: Pri učení s učitelem dostáva neurónová sieť na vstup data set, ktorý obsahuje
      dvojice (vstupný vektor príznakov, pora vaný správný výstup / siešenie). � tj.
      sieť / agent víe aké je správně rušená kt. sa zna vyrušit;Priposilovanom učenie
      adent disponuje len vstupom [vektor] a postupnými iteráciami sa snaží nájsť
      riešenie, ktoré vopred nepozná, a dozvie sa ho až teď ho najde Následne za toto
      riešenie a jeho kvalitu dostáva odmenu (prime agent sa snaží postupne maximalizovat
      na odměnu
    truth: 3
fbdbb7fc219dc1afa5f5a66fe575382b:
  6:
    pred: 0
    text: P(nak) = P(pos). P(naklpos) = Pinak). P(poslank);P(posl. naz) = 0,9;P(pos)
      =?;0,1 . 0,8 + 0,2. 0,9 = P(pos) P(posledn). P(zár) + Pinak). P(poslanek)
    truth: 4
  9:
    pred: 3
    text: Agent může mít jen nějaké prvky inteligence, abychom ho považovali za inteligentního
      - rozlišujeme tím různé druhy a stupně inteligence.;+ emoční inteligence, racionalita,
      průběžné zlepšování (sebereflexe),
    truth: 3
  14:
    pred: 2
    text: Při učení s učitelem předem známe výsledek a učíme algoritmus, aby uměl
      správně přiřadit daný výsledek ke vstupu.;V reinforcement learningu se učíme
      (algoritmus) najít správný postup - za ten agent dostává odměny. Víme, čeho
      chceme dosáhnout, ale nevíme jak, na to musí algoritmus přijít sám (s pomocí
      odměn).
    truth: 3
fcf2016bac3730d763f23a8a1ffd10de:
  6:
    pred: 4
    text: 80%;90% úspěšnost 0,2x0, 9;testy;nakažen;nenakažen;P;pozitivní;0,18;0,08;0,26;hegarivní;0,02;0,72;0,74;0,2;0,8;Pravděpodobnost;pozitivního;testu;u;populace;je;0,26;26
      %
    truth: 4
  9:
    pred: 3
    text: Aspekty inteligence - správnost řešení;- pochopení kontextu/úlohy pochopení
      existence sama sebe;- záleží na definici inteligenčního agenta Jeden z testu
      inteligence je turingův test, kdy pokud není možné rozeznat řešení člověka a
      agen;jedná se o inteligentního agenta. (vycházíme z toho, že člověk je inteligenní
      takže spíše NE, protože může dávat správné výsledky, ale nechápat složitost
      úlohy)
    truth: 2
  12:
    pred: 3
    text: Vrstva NS zpracovávající data Obosměrná dává do Slova. výhody — větší přesnost
      nevýhody — složitost, náročnost;konzexu předchozí;i;následující
    truth: 3
  13:
    pred: 3
    text: attention mechanizmus od slova pozornost dává;"pozor" na předchozí slova
      a těží z uložených posloupností. nepamatuje si celou historii, ale "jen nedávnou"
      historii méně náročné méně efektivní;Používají se u dlouhých úloh, kde je potřeba
      jen;uchování krátké historie (skloňování slov � ne kontext celého textu
    truth: 1
  14:
    pred: 3
    text: učení s učitelem - dostává na vstup anotovaní data a díky nim se učí na
      učících datech vyřešit úloha;reinforcement learning - nedostává žádná dnorovaná
      data a učí se úloha vyřešit sám, řešení nemusí být. znát jen ohodnocení kroků
      potřebných k dosažení cíle. ohodnocení správných kroků / penalizace špatných
      kroků
    truth: 3
fdd9ca784e674c04aa5436a352eb8651:
  4:
    pred: 3
    text: Dix/3/3/4 x2 x x x x x + 9/X D3 x x 4 x 4 8 x 8;P1 PA PRAP3 P2 P3P2;x1=
      § 33 x2= 533 x3= 48)
    truth: 4
  7:
    pred: 4
    text: '- funkce, podle které byly vygenerována dat;- regresní polynom odpovídající
      K =2 (parabola);- pro zlepšení generalizace potřebujeme více dat;negeneralizuje,
      procház přesně body, málo trenovacích dat. klasifikace generalizace by byla
      špatná.;výsledná'
    truth: 4
feef7d1e9a822ca84b2d9340a42f8ede:
  7:
    pred: 2
    text: tento pokynouvání model prochází všemi testovani doby, jeho MSE-;Negeneralizace
      je způsobem přetrénováním no příliš malé dobové sadě, je potřeba dodat další
      trénovací data
    truth: 4
  9:
    pred: 3
    text: schopnost učení, logické uvožování, schopnost emposie;asociativní myšlení;Nemusí,
      některé aspekty inteligence lze považovat ze specificky "lidské" a ogent je
      nemusí nimitovat.
    truth: 4
  10:
    pred: 4
    text: „Grodientem“ je pravděpodobně myšleno gradient parciálních derivací nějaké
      objektivní funkce. Gradient určuje, kterým směrem derivovaná funkce nejstraněji
      roste pokud tady půjdeme proti jeho směru, nalezneme nejlepší boháku minimum
      dové funkce. Při učení optimalizujeme hodnoty vah neuronové sítě, což lze právě
      provést maturity algoritmem gradient descend, který je založen na tomto principu.
    truth: 4
  11:
    pred: 2
    text: 64 x 64;E;vstupné 7x7, první 5x5.
    truth: 4
  14:
    pred: 2
    text: Při učení s učitelkou přesně vine požadované řešení, u posilovaného učení
      máme definovaný požadovaný výsledek, ale způsob řešení je ponechán více na algoritmu.
    truth: 2
ff2edbee88a7b474b40b3bed7f2d00cd:
  4:
    pred: 3
    text: XII X2;X3;6 x;x X;X;x;x;x;X;X;0;X;l;X;X;X;X;X;O;X;11 = 1=7 K2;= 4 => XI
      =;XI=27 x2=4=7=70 X15157 KLEINEISTŮD
    truth: 3
  6:
    pred: 4
    text: p(nemocný/=0,2 pozdravý) FOL;p(pozitivní (zdravý|=0, 1 plodě;plusovitivní
      (nemocný) 50, P, G. O, 2 + 0, 2 0, 8 = 0, 18 + 0, 0, 26
    truth: 4
  8:
    pred: 2
    text: Generativní model modeluje pravděpodobnostní distribuci dat. např Gaussovský
      klasifikátor. Turní generovat nová data z distribuer;pro klasifikaci obsahují
      diskriminativní pouze modeluje pravděpodobnost. Zbytečně moc parametrů že dato
      patří do daných tříd. (stačí rozh. hranice) např. log. regrese, sum/MLP... t
      stačí méně parametrů;- na málo datech mohou mít horší výsledky
    truth: 3
  11:
    pred: 1
    text: pixel 2. vrstvy závisí na 5x5 aktivacích 1. vrstvy 4 2x7 vstupních rixplech;1
      - 20, 2 579, 6;arii;d 6;MDJ;62-45 kg;- 70,2 1 1/1 B LIALIY BYBAT 41746 59517
      �;9x5 z 1. vstupu;7 x 7 obrázků
    truth: 4
  12:
    pred: 3
    text: narozdíl od normální čte vstup od konce i od začátku;zároveň.;může generovat
      slovo v závislosti na dalších slovech;nemůže ponechovat pokud není udělena celá
      věta předem.
    truth: 4
  13:
    pred: 2
    text: 'dalších částí 6. pro každou část sekvence určuje důležitost setrvalce výhoda:
      může lépe modelovat závislosti začátku věty na konci atd, může se počítat paralelně
      kouřívají se hlavně v jazykových modelech ale i ve visiou. kladekoliv kde je
      na vstupu sekvence'
    truth: 4
